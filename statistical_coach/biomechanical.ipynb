{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '..'\n",
    "# Gets label\n",
    "csv_path = os.path.join(base_path,'data/3DYoga90_corrected.csv')\n",
    "\n",
    "SAVE_PATH = os.path.join(base_path, 'biomechanical_features')\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "# Classification classes\n",
    "pose_list = ['mountain', 'half-way-lift', 'standing-forward-bend', 'downward-dog']\n",
    "subset_of_poses = pose_list\n",
    "NUM_CLASSES = len(pose_list)\n",
    "\n",
    "dataset_dir = os.path.join(base_path, 'official_dataset')\n",
    "assert os.path.isdir(dataset_dir), f\"Directory '{dataset_dir}' does not exist.\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info_path = os.path.join(base_path, 'data')\n",
    "pose_index = pd.read_csv(f'{meta_info_path}/pose-index.csv')\n",
    "sequence_index = pd.read_csv(f'{meta_info_path}/3DYoga90_corrected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant columns\n",
    "def read_meta_data():\n",
    "    meta_info_path = os.path.join(base_path, 'data')\n",
    "    pose_index = pd.read_csv(f'{meta_info_path}/pose-index.csv')\n",
    "    sequence_index = pd.read_csv(f'{meta_info_path}/3DYoga90_corrected.csv')\n",
    "    parquet_index = sequence_index[['sequence_id', 'l3_pose', 'split']]\n",
    "    return parquet_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Yoga3DDataset(Dataset):\n",
    "    def __init__(self, parquet_index, root_dir =  dataset_dir,subset_of_poses= subset_of_poses, sub_sampling_length = 20, transform=None, max_frames=None):\n",
    "        self.parquet_index = parquet_index\n",
    "        self.parquet_index = self.parquet_index[self.parquet_index['l3_pose'].isin(subset_of_poses)]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.max_frames = max_frames\n",
    "        self.sub_sampling_length = sub_sampling_length\n",
    "        self.pose_to_label = {pose: i for i, pose in enumerate(subset_of_poses)}\n",
    "        self.use_augmentation = False\n",
    "\n",
    "        self.cache = dict()\n",
    "        self.idx_to_seq = dict()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.parquet_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.cache:\n",
    "            data, label = self.cache[idx]\n",
    "        else:\n",
    "            fname, pose_name, _ = self.parquet_index.iloc[idx]\n",
    "            label = self.pose_to_label[pose_name]\n",
    "            path = os.path.join(self.root_dir, f'{fname}.parquet')\n",
    "\n",
    "            df = pd.read_parquet(path)\n",
    "            df = df.drop(columns=['frame', 'row_id', 'type','landmark_index'])\n",
    "\n",
    "            data = self.to_tensor(df)\n",
    "            # data = self.sub_sample(data)\n",
    "            data = data.permute(1,0,2)\n",
    "            self.cache[idx] = (data, label)\n",
    "            self.idx_to_seq[idx] = fname\n",
    "\n",
    "        if self.transform and self.use_augmentation:\n",
    "            data = self.transform(data.clone())\n",
    "\n",
    "        return data, self.idx_to_seq[idx] # C, T , V\n",
    "\n",
    "    def sub_sample(self, data):\n",
    "        # data(Number_of_frames, 3, 33)\n",
    "        total_frames = data.shape[0]\n",
    "        indices = torch.linspace(0, total_frames -1 , self.sub_sampling_length, dtype= int)\n",
    "        return data[indices]\n",
    "\n",
    "    def to_tensor(self, df):\n",
    "        # Reshape the data to (num_frames, num_landmarks, 3)  ## WHAT WHAT? this doesn't make sense remove this line you are doing (number of frames, 3 , 33)\n",
    "        num_frames = len(df) // 33  # Assuming 33 landmarks per frame\n",
    "        data = df.values.reshape(num_frames, 33, 3)\n",
    "        return torch.FloatTensor(data).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class BiomechanicalFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the feature extractor.\n",
    "        Note: Simplified version using frame-by-frame differences\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def compute_velocities(self, joint_positions: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute joint velocities from positions using simple frame differences.\n",
    "        \n",
    "        Args:\n",
    "            joint_positions: Tensor of shape (frames, num_joints, 3)\n",
    "            \n",
    "        Returns:\n",
    "            Tensor of shape (frames, num_joints, 3) containing velocities\n",
    "        \"\"\"\n",
    "        # Initialize velocities tensor with zeros\n",
    "        velocities = torch.zeros_like(joint_positions)\n",
    "        \n",
    "        # Compute velocities as simple differences between consecutive frames\n",
    "        velocities[:-1] = joint_positions[1:] - joint_positions[:-1]\n",
    "        \n",
    "        # For the last frame, use the same velocity as the second-to-last frame\n",
    "        velocities[-1] = velocities[-2]\n",
    "        \n",
    "        return velocities\n",
    "    \n",
    "    def compute_accelerations(self, velocities: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute joint accelerations from velocities using simple frame differences.\n",
    "        \n",
    "        Args:\n",
    "            velocities: Tensor of shape (frames, num_joints, 3)\n",
    "            \n",
    "        Returns:\n",
    "            Tensor of shape (frames, num_joints, 3) containing accelerations\n",
    "        \"\"\"\n",
    "        # Initialize accelerations tensor with zeros\n",
    "        accelerations = torch.zeros_like(velocities)\n",
    "        \n",
    "        # Compute accelerations as simple differences between consecutive velocities\n",
    "        accelerations[:-1] = velocities[1:] - velocities[:-1]\n",
    "        \n",
    "        # For the last frame, use the same acceleration as the second-to-last frame\n",
    "        accelerations[-1] = accelerations[-2]\n",
    "        \n",
    "        return accelerations\n",
    "    \n",
    "    def compute_joint_angle(self, p1: torch.Tensor, p2: torch.Tensor, p3: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the angle between three joints.\n",
    "        \n",
    "        Args:\n",
    "            p1, p2, p3: Joint positions forming the angle (p2 is the vertex)\n",
    "            \n",
    "        Returns:\n",
    "            Angle in radians\n",
    "        \"\"\"\n",
    "        # Compute vectors\n",
    "        v1 = p1 - p2  # Vector from p2 to p1\n",
    "        v2 = p3 - p2  # Vector from p2 to p3\n",
    "        \n",
    "        # Compute dot product\n",
    "        dot_product = torch.sum(v1 * v2, dim=-1)\n",
    "        \n",
    "        # Compute magnitudes\n",
    "        v1_mag = torch.sqrt(torch.sum(v1 * v1, dim=-1))\n",
    "        v2_mag = torch.sqrt(torch.sum(v2 * v2, dim=-1))\n",
    "        \n",
    "        # Compute cosine of angle\n",
    "        cos_angle = dot_product / (v1_mag * v2_mag)\n",
    "        \n",
    "        # Clamp to avoid numerical issues\n",
    "        cos_angle = torch.clamp(cos_angle, -1.0, 1.0)\n",
    "        \n",
    "        # Return angle in radians\n",
    "        return torch.acos(cos_angle)\n",
    "    \n",
    "    def compute_joint_angles(\n",
    "        self, \n",
    "        joint_positions: torch.Tensor,\n",
    "        joint_triplets: List[Tuple[int, int, int]]\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute angles for all specified joint triplets.\n",
    "        \n",
    "        Args:\n",
    "            joint_positions: Tensor of shape (frames, num_joints, 3)\n",
    "            joint_triplets: List of tuples containing indices of joint triplets\n",
    "            \n",
    "        Returns:\n",
    "            Tensor of shape (frames, num_angles, 1) containing angles\n",
    "        \"\"\"\n",
    "        num_frames = joint_positions.shape[0]\n",
    "        num_angles = len(joint_triplets)\n",
    "        angles = torch.zeros((num_frames, num_angles, 1))\n",
    "        \n",
    "        for i, (j1, j2, j3) in enumerate(joint_triplets):\n",
    "            angle = self.compute_joint_angle(\n",
    "                joint_positions[:, j1],\n",
    "                joint_positions[:, j2],\n",
    "                joint_positions[:, j3]\n",
    "            )\n",
    "            angles[:, i, 0] = angle\n",
    "            \n",
    "        return angles\n",
    "    \n",
    "    def extract_features(\n",
    "        self, \n",
    "        joint_positions: torch.Tensor,\n",
    "        joint_triplets: List[Tuple[int, int, int]]\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Extract all biomechanical features from joint positions.\n",
    "        \n",
    "        Args:\n",
    "            joint_positions: Tensor of shape (frames, num_joints, 3)\n",
    "            joint_triplets: List of tuples containing indices of joint triplets\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing all computed features\n",
    "        \"\"\"\n",
    "        # Compute velocities\n",
    "        velocities = self.compute_velocities(joint_positions)\n",
    "        \n",
    "        # Compute accelerations\n",
    "        accelerations = self.compute_accelerations(velocities)\n",
    "        \n",
    "        # Compute joint angles\n",
    "        # angles = self.compute_joint_angles(joint_positions, joint_triplets)\n",
    "        \n",
    "        # Return features dictionary\n",
    "        return {\n",
    "            \"Joint Position\": joint_positions,\n",
    "            # \"Joint Angles\": angles,\n",
    "            \"Joint Velocity\": velocities,\n",
    "            \"Joint Acceleration\": accelerations\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_features(features: Dict[str, torch.Tensor], filename: str):\n",
    "        \"\"\"Save features to a .pt file.\"\"\"\n",
    "        torch.save(features, filename)\n",
    "        print(f\"saving {filename}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_features(filename: str) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Load features from a .pt file.\"\"\"\n",
    "        return torch.load(f\"{filename}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def process_dataset(\n",
    "    dataset: Yoga3DDataset,\n",
    "    output_dir: str,\n",
    "    batch_size: int = 1,\n",
    "    num_workers: int = 1,\n",
    "    joint_triplets: List[Tuple[int, int, int]] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Process entire dataset and save biomechanical features.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Yoga3DDataset instance\n",
    "        output_dir: Directory to save extracted features\n",
    "        batch_size: Batch size for dataloader (default 1 for sequential processing)\n",
    "        num_workers: Number of worker processes for data loading\n",
    "        joint_triplets: List of joint triplet indices for angle calculation\n",
    "    \"\"\"\n",
    "    \n",
    "    extractor = BiomechanicalFeatureExtractor()\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False  # Keep sequential order\n",
    "    )\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Processing sequences\"):\n",
    "        joints, fnames = batch  # Shape: (B, 3, frames, 33) \n",
    "        for i in range(len(joints)):\n",
    "            joint_positions = joints[i]  # Shape: (3, frames, 33)\n",
    "            fname = fnames[i]\n",
    "            # From: (3, frames, 33) -> To: (frames, 33, 3)\n",
    "            joint_positions = joint_positions.permute(1, 2, 0)\n",
    "            # Extract features\n",
    "            features = extractor.extract_features(\n",
    "                joint_positions,\n",
    "                joint_triplets\n",
    "            )\n",
    "            print(features[\"Joint Velocity\"])  \n",
    "            # Save features\n",
    "            output_path = os.path.join(output_dir, f\"{fname}.pt\")\n",
    "            extractor.save_features(features, output_path)\n",
    "\n",
    "def verify_processed_features(\n",
    "    output_dir: str,\n",
    "    expected_count: int\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Verify that all features were properly extracted and saved.\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory containing saved features\n",
    "        expected_count: Expected number of processed sequences\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if verification passes\n",
    "    \"\"\"\n",
    "    # Count .pt files in output directory\n",
    "    feature_files = list(Path(output_dir).glob(\"*.pt\"))\n",
    "    actual_count = len(feature_files)\n",
    "    \n",
    "    # Basic verification\n",
    "    if actual_count != expected_count:\n",
    "        print(f\"Warning: Found {actual_count} feature files, expected {expected_count}\")\n",
    "        return False\n",
    "    \n",
    "    # Try loading each file\n",
    "    for file_path in tqdm(feature_files, desc=\"Verifying files\"):\n",
    "        try:\n",
    "            features = torch.load(str(file_path))\n",
    "            # Check if all expected keys are present\n",
    "            expected_keys = {\"Joint Position\", \"Joint Angles\", \"Joint Velocity\", \"Joint Acceleration\"}\n",
    "            if not all(key in features for key in expected_keys):\n",
    "                print(f\"Warning: Missing keys in {file_path}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = Yoga3DDataset(read_meta_data())\n",
    "   \n",
    "    process_dataset(\n",
    "        dataset=dataset,\n",
    "        output_dir=SAVE_PATH,\n",
    "        batch_size=1,\n",
    "        num_workers=1,\n",
    "        joint_triplets=None  \n",
    "    )\n",
    "    \n",
    "    # Verify processing\n",
    "    # success = verify_processed_features(\n",
    "    #     output_dir=SAVE_PATH,\n",
    "    #     expected_count=len(dataset)\n",
    "    # )\n",
    "    \n",
    "    # if success:\n",
    "    #     print(\"Feature extraction completed successfully!\")\n",
    "    # else:\n",
    "    #     print(\"Feature extraction completed with some issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# # Define the MediaPipe Pose landmarks and their connections\n",
    "# # Landmark names and their corresponding indices\n",
    "# LANDMARK_NAMES = [\n",
    "#     'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer', 'right_eye_inner',\n",
    "#     'right_eye', 'right_eye_outer', 'left_ear', 'right_ear', 'mouth_left',\n",
    "#     'mouth_right', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
    "#     'left_wrist', 'right_wrist', 'left_pinky', 'right_pinky', 'left_index',\n",
    "#     'right_index', 'left_thumb', 'right_thumb', 'left_hip', 'right_hip',\n",
    "#     'left_knee', 'right_knee', 'left_ankle', 'right_ankle', 'left_heel',\n",
    "#     'right_heel', 'left_foot_index', 'right_foot_index'\n",
    "# ]\n",
    "\n",
    "# # Define connections between landmarks\n",
    "# POSE_CONNECTIONS = [\n",
    "#     (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8),\n",
    "#     (1, 2), (2, 3), (4, 5), (5, 6), (7, 9), (8, 10), (11, 12),\n",
    "#     (11, 13), (13, 15), (15, 17), (15, 19), (15, 21), (12, 14),\n",
    "#     (14, 16), (16, 18), (16, 20), (16, 22), (11, 23), (12, 24),\n",
    "#     (23, 24), (23, 25), (24, 26), (25, 27), (26, 28), (27, 29),\n",
    "#     (28, 30), (29, 31), (30, 32)\n",
    "# ]\n",
    "\n",
    "# def visualize_pose_sequence(data, label, connections=POSE_CONNECTIONS, figsize=(8, 8)):\n",
    "#     \"\"\"\n",
    "#     Visualize a sequence of 3D poses.\n",
    "\n",
    "#     Parameters:\n",
    "#         data (torch.Tensor): Tensor of shape (channels, number_of_frames, landmarks=33)\n",
    "#                              where channels are x, y, z coordinates.\n",
    "#         label (int): The label corresponding to the pose.\n",
    "#         connections (list of tuples): Landmark connections to draw the skeleton.\n",
    "#         figsize (tuple): Figure size for the plot.\n",
    "#     \"\"\"\n",
    "#     # Convert tensor to numpy array\n",
    "#     data_np = data.numpy()\n",
    "#     # Assuming channels are in the order x, y, z\n",
    "#     x = data_np[0]  # shape: (number_of_frames, 33)\n",
    "#     y = data_np[1]\n",
    "#     z = data_np[2]\n",
    "#     # print(x.shape)\n",
    "#     num_frames = x.shape[0]\n",
    "\n",
    "#     # Create a figure and a 3D subplot\n",
    "#     fig = plt.figure(figsize=figsize)\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "#     plt.title(f'Pose: {label}')\n",
    "\n",
    "#     # Function to update the plot for each frame\n",
    "#     def update(frame):\n",
    "#         ax.cla()\n",
    "#         ax.set_xlim3d(-1, 1)\n",
    "#         ax.set_ylim3d(-1, 1)\n",
    "#         ax.set_zlim3d(-1, 1)\n",
    "#         ax.set_xlabel('X')\n",
    "#         ax.set_ylabel('Y')\n",
    "#         ax.set_zlabel('Z')\n",
    "#         plt.title(f'Pose: {label}, Frame: {frame + 1}/{num_frames}')\n",
    "\n",
    "#         # Scatter plot of landmarks\n",
    "#         ax.scatter(x[frame], y[frame], z[frame], c='r', marker='.')\n",
    "\n",
    "#         # Draw connections\n",
    "#         for connection in connections:\n",
    "#             idx1, idx2 = connection\n",
    "#             ax.plot([x[frame, idx1], x[frame, idx2]],\n",
    "#                     [y[frame, idx1], y[frame, idx2]],\n",
    "#                     [z[frame, idx1], z[frame, idx2]], 'b-')\n",
    "#         # plt.show() \n",
    "#         return\n",
    "\n",
    "#     # Create the animation\n",
    "#     anim = FuncAnimation(fig, update, frames=num_frames, interval=100)\n",
    "#     plt.show()\n",
    "#     save_dir = 'data'\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "#     save_path = os.path.join(save_dir, f'test_{label}.mp4')\n",
    "#     anim.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
