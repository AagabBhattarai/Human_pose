{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '..'\n",
    "# Gets label\n",
    "csv_path = os.path.join(base_path,'data/3DYoga90_corrected.csv')\n",
    "\n",
    "SAVE_PATH = os.path.join(base_path, 'biomechanical_features')\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "# Classification classes\n",
    "pose_list = ['mountain', 'half-way-lift', 'standing-forward-bend', 'downward-dog']\n",
    "subset_of_poses = pose_list\n",
    "NUM_CLASSES = len(pose_list)\n",
    "\n",
    "dataset_dir = os.path.join(base_path, 'official_dataset')\n",
    "assert os.path.isdir(dataset_dir), f\"Directory '{dataset_dir}' does not exist.\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info_path = os.path.join(base_path, 'data')\n",
    "pose_index = pd.read_csv(f'{meta_info_path}/pose-index.csv')\n",
    "sequence_index = pd.read_csv(f'{meta_info_path}/3DYoga90_corrected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant columns\n",
    "def read_meta_data():\n",
    "    meta_info_path = os.path.join(base_path, 'data')\n",
    "    pose_index = pd.read_csv(f'{meta_info_path}/pose-index.csv')\n",
    "    sequence_index = pd.read_csv(f'{meta_info_path}/3DYoga90_corrected.csv')\n",
    "    parquet_index = sequence_index[['sequence_id', 'l3_pose', 'split']]\n",
    "    return parquet_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Yoga3DDataset(Dataset):\n",
    "    def __init__(self, parquet_index, root_dir =  dataset_dir,subset_of_poses= subset_of_poses, sub_sampling_length = 20, transform=None, max_frames=None):\n",
    "        self.parquet_index = parquet_index\n",
    "        self.parquet_index = self.parquet_index[self.parquet_index['l3_pose'].isin(subset_of_poses)]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.max_frames = max_frames\n",
    "        self.sub_sampling_length = sub_sampling_length\n",
    "        self.pose_to_label = {pose: i for i, pose in enumerate(subset_of_poses)}\n",
    "        self.use_augmentation = False\n",
    "\n",
    "        self.cache = dict()\n",
    "        self.idx_to_seq = dict()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.parquet_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.cache:\n",
    "            data, label = self.cache[idx]\n",
    "        else:\n",
    "            fname, pose_name, _ = self.parquet_index.iloc[idx]\n",
    "            label = self.pose_to_label[pose_name]\n",
    "            path = os.path.join(self.root_dir, f'{fname}.parquet')\n",
    "\n",
    "            df = pd.read_parquet(path)\n",
    "            df = df.drop(columns=['frame', 'row_id', 'type','landmark_index'])\n",
    "\n",
    "            data = self.to_tensor(df)\n",
    "            # data = self.sub_sample(data)\n",
    "            data = data.permute(1,0,2)\n",
    "            self.cache[idx] = (data, label)\n",
    "            self.idx_to_seq[idx] = fname\n",
    "\n",
    "        if self.transform and self.use_augmentation:\n",
    "            data = self.transform(data.clone())\n",
    "\n",
    "        return data, self.idx_to_seq[idx] # C, T , V\n",
    "\n",
    "    def sub_sample(self, data):\n",
    "        # data(Number_of_frames, 3, 33)\n",
    "        total_frames = data.shape[0]\n",
    "        indices = torch.linspace(0, total_frames -1 , self.sub_sampling_length, dtype= int)\n",
    "        return data[indices]\n",
    "\n",
    "    def to_tensor(self, df):\n",
    "        # Reshape the data to (num_frames, num_landmarks, 3)  ## WHAT WHAT? this doesn't make sense remove this line you are doing (number of frames, 3 , 33)\n",
    "        num_frames = len(df) // 33  # Assuming 33 landmarks per frame\n",
    "        data = df.values.reshape(num_frames, 33, 3)\n",
    "        return torch.FloatTensor(data).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_vector(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate vector between two 3D points\n",
    "    \"\"\"\n",
    "    return point2 - point1\n",
    "\n",
    "def calculate_angle(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Calculate angle between two 3D vectors using dot product\n",
    "    Returns angle in degrees\n",
    "    \"\"\"\n",
    "    dot_product = torch.dot(vector1, vector2)\n",
    "    norms = torch.norm(vector1) * torch.norm(vector2)\n",
    "    \n",
    "    # Handle numerical stability\n",
    "    cos_angle = torch.clamp(dot_product / norms, -1.0, 1.0)\n",
    "    angle_rad = torch.acos(cos_angle)\n",
    "    return torch.rad2deg(angle_rad)\n",
    "\n",
    "def calculate_projected_angle(vector1, vector2, normal):\n",
    "    \"\"\"\n",
    "    Calculate angle between two vectors when projected onto a plane\n",
    "    defined by its normal vector\n",
    "    \"\"\"\n",
    "    # Project vectors onto the plane\n",
    "    proj1 = vector1 - torch.dot(vector1, normal) * normal\n",
    "    proj2 = vector2 - torch.dot(vector2, normal) * normal\n",
    "    \n",
    "    return calculate_angle(proj1, proj2)\n",
    "\n",
    "def calculate_joint_angles(poses):\n",
    "    \"\"\"\n",
    "    Calculate relevant joint angles from pose data\n",
    "    Input: poses - torch tensor of shape (frames, 33, 3)\n",
    "    Output: dictionary of joint angles\n",
    "    \"\"\"\n",
    "    joint_configs = {\n",
    "        # Upper body\n",
    "        'right_shoulder': {\n",
    "            'joints': (13, 11, 23),  # right_elbow, right_shoulder, right_hip\n",
    "            'planes': ['sagittal', 'transverse', 'frontal']\n",
    "        },\n",
    "        'left_shoulder': {\n",
    "            'joints': (14, 12, 24),  # left_elbow, left_shoulder, left_hip\n",
    "            'planes': ['sagittal', 'transverse', 'frontal']\n",
    "        },\n",
    "        'right_elbow': {\n",
    "            'joints': (11, 13, 15),  # right_shoulder, right_elbow, right_wrist\n",
    "            'planes': ['sagittal', 'transverse', 'frontal']\n",
    "        },\n",
    "        'left_elbow': {\n",
    "            'joints': (12, 14, 16),  # left_shoulder, left_elbow, left_wrist\n",
    "            'planes': ['sagittal', 'transverse', 'frontal']\n",
    "        },\n",
    "        \n",
    "        # Lower body\n",
    "        'right_hip': {\n",
    "            'joints': (11, 23, 25),  # right_shoulder, right_hip, right_knee\n",
    "            'planes': ['sagittal', 'transverse', 'frontal']\n",
    "        },\n",
    "        'left_hip': {\n",
    "            'joints': (12, 24, 26),  # left_shoulder, left_hip, left_knee\n",
    "            'planes': ['sagittal', 'transverse', 'frontal']\n",
    "        },\n",
    "        'right_knee': {\n",
    "            'joints': (23, 25, 27),  # right_hip, right_knee, right_ankle\n",
    "            'planes': ['sagittal', 'transverse', 'frontal']  # Now including transverse\n",
    "        },\n",
    "        'left_knee': {\n",
    "            'joints': (24, 26, 28),  # left_hip, left_knee, left_ankle\n",
    "            'planes': ['sagittal', 'transverse', 'frontal']  # Now including transverse\n",
    "        },\n",
    "        'right_ankle': {\n",
    "            'joints': (25, 27, 31),  # right_knee, right_ankle, right_foot_index\n",
    "            'planes': ['sagittal', 'transverse', 'frontal']\n",
    "        },\n",
    "        'left_ankle': {\n",
    "            'joints': (26, 28, 32),  # left_knee, left_ankle, left_foot_index\n",
    "            'planes': ['sagittal', 'transverse', 'frontal']\n",
    "        }\n",
    "    }\n",
    "    num_frames = poses.shape[0]\n",
    "    angles = {}\n",
    "    angles_tensor = torch.zeros((num_frames,len(joint_configs),1 ))\n",
    "    # Define joint triplets for angle calculation\n",
    "    \n",
    "    # Define anatomical planes using normal vectors\n",
    "    planes = {\n",
    "        'sagittal': torch.tensor([1, 0, 0]),  # Left-right axis (flexion/extension)\n",
    "        'frontal': torch.tensor([0, 0, 1]),   # Forward-backward axis (abduction/adduction)\n",
    "        'transverse': torch.tensor([0, 1, 0])  # Up-down axis (internal/external rotation)\n",
    "    }\n",
    "    \n",
    "    # Calculate angles for each frame\n",
    "    for frame in range(num_frames):\n",
    "        frame_angles = {}\n",
    "        \n",
    "        for j, (joint_name, config) in enumerate(joint_configs.items()):\n",
    "            j1, j2, j3 = config['joints']\n",
    "            \n",
    "            # Calculate vectors\n",
    "            vector1 = calculate_vector(poses[frame, j2], poses[frame, j1])\n",
    "            vector2 = calculate_vector(poses[frame, j2], poses[frame, j3])\n",
    "            \n",
    "            # Calculate 3D angle\n",
    "            computed_angle = calculate_angle(vector1, vector2)\n",
    "            frame_angles[f\"{joint_name}_3d\"] = computed_angle \n",
    "            angles_tensor[frame, j,0] =  computed_angle\n",
    "            # # Calculate projected angles on anatomical planes\n",
    "            # for plane_name in config['planes']:\n",
    "            #     normal = planes[plane_name]\n",
    "            #     projected_angle = calculate_projected_angle(vector1, vector2, normal)\n",
    "            #     frame_angles[f\"{joint_name}_{plane_name}\"] = projected_angle\n",
    "        \n",
    "        angles[frame] = frame_angles\n",
    "    \n",
    "    return angles, angles_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class BiomechanicalFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the feature extractor.\n",
    "        Note: Simplified version using frame-by-frame differences\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def compute_velocities(self, joint_positions: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute joint velocities from positions using simple frame differences.\n",
    "        \n",
    "        Args:\n",
    "            joint_positions: Tensor of shape (frames, num_joints, 3)\n",
    "            \n",
    "        Returns:\n",
    "            Tensor of shape (frames, num_joints, 3) containing velocities\n",
    "        \"\"\"\n",
    "        # Initialize velocities tensor with zeros\n",
    "        velocities = torch.zeros_like(joint_positions)\n",
    "        \n",
    "        # Compute velocities as simple differences between consecutive frames\n",
    "        velocities[:-1] = joint_positions[1:] - joint_positions[:-1]\n",
    "        \n",
    "        # For the last frame, use the same velocity as the second-to-last frame\n",
    "        velocities[-1] = velocities[-2]\n",
    "        \n",
    "        return velocities\n",
    "    \n",
    "    def compute_accelerations(self, velocities: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute joint accelerations from velocities using simple frame differences.\n",
    "        \n",
    "        Args:\n",
    "            velocities: Tensor of shape (frames, num_joints, 3)\n",
    "            \n",
    "        Returns:\n",
    "            Tensor of shape (frames, num_joints, 3) containing accelerations\n",
    "        \"\"\"\n",
    "        # Initialize accelerations tensor with zeros\n",
    "        accelerations = torch.zeros_like(velocities)\n",
    "        \n",
    "        # Compute accelerations as simple differences between consecutive velocities\n",
    "        accelerations[:-1] = velocities[1:] - velocities[:-1]\n",
    "        \n",
    "        # For the last frame, use the same acceleration as the second-to-last frame\n",
    "        accelerations[-1] = accelerations[-2]\n",
    "        \n",
    "        return accelerations\n",
    "    \n",
    "\n",
    "    def compute_joint_angles(\n",
    "        self, \n",
    "        joint_positions: torch.Tensor,\n",
    "    ) -> Tuple[Dict[str, torch.Tensor], torch.Tensor]:\n",
    "        joint_angles, angles_tensor = calculate_joint_angles(joint_positions)\n",
    "        return joint_angles, angles_tensor\n",
    "    \n",
    "    def extract_features(\n",
    "        self, \n",
    "        joint_positions: torch.Tensor,\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Extract all biomechanical features from joint positions.\n",
    "        \n",
    "        Args:\n",
    "            joint_positions: Tensor of shape (frames, num_joints, 3)\n",
    "        Returns:\n",
    "            Dictionary containing all computed features\n",
    "        \"\"\"\n",
    "        velocities = self.compute_velocities(joint_positions)\n",
    "        accelerations = self.compute_accelerations(velocities)\n",
    "        angles_dict, angles = self.compute_joint_angles(joint_positions)# Access Angles Dict if you need to know which scalar value corresponds to which angle\n",
    "\n",
    "        return {\n",
    "            \"Joint Position\": joint_positions,\n",
    "            \"Joint Angles\": angles,\n",
    "            \"Joint Velocity\": velocities,\n",
    "            \"Joint Acceleration\": accelerations\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_features(features: Dict[str, torch.Tensor], filename: str):\n",
    "        \"\"\"Save features to a .pt file.\"\"\"\n",
    "        torch.save(features, filename)\n",
    "        print(f\"saving {filename}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_features(filename: str) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Load features from a .pt file.\"\"\"\n",
    "        return torch.load(f\"{filename}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   0%|          | 3/844 [00:00<00:36, 23.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1000.pt\n",
      "saving ..\\biomechanical_features\\1002.pt\n",
      "saving ..\\biomechanical_features\\1003.pt\n",
      "saving ..\\biomechanical_features\\1004.pt\n",
      "saving ..\\biomechanical_features\\1005.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   1%|          | 8/844 [00:00<00:45, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1006.pt\n",
      "saving ..\\biomechanical_features\\1007.pt\n",
      "saving ..\\biomechanical_features\\1008.pt\n",
      "saving ..\\biomechanical_features\\1009.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   2%|▏         | 13/844 [00:00<00:51, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1010.pt\n",
      "saving ..\\biomechanical_features\\1011.pt\n",
      "saving ..\\biomechanical_features\\1012.pt\n",
      "saving ..\\biomechanical_features\\1013.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   2%|▏         | 15/844 [00:00<00:57, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1014.pt\n",
      "saving ..\\biomechanical_features\\1015.pt\n",
      "saving ..\\biomechanical_features\\1016.pt\n",
      "saving ..\\biomechanical_features\\1017.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   2%|▏         | 20/844 [00:01<00:57, 14.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1018.pt\n",
      "saving ..\\biomechanical_features\\1020.pt\n",
      "saving ..\\biomechanical_features\\1021.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   3%|▎         | 23/844 [00:01<00:53, 15.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1022.pt\n",
      "saving ..\\biomechanical_features\\1023.pt\n",
      "saving ..\\biomechanical_features\\1024.pt\n",
      "saving ..\\biomechanical_features\\1025.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   3%|▎         | 27/844 [00:01<01:13, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1026.pt\n",
      "saving ..\\biomechanical_features\\1027.pt\n",
      "saving ..\\biomechanical_features\\1028.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   4%|▎         | 31/844 [00:02<01:05, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1029.pt\n",
      "saving ..\\biomechanical_features\\1030.pt\n",
      "saving ..\\biomechanical_features\\1031.pt\n",
      "saving ..\\biomechanical_features\\1032.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   4%|▍         | 33/844 [00:02<01:00, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1033.pt\n",
      "saving ..\\biomechanical_features\\1034.pt\n",
      "saving ..\\biomechanical_features\\1035.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   4%|▍         | 37/844 [00:02<01:00, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1036.pt\n",
      "saving ..\\biomechanical_features\\1037.pt\n",
      "saving ..\\biomechanical_features\\1038.pt\n",
      "saving ..\\biomechanical_features\\1039.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   5%|▍         | 41/844 [00:02<00:58, 13.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1040.pt\n",
      "saving ..\\biomechanical_features\\1041.pt\n",
      "saving ..\\biomechanical_features\\1042.pt\n",
      "saving ..\\biomechanical_features\\1043.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   5%|▌         | 45/844 [00:03<00:51, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1044.pt\n",
      "saving ..\\biomechanical_features\\1045.pt\n",
      "saving ..\\biomechanical_features\\1046.pt\n",
      "saving ..\\biomechanical_features\\1047.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   6%|▌         | 49/844 [00:03<00:50, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1048.pt\n",
      "saving ..\\biomechanical_features\\1049.pt\n",
      "saving ..\\biomechanical_features\\1050.pt\n",
      "saving ..\\biomechanical_features\\1051.pt\n",
      "saving ..\\biomechanical_features\\1052.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   7%|▋         | 55/844 [00:03<00:44, 17.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1053.pt\n",
      "saving ..\\biomechanical_features\\1054.pt\n",
      "saving ..\\biomechanical_features\\1055.pt\n",
      "saving ..\\biomechanical_features\\1056.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   7%|▋         | 59/844 [00:03<00:45, 17.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1057.pt\n",
      "saving ..\\biomechanical_features\\1058.pt\n",
      "saving ..\\biomechanical_features\\1059.pt\n",
      "saving ..\\biomechanical_features\\1060.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   7%|▋         | 63/844 [00:04<00:47, 16.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1061.pt\n",
      "saving ..\\biomechanical_features\\1062.pt\n",
      "saving ..\\biomechanical_features\\1063.pt\n",
      "saving ..\\biomechanical_features\\1064.pt\n",
      "saving ..\\biomechanical_features\\1065.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   8%|▊         | 65/844 [00:04<01:21,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1066.pt\n",
      "saving ..\\biomechanical_features\\1067.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   8%|▊         | 67/844 [00:04<01:30,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1068.pt\n",
      "saving ..\\biomechanical_features\\1069.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   8%|▊         | 70/844 [00:05<01:43,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1070.pt\n",
      "saving ..\\biomechanical_features\\1071.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sequences:   9%|▊         | 73/844 [00:05<01:00, 12.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving ..\\biomechanical_features\\1072.pt\n",
      "saving ..\\biomechanical_features\\1073.pt\n",
      "saving ..\\biomechanical_features\\1074.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     32\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m Yoga3DDataset(read_meta_data())\n\u001b[1;32m---> 34\u001b[0m     process_dataset(\n\u001b[0;32m     35\u001b[0m         dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m     36\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39mSAVE_PATH,\n\u001b[0;32m     37\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[84], line 24\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[1;34m(dataset, output_dir)\u001b[0m\n\u001b[0;32m     22\u001b[0m joint_positions \u001b[38;5;241m=\u001b[39m joints\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m features \u001b[38;5;241m=\u001b[39m extractor\u001b[38;5;241m.\u001b[39mextract_features(\n\u001b[0;32m     25\u001b[0m     joint_positions\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m extractor\u001b[38;5;241m.\u001b[39msave_features(features, output_path)\n",
      "Cell \u001b[1;32mIn[83], line 77\u001b[0m, in \u001b[0;36mBiomechanicalFeatureExtractor.extract_features\u001b[1;34m(self, joint_positions)\u001b[0m\n\u001b[0;32m     75\u001b[0m velocities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_velocities(joint_positions)\n\u001b[0;32m     76\u001b[0m accelerations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_accelerations(velocities)\n\u001b[1;32m---> 77\u001b[0m angles_dict, angles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_joint_angles(joint_positions)\u001b[38;5;66;03m# Access Angles Dict if you need to know which scalar value corresponds to which angle\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoint Position\u001b[39m\u001b[38;5;124m\"\u001b[39m: joint_positions,\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoint Angles\u001b[39m\u001b[38;5;124m\"\u001b[39m: angles,\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoint Velocity\u001b[39m\u001b[38;5;124m\"\u001b[39m: velocities,\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoint Acceleration\u001b[39m\u001b[38;5;124m\"\u001b[39m: accelerations\n\u001b[0;32m     84\u001b[0m }\n",
      "Cell \u001b[1;32mIn[83], line 60\u001b[0m, in \u001b[0;36mBiomechanicalFeatureExtractor.compute_joint_angles\u001b[1;34m(self, joint_positions)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_joint_angles\u001b[39m(\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m     58\u001b[0m     joint_positions: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m     59\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor], torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m---> 60\u001b[0m     joint_angles, angles_tensor \u001b[38;5;241m=\u001b[39m calculate_joint_angles(joint_positions)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m joint_angles, angles_tensor\n",
      "Cell \u001b[1;32mIn[82], line 105\u001b[0m, in \u001b[0;36mcalculate_joint_angles\u001b[1;34m(poses)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Calculate vectors\u001b[39;00m\n\u001b[0;32m    104\u001b[0m vector1 \u001b[38;5;241m=\u001b[39m calculate_vector(poses[frame, j2], poses[frame, j1])\n\u001b[1;32m--> 105\u001b[0m vector2 \u001b[38;5;241m=\u001b[39m calculate_vector(poses[frame, j2], poses[frame, j3])\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Calculate 3D angle\u001b[39;00m\n\u001b[0;32m    108\u001b[0m computed_angle \u001b[38;5;241m=\u001b[39m calculate_angle(vector1, vector2)\n",
      "Cell \u001b[1;32mIn[82], line 3\u001b[0m, in \u001b[0;36mcalculate_vector\u001b[1;34m(point1, point2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_vector\u001b[39m(point1, point2):\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    Calculate vector between two 3D points\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m point2 \u001b[38;5;241m-\u001b[39m point1\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_dataset(\n",
    "    dataset: Yoga3DDataset,\n",
    "    output_dir: str,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Process entire dataset and save biomechanical features.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Yoga3DDataset instance\n",
    "        output_dir: Directory to save extracted features\n",
    "        joint_triplets: List of joint triplet indices for angle calculation\n",
    "    \"\"\"\n",
    "    \n",
    "    extractor = BiomechanicalFeatureExtractor()\n",
    "    \n",
    "    for i in tqdm(range(len(dataset)), desc=\"Processing sequences\"):\n",
    "        joints, fname = dataset[i]  # Shape: (3, frames, 33) \n",
    "        # From: (3, frames, 33) -> To: (frames, 33, 3)\n",
    "        joint_positions = joints.permute(1, 2, 0)\n",
    "        # Extract features\n",
    "        features = extractor.extract_features(\n",
    "            joint_positions\n",
    "        )\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"{fname}.pt\")\n",
    "        extractor.save_features(features, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = Yoga3DDataset(read_meta_data())\n",
    "   \n",
    "    process_dataset(\n",
    "        dataset=dataset,\n",
    "        output_dir=SAVE_PATH,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# # Define the MediaPipe Pose landmarks and their connections\n",
    "# # Landmark names and their corresponding indices\n",
    "# LANDMARK_NAMES = [\n",
    "#     'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer', 'right_eye_inner',\n",
    "#     'right_eye', 'right_eye_outer', 'left_ear', 'right_ear', 'mouth_left',\n",
    "#     'mouth_right', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',\n",
    "#     'left_wrist', 'right_wrist', 'left_pinky', 'right_pinky', 'left_index',\n",
    "#     'right_index', 'left_thumb', 'right_thumb', 'left_hip', 'right_hip',\n",
    "#     'left_knee', 'right_knee', 'left_ankle', 'right_ankle', 'left_heel',\n",
    "#     'right_heel', 'left_foot_index', 'right_foot_index'\n",
    "# ]\n",
    "\n",
    "# # Define connections between landmarks\n",
    "# POSE_CONNECTIONS = [\n",
    "#     (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8),\n",
    "#     (1, 2), (2, 3), (4, 5), (5, 6), (7, 9), (8, 10), (11, 12),\n",
    "#     (11, 13), (13, 15), (15, 17), (15, 19), (15, 21), (12, 14),\n",
    "#     (14, 16), (16, 18), (16, 20), (16, 22), (11, 23), (12, 24),\n",
    "#     (23, 24), (23, 25), (24, 26), (25, 27), (26, 28), (27, 29),\n",
    "#     (28, 30), (29, 31), (30, 32)\n",
    "# ]\n",
    "\n",
    "# def visualize_pose_sequence(data, label, connections=POSE_CONNECTIONS, figsize=(8, 8)):\n",
    "#     \"\"\"\n",
    "#     Visualize a sequence of 3D poses.\n",
    "\n",
    "#     Parameters:\n",
    "#         data (torch.Tensor): Tensor of shape (channels, number_of_frames, landmarks=33)\n",
    "#                              where channels are x, y, z coordinates.\n",
    "#         label (int): The label corresponding to the pose.\n",
    "#         connections (list of tuples): Landmark connections to draw the skeleton.\n",
    "#         figsize (tuple): Figure size for the plot.\n",
    "#     \"\"\"\n",
    "#     # Convert tensor to numpy array\n",
    "#     data_np = data.numpy()\n",
    "#     # Assuming channels are in the order x, y, z\n",
    "#     x = data_np[0]  # shape: (number_of_frames, 33)\n",
    "#     y = data_np[1]\n",
    "#     z = data_np[2]\n",
    "#     # print(x.shape)\n",
    "#     num_frames = x.shape[0]\n",
    "\n",
    "#     # Create a figure and a 3D subplot\n",
    "#     fig = plt.figure(figsize=figsize)\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "#     plt.title(f'Pose: {label}')\n",
    "\n",
    "#     # Function to update the plot for each frame\n",
    "#     def update(frame):\n",
    "#         ax.cla()\n",
    "#         ax.set_xlim3d(-1, 1)\n",
    "#         ax.set_ylim3d(-1, 1)\n",
    "#         ax.set_zlim3d(-1, 1)\n",
    "#         ax.set_xlabel('X')\n",
    "#         ax.set_ylabel('Y')\n",
    "#         ax.set_zlabel('Z')\n",
    "#         plt.title(f'Pose: {label}, Frame: {frame + 1}/{num_frames}')\n",
    "\n",
    "#         # Scatter plot of landmarks\n",
    "#         ax.scatter(x[frame], y[frame], z[frame], c='r', marker='.')\n",
    "\n",
    "#         # Draw connections\n",
    "#         for connection in connections:\n",
    "#             idx1, idx2 = connection\n",
    "#             ax.plot([x[frame, idx1], x[frame, idx2]],\n",
    "#                     [y[frame, idx1], y[frame, idx2]],\n",
    "#                     [z[frame, idx1], z[frame, idx2]], 'b-')\n",
    "#         # plt.show() \n",
    "#         return\n",
    "\n",
    "#     # Create the animation\n",
    "#     anim = FuncAnimation(fig, update, frames=num_frames, interval=100)\n",
    "#     plt.show()\n",
    "#     save_dir = 'data'\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "#     save_path = os.path.join(save_dir, f'test_{label}.mp4')\n",
    "#     anim.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
