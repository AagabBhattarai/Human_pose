{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\aagab\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\aagab\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imageio[ffmpeg] in c:\\users\\aagab\\anaconda3\\lib\\site-packages (2.33.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\aagab\\anaconda3\\lib\\site-packages (from imageio[ffmpeg]) (1.26.4)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\aagab\\anaconda3\\lib\\site-packages (from imageio[ffmpeg]) (10.3.0)\n",
      "Requirement already satisfied: imageio-ffmpeg in c:\\users\\aagab\\anaconda3\\lib\\site-packages (from imageio[ffmpeg]) (0.5.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\aagab\\anaconda3\\lib\\site-packages (from imageio[ffmpeg]) (5.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aagab\\anaconda3\\lib\\site-packages (from imageio-ffmpeg->imageio[ffmpeg]) (69.5.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python\n",
    "%pip install imageio[ffmpeg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_path = 'data/3DYoga90.csv'\n",
    "sequence_path = 'short/download_log.txt'\n",
    "pose_list = ['mountain', 'half-way-lift', 'standing-forward-bend', 'downward-dog']\n",
    "NUM_CLASSES = len(pose_list)\n",
    "video_dir = 'short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "FRAME_HEIGHT = 224  # VGG16 input size\n",
    "FRAME_WIDTH = 224\n",
    "SEQUENCE_LENGTH = 16 \n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "97\n",
      "torch.Size([16, 3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('short\\\\1000.mp4', 'mountain', tensor([1., 0., 0., 0.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "length_of_dataset = 0\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, csv_path, sequence_path, pose_list, video_dir):\n",
    "        with open(sequence_path) as f:\n",
    "            sequence_list = f.read().splitlines()\n",
    "            sequence_list = [int(x) for x in sequence_list]\n",
    "            \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        # Keep only downloaded sequences\n",
    "        self.df = self.df[self.df['sequence_id'].isin(sequence_list)]\n",
    "        # Keep only required classes\n",
    "        self.df = self.df[self.df['l3_pose'].isin(pose_list)]\n",
    "\n",
    "        self.pose_to_idx = {pose: idx for idx, pose in enumerate(pose_list)}\n",
    "\n",
    "        self.length_of_dataset = len(self.df)\n",
    "\n",
    "        self.video_dir = video_dir\n",
    "\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize((FRAME_HEIGHT, FRAME_WIDTH)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length_of_dataset\n",
    "\n",
    "    def print(self):\n",
    "        print(len(self.df))\n",
    "        print(self.pose_to_idx)\n",
    "        print(len(self))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sequence_id = self.df.iloc[i]['sequence_id']\n",
    "        print(sequence_id)\n",
    "        video_path = os.path.join(self.video_dir, f\"{sequence_id}.mp4\")\n",
    "        pose = self.df.iloc[i]['l3_pose']\n",
    "\n",
    "        label = torch.zeros(NUM_CLASSES)\n",
    "        label[self.pose_to_idx[pose]] = 1\n",
    "\n",
    "        frames = self.read_video_with_imageio(video_path)\n",
    "        print(frames.shape)\n",
    "        \n",
    "        return video_path, pose, label\n",
    "    \n",
    "    def read_video_with_imageio(self, video_path):\n",
    "        reader = imageio.get_reader(video_path, 'ffmpeg')\n",
    "        total_frames = reader.count_frames()\n",
    "        print(total_frames)\n",
    "        indices = np.linspace(0, total_frames-1, SEQUENCE_LENGTH, dtype=int)\n",
    "        \n",
    "        frames = []\n",
    "        for i, frame in enumerate(reader):\n",
    "            if i in indices:\n",
    "                frame = Image.fromarray(frame)\n",
    "                # Apply your transforms here\n",
    "                frame = self.transforms(frame)\n",
    "                frames.append(frame)\n",
    "        \n",
    "        reader.close()\n",
    "        frames = torch.stack([torch.tensor(np.array(f)) for f in frames])\n",
    "        return frames  \n",
    "\n",
    "    def _get_frames(self, video_path):\n",
    "        \"\"\"Load video and sample SEQUENCE_LENGTH frames.\"\"\"\n",
    "        cap = cv.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        total_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Calculate sampling indices\n",
    "        indices = np.linspace(0, total_frames-1, SEQUENCE_LENGTH, dtype=int)\n",
    "        print('Total Frames:',total_frames)\n",
    "        for frame_idx in range(total_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # cv.imshow('WIn',frame)\n",
    "            # cv.waitKey(0)\n",
    "            print(frame_idx)\n",
    "            if frame_idx in indices:\n",
    "                # Convert BGR to RGB\n",
    "                frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "                # Convert to PIL Image\n",
    "                frame = Image.fromarray(frame)\n",
    "                # Apply transforms\n",
    "                frame = self.transforms(frame)\n",
    "                frames.append(frame)\n",
    "                \n",
    "        cap.release()\n",
    "        \n",
    "        # Stack frames into tensor\n",
    "        frames = torch.stack(frames)\n",
    "        print(frames.shape)\n",
    "        return frames\n",
    "               \n",
    "        \n",
    "\n",
    "a = Dataset(csv_path, sequence_path, pose_list, video_dir)\n",
    "# a.print()\n",
    "a[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
