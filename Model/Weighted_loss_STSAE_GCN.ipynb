{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "cu0Fn1p_CZC3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "5-EmS0rvCZC4"
      },
      "outputs": [],
      "source": [
        "TEST_SPLIT = 0.1\n",
        "VAL_SPLIT = 0.2\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFsLvlE_CZC5",
        "outputId": "9f8ba21e-8810-4927-dfbf-bb9fc04735d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "data\t\t      nov16_third_run\t       nov22_DA\t\t    official_dataset\n",
            "nov16_second_run      nov16_unknown_attention  nov22_DA_longer\n",
            "nov16_test_third_run  nov20_third_run\t       nov24_weighted_loss\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "# Define base folder path\n",
        "base_path = '/content/gdrive/MyDrive/yoga_proj'\n",
        "!ls /content/gdrive/MyDrive/yoga_proj\n",
        "# base_path = '../'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "1QiOQi7BCZC5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Gets label\n",
        "csv_path = os.path.join(base_path,'data/3DYoga90_corrected.csv')\n",
        "\n",
        "SAVE_PATH = os.path.join(base_path, 'nov24_weighted_loss')\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# Classification classes\n",
        "pose_list = ['mountain', 'half-way-lift', 'standing-forward-bend', 'downward-dog']\n",
        "NUM_CLASSES = len(pose_list)\n",
        "\n",
        "dataset_dir = os.path.join(base_path, 'official_dataset')\n",
        "assert os.path.isdir(dataset_dir), f\"Directory '{dataset_dir}' does not exist.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_mVAnHmCZC6",
        "outputId": "48b253d3-e434-4151-f00a-4dfeb3941d00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SCqudip1CZC6",
        "outputId": "401c40d2-ede9-44f3-92c3-3adcff9bcbd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   level1_id level1_pose  level2_id        level2_pose  l3_pose_id   13_pose\n",
              "0          1    standing         11  standing-straight         101  mountain\n",
              "1          1    standing         11  standing-straight         102   goddess\n",
              "2          1    standing         11  standing-straight         103     eagle\n",
              "3          1    standing         11  standing-straight         104      tree\n",
              "4          1    standing         11  standing-straight         105     chair"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dba3b4e2-db96-4731-ae99-b31153562991\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level1_id</th>\n",
              "      <th>level1_pose</th>\n",
              "      <th>level2_id</th>\n",
              "      <th>level2_pose</th>\n",
              "      <th>l3_pose_id</th>\n",
              "      <th>13_pose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>standing</td>\n",
              "      <td>11</td>\n",
              "      <td>standing-straight</td>\n",
              "      <td>101</td>\n",
              "      <td>mountain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>standing</td>\n",
              "      <td>11</td>\n",
              "      <td>standing-straight</td>\n",
              "      <td>102</td>\n",
              "      <td>goddess</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>standing</td>\n",
              "      <td>11</td>\n",
              "      <td>standing-straight</td>\n",
              "      <td>103</td>\n",
              "      <td>eagle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>standing</td>\n",
              "      <td>11</td>\n",
              "      <td>standing-straight</td>\n",
              "      <td>104</td>\n",
              "      <td>tree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>standing</td>\n",
              "      <td>11</td>\n",
              "      <td>standing-straight</td>\n",
              "      <td>105</td>\n",
              "      <td>chair</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dba3b4e2-db96-4731-ae99-b31153562991')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dba3b4e2-db96-4731-ae99-b31153562991 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dba3b4e2-db96-4731-ae99-b31153562991');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1f116840-75bd-48db-8695-a59bbb44e693\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f116840-75bd-48db-8695-a59bbb44e693')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1f116840-75bd-48db-8695-a59bbb44e693 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pose_index",
              "summary": "{\n  \"name\": \"pose_index\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"level1_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level1_pose\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"standing\",\n          \"sitting\",\n          \"wheel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level2_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 11,\n        \"max\": 30,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          11,\n          28,\n          26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"level2_pose\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"standing-straight\",\n          \"wheel-up-facing\",\n          \"reclining-side-facing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"l3_pose_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 101,\n        \"max\": 190,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          141,\n          123,\n          156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"13_pose\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"shooting-bow\",\n          \"standing-big-toe-hold\",\n          \"feather-peacock\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "meta_info_path = os.path.join(base_path, 'data')\n",
        "pose_index = pd.read_csv(f'{meta_info_path}/pose-index.csv')\n",
        "sequence_index = pd.read_csv(f'{meta_info_path}/3DYoga90_corrected.csv')\n",
        "\n",
        "pose_index.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG2mAMJSCZC6",
        "outputId": "2f1b9f46-cfbd-433d-c076-09c67796d7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('downward-dog', 245), ('standing-forward-bend', 225), ('half-way-lift', 209), ('mountain', 165), ('chair', 140), ('cobra', 129), ('cockerel', 120), ('extended-triangle', 108), ('extended-side-angle', 101), ('corpse', 95), ('staff', 94), ('wind-relieving', 94), ('fish', 93), ('happy-baby', 93), ('shoulder-pressing', 92), ('reclining-cobbler', 91), ('reclining-hero', 82), ('frog', 80), ('tree', 69), ('intense-side-stretch', 59)]\n",
            "'downward-dog','standing-forward-bend','half-way-lift','mountain','chair','cobra','cockerel','extended-triangle','extended-side-angle','corpse','staff','wind-relieving','fish','happy-baby','shoulder-pressing','reclining-cobbler','reclining-hero','frog','tree','intense-side-stretch',mountain 165\n",
            "half-way-lift 209\n",
            "standing-forward-bend 225\n",
            "downward-dog 245\n",
            "high-lunge 42\n",
            "low-lunge 44\n",
            "warrior-3 47\n",
            "side-plank 48\n",
            "balancing-table 44\n",
            "child 47\n",
            "tree 69\n",
            "extended-triangle 108\n",
            "bridge 41\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1334"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "list_poses = [p for p in sequence_index['l3_pose']]\n",
        "pose_dict = dict()\n",
        "for poses in list_poses:\n",
        "    if poses in pose_dict:\n",
        "        pose_dict[poses] += 1\n",
        "    else:\n",
        "        pose_dict[poses] =1\n",
        "sorted_poses = sorted(pose_dict.items(), key= lambda item: item[1], reverse=True)\n",
        "print(sorted_poses[:20])\n",
        "for p, c in sorted_poses[:20]:\n",
        "    print(f\"'{p}'\",end=\",\")\n",
        "poses = ['mountain',\n",
        "'half-way-lift',\n",
        "'standing-forward-bend',\n",
        "'downward-dog',\n",
        "'high-lunge',\n",
        "'low-lunge',\n",
        "'warrior-3',\n",
        "'side-plank',\n",
        "'balancing-table',\n",
        "'child',\n",
        "'tree',\n",
        "'extended-triangle',\n",
        "'bridge']\n",
        "for keys in poses:\n",
        "    print(keys, pose_dict[keys])\n",
        "\n",
        "sum(map(lambda k: pose_dict[k], poses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpLOGWwACZC7"
      },
      "source": [
        "What does each file tell?\n",
        "\n",
        "1.) pose-index.csv -> Shows Heirarchical organization (THEN NOTHING MORE)\n",
        "\n",
        "2.) 3DYoga90.csv -> Total Main Info(i.e. along with RGB stream){\n",
        "    SequneceID: Parquet_FILE_NAME,\n",
        "    URL,\n",
        "    Frame Start and Frame Stop,\n",
        "    Pose Name, Training Test Split\n",
        "} `Difference between train and test? where to get the validation set from? How to do data augmentation?\n",
        "\n",
        "3.) Parquet Files -> {\n",
        "    Frame Number {\n",
        "        33 Landmarks\n",
        "    },\n",
        "    row-id: FrameNumber-TYPE-Landmark_index,\n",
        "    Coordinates: {x, y, z}\n",
        "}\n",
        "\n",
        "`PLEASE NOTE: The landmark coordinates are all normalized`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y0RRgDxCZC7"
      },
      "source": [
        "# Getting the data ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Kg3fH4QhCZC8"
      },
      "outputs": [],
      "source": [
        "the_desired_poses = [\n",
        "  'downward-dog',\n",
        "  'high-lunge',\n",
        "  'low-lunge',\n",
        "  'warrior-3',\n",
        "  'side-plank',\n",
        "  'balancing-table',\n",
        "  'child',\n",
        "  'tree',\n",
        "  'extended-triangle',\n",
        "  'bridge']\n",
        "\n",
        "# subset_of_poses = [\n",
        "#   'mountain',\n",
        "#   'downward-dog',\n",
        "#   'standing-foward-bend',\n",
        "#   'half-way-lift'\n",
        "# ]\n",
        "\n",
        "subset_of_poses = pose_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "JD1fgbe3CZC8"
      },
      "outputs": [],
      "source": [
        "# Keep only relevant columns\n",
        "def read_meta_data():\n",
        "    meta_info_path = os.path.join(base_path, 'data')\n",
        "    pose_index = pd.read_csv(f'{meta_info_path}/pose-index.csv')\n",
        "    sequence_index = pd.read_csv(f'{meta_info_path}/3DYoga90_corrected.csv')\n",
        "    parquet_index = sequence_index[['sequence_id', 'l3_pose', 'split']]\n",
        "    return parquet_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "2rYfhKBuu5Ap"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def AddGaussianNoise(data, mean=0., std=0.01):\n",
        "    noise = torch.randn_like(data) * std + mean\n",
        "    return data + noise\n",
        "\n",
        "def RandomRotate(data, max_angle=30):\n",
        "    angle = torch.rand(1) * 2 * max_angle - max_angle  # Range: [-max_angle, max_angle] in degrees\n",
        "    angle_rad = torch.deg2rad(angle)\n",
        "    cos_theta = torch.cos(angle_rad)\n",
        "    sin_theta = torch.sin(angle_rad)\n",
        "\n",
        "    rotation_matrix = torch.tensor([\n",
        "        [cos_theta, 0, sin_theta],\n",
        "        [0, 1, 0],\n",
        "        [-sin_theta, 0, cos_theta]\n",
        "    ]).squeeze()\n",
        "\n",
        "    # print(data.shape)\n",
        "    # print(rotation_matrix.shape)\n",
        "    # data = torch.matmul(rotation_matrix, data)\n",
        "    data = torch.einsum('ij, jkl -> ikl', rotation_matrix, data)\n",
        "    return data\n",
        "\n",
        "def RandomScale(data, scale_range=(0.9, 1.1)):\n",
        "    scale =  scale_range[0] + torch.rand(1) * (scale_range[1] - scale_range[0]) # 0.9 + 0.2 * percentage\n",
        "    return data * scale\n",
        "\n",
        "def RandomTranslate(data, max_translate=0.1):\n",
        "    translate = torch.rand(3) * 2 * max_translate - max_translate  # Range: [-max_translate, max_translate]\n",
        "    return data + translate.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "def TimeReverse(data, p=0.5):\n",
        "    if torch.rand(1) < p:\n",
        "        return torch.flip(data, [1])\n",
        "    else:\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "zaw3MmIFCZC8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class Yoga3DDataset(Dataset):\n",
        "    def __init__(self, parquet_index, root_dir =  dataset_dir,subset_of_poses= subset_of_poses, sub_sampling_length = 20, transform=None, max_frames=None):\n",
        "        self.parquet_index = parquet_index\n",
        "        self.parquet_index = self.parquet_index[self.parquet_index['l3_pose'].isin(subset_of_poses)]\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.max_frames = max_frames\n",
        "        self.sub_sampling_length = sub_sampling_length\n",
        "        self.pose_to_label = {pose: i for i, pose in enumerate(subset_of_poses)}\n",
        "        self.use_augmentation = False\n",
        "\n",
        "        self.cache = dict()\n",
        "        self.idx_to_seq = dict()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.parquet_index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx in self.cache:\n",
        "            data, label = self.cache[idx]\n",
        "        else:\n",
        "            fname, pose_name, _ = self.parquet_index.iloc[idx]\n",
        "            label = self.pose_to_label[pose_name]\n",
        "\n",
        "\n",
        "            path = os.path.join(self.root_dir, f'{fname}.parquet')\n",
        "\n",
        "            df = pd.read_parquet(path)\n",
        "            df = df.drop(columns=['frame', 'row_id', 'type','landmark_index'])\n",
        "\n",
        "            data = self.to_tensor(df)\n",
        "            data = self.sub_sample(data)\n",
        "            data = data.permute(1,0,2)\n",
        "            self.cache[idx] = (data, label)\n",
        "            self.idx_to_seq[idx] = fname\n",
        "\n",
        "        if self.transform and self.use_augmentation:\n",
        "            data = self.transform(data.clone())\n",
        "\n",
        "        return data, label # C, T , V\n",
        "\n",
        "    def sub_sample(self, data):\n",
        "        # data(Number_of_frames, 3, 33)\n",
        "        total_frames = data.shape[0]\n",
        "        indices = torch.linspace(0, total_frames -1 , self.sub_sampling_length, dtype= int)\n",
        "        return data[indices]\n",
        "\n",
        "    def to_tensor(self, df):\n",
        "        # Reshape the data to (num_frames, num_landmarks, 3)  ## WHAT WHAT? this doesn't make sense remove this line you are doing (number of frames, 3 , 33)\n",
        "        num_frames = len(df) // 33  # Assuming 33 landmarks per frame\n",
        "        data = df.values.reshape(num_frames, 33, 3)\n",
        "        return torch.FloatTensor(data).permute(0, 2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "BFttuAX3u5Aq"
      },
      "outputs": [],
      "source": [
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, data):\n",
        "        for transform in self.transforms:\n",
        "            data = transform(data)\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "V5QKB0vju5Aq"
      },
      "outputs": [],
      "source": [
        "class RandomApply:\n",
        "    def __init__(self, transform, p=0.5):\n",
        "        self.transform = transform\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, data):\n",
        "        if torch.rand(1) < self.p:\n",
        "            return self.transform(data)\n",
        "        else:\n",
        "            return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "x8-j_6zmCZC8"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class AGCN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(AGCN, self).__init__()\n",
        "\n",
        "        # Initialize adjacency matrix for BlazePose (33 joints)\n",
        "        self.num_nodes = 33\n",
        "        # Define the natural connections in BlazePose skeleton\n",
        "        self.edges = [\n",
        "            # Torso\n",
        "            (11, 12), (12, 24), (24, 23), (23, 11),  # shoulders to hips\n",
        "            # Right arm\n",
        "            (12, 14), (14, 16), (16, 18), (18, 20), (20, 22),  # shoulder to fingertip\n",
        "            # Left arm\n",
        "            (11, 13), (13, 15), (15, 17), (17, 19), (19, 21),  # shoulder to fingertip\n",
        "            # Right leg\n",
        "            (24, 26), (26, 28), (28, 30), (30, 32),  # hip to foot\n",
        "            # Left leg\n",
        "            (23, 25), (25, 27), (27, 29), (29, 31),  # hip to foot\n",
        "            # Face\n",
        "            (0, 1), (1, 2), (2, 3), (3, 7),  # right eye\n",
        "            (0, 4), (4, 5), (5, 6), (6, 8),  # left eye\n",
        "            (9, 10),  # mouth\n",
        "            # Add connections to nose (0) from shoulders\n",
        "            # (0, 11), (0, 12)  # do we include this connection dear friend?\n",
        "        ]\n",
        "\n",
        "        # Create adjacency matrix\n",
        "        A = np.zeros((self.num_nodes, self.num_nodes))\n",
        "        for i, j in self.edges:\n",
        "            A[i, j] = 1\n",
        "            A[j, i] = 1  # Undirected graph\n",
        "\n",
        "        # Convert to tensor and make it a parameter\n",
        "        self.A = nn.Parameter(torch.from_numpy(A.astype(np.float32)))\n",
        "\n",
        "        # Create identity matrix\n",
        "        self.identity = nn.Parameter(torch.eye(self.num_nodes), requires_grad=False)\n",
        "\n",
        "        # 1x1 convolution for feature transformation\n",
        "        self.W = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Compute degree matrix\n",
        "        D = torch.sum(self.A, dim=1)\n",
        "        D = torch.diag(torch.pow(D, -0.5))\n",
        "        # D_r = torch.diag(torch.pow(D, 0.5))\n",
        "\n",
        "        # Normalized adjacency matrix\n",
        "        A_norm = torch.matmul(torch.matmul(D, self.A + self.identity), D)\n",
        "\n",
        "        # Reshape input for matrix multiplication\n",
        "        # N, C, T, V = x.size()\n",
        "        x_reshape = x.permute(0, 2, 3, 1).contiguous()  # N, T, V, C\n",
        "        # Apply GCN operation\n",
        "        x_gc = torch.matmul(A_norm, x_reshape)  # N, T, V, C\n",
        "\n",
        "        # Reshape back\n",
        "        x_gc = x_gc.permute(0, 3, 1, 2).contiguous()  # N, C, T, V\n",
        "\n",
        "        # Apply 1x1 convolution\n",
        "        out = self.W(x_gc)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Wtn_mpv9CZC8"
      },
      "outputs": [],
      "source": [
        "# agcn = AGCN(3, 64)\n",
        "# D = torch.sum(agcn.A, dim=1)\n",
        "# D = torch.diag(torch.pow(D, -0.5))\n",
        "# A_norm = torch.matmul(torch.matmul(D, agcn.A + agcn.identity), D)\n",
        "# # A_norm\n",
        "# agcn.A.shape\n",
        "# D.shape\n",
        "# torch.matmul(torch.matmul(D, agcn.A + agcn.identity), D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn5818CLCZC8"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "CNv13nUNCZC9"
      },
      "outputs": [],
      "source": [
        "class STSAM(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(STSAM, self).__init__()\n",
        "\n",
        "        # 1x1 convolutions for Q, K, V\n",
        "        self.query_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "\n",
        "        # 1x1 convolutions for scaling attention maps\n",
        "        self.Ws = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
        "        self.Wt = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, T, V = x.size()\n",
        "\n",
        "        # Generate Q, K, V\n",
        "        Q = self.query_conv(x)\n",
        "        K = self.key_conv(x)\n",
        "        V = self.value_conv(x)\n",
        "\n",
        "        # Spatial attention\n",
        "        Qs = torch.mean(Q, dim=2, keepdim=True)  # (N, C, 1, V)\n",
        "        Ks = torch.mean(K, dim=2, keepdim=True)  # (N, C, 1, V)\n",
        "        Vs = torch.mean(V, dim=2, keepdim=True)  # (N, C, 1, V)\n",
        "\n",
        "        # Temporal attention\n",
        "        Qt = torch.mean(Q, dim=3, keepdim=True)  # (N, C, T, 1)\n",
        "        Kt = torch.mean(K, dim=3, keepdim=True)  # (N, C, T, 1)\n",
        "        Vt = torch.mean(V, dim=3, keepdim=True)  # (N, C, T, 1)\n",
        "\n",
        "        # Compute attention maps\n",
        "        Ms = torch.matmul(Qs.transpose(2, 3), Ks) / torch.sqrt(torch.tensor(C, dtype=torch.float))  # Spatial attention\n",
        "        Ms = torch.softmax(Ms, dim=-1)\n",
        "        Ms = torch.matmul(Ms, Vs.transpose(2, 3)).transpose(2, 3)\n",
        "\n",
        "        Mt = torch.matmul(Qt.transpose(2, 3), Kt) / torch.sqrt(torch.tensor(C, dtype=torch.float))  # Temporal attention\n",
        "        Mt = torch.softmax(Mt, dim=-1)\n",
        "        Mt = torch.matmul(Mt, Vt.transpose(2, 3)).transpose(2, 3)\n",
        "\n",
        "        # Scale attention maps\n",
        "        Ms1 = torch.sigmoid(self.Ws(Ms))  # (N, 1, 1, V)\n",
        "        Mt1 = torch.sigmoid(self.Wt(Mt))  # (N, 1, T, 1)\n",
        "\n",
        "        # Apply attention with residual connections\n",
        "        out = (x + x * Ms1) + (x + x * Mt1)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "bnCm6QuhCZC9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MTCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=None):\n",
        "        super(MTCN, self).__init__()\n",
        "\n",
        "        # If hidden_channels not specified, make it divisible by 6\n",
        "        if hidden_channels is None:\n",
        "            hidden_channels = in_channels - (in_channels % 6)\n",
        "\n",
        "        assert hidden_channels % 6 == 0, \"var: hidden_channels should always be multple of 6 because 6 branches\"\n",
        "\n",
        "        self.branch_channels = hidden_channels // 6\n",
        "\n",
        "        # Initial 1x1 conv to reduce channels\n",
        "        self.init_conv = nn.Conv2d(\n",
        "            in_channels,\n",
        "            hidden_channels,\n",
        "            kernel_size=1\n",
        "        )\n",
        "\n",
        "        # Branch 1: 1x1 Conv\n",
        "        self.branch1 = nn.Conv2d(\n",
        "            hidden_channels,\n",
        "            self.branch_channels,\n",
        "            kernel_size=1\n",
        "        )\n",
        "\n",
        "        # Branch 2: Max Pooling followed by 1x1 Conv to adjust channels\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=(1, 3), padding=(0, 1), stride=1),\n",
        "            nn.Conv2d(hidden_channels, self.branch_channels, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        # Branches 3-6: 1D Conv with different dilations\n",
        "        self.branches = nn.ModuleList([\n",
        "            nn.Conv2d(\n",
        "                hidden_channels,\n",
        "                self.branch_channels,\n",
        "                kernel_size=(1, 3),\n",
        "                padding=(0, dilation),\n",
        "                dilation=(1, dilation)\n",
        "            ) for dilation in range(1, 5)\n",
        "        ])\n",
        "\n",
        "        # Final 1x1 conv to restore original channel count\n",
        "        self.final_conv = nn.Conv2d(hidden_channels, in_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, C, V, T)\n",
        "\n",
        "        # Initial channel reduction\n",
        "        x = self.init_conv(x)\n",
        "\n",
        "        # Process each branch\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "\n",
        "        # Process dilated convolution branches\n",
        "        branch_outputs = [branch1, branch2]\n",
        "        for branch in self.branches:\n",
        "            branch_outputs.append(branch(x))\n",
        "\n",
        "        # Concatenate all branch outputs\n",
        "        x = torch.cat(branch_outputs, dim=1)\n",
        "\n",
        "        # Final 1x1 conv\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "EfgmXSoiCZC9"
      },
      "outputs": [],
      "source": [
        "\n",
        "class STSAE_GCN_Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(STSAE_GCN_Block, self).__init__()\n",
        "        self.agcn = AGCN(in_channels, out_channels)\n",
        "        self.stsam = STSAM(out_channels)\n",
        "        self.mtcn = MTCN(out_channels, 48)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.agcn(x)\n",
        "        x = self.stsam(x)\n",
        "        x = self.mtcn(x)\n",
        "        return x\n",
        "\n",
        "class STSAE_GCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, num_classes, num_frames, num_blocks=9):\n",
        "        super(STSAE_GCN, self).__init__()\n",
        "        self.num_blocks = num_blocks\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            STSAE_GCN_Block(in_channels if i == 0 else hidden_channels,\n",
        "                            hidden_channels)\n",
        "            for i in range(num_blocks)\n",
        "        ])\n",
        "        num_nodes = 33\n",
        "        self.fc = nn.Linear(hidden_channels * num_nodes * num_frames, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, in_channels, num_frames, num_nodes)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Global average pooling\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def count_parameters(self):\n",
        "        total_params = 0\n",
        "        for name, parameter in self.named_parameters():\n",
        "            if parameter.requires_grad:\n",
        "                params = parameter.numel()\n",
        "                print(f\"{name}: {params}\")\n",
        "                total_params += params\n",
        "        print(f\"Total Trainable Params: {total_params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "GFgBfmOSCZC9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "def save_checkpoint(model, optimizer, epoch, history, save_path = SAVE_PATH, best_path=None):\n",
        "    if best_path is not None:\n",
        "        chk_path = os.path.join(save_path, f'best_model.pth')\n",
        "        print(f\"Saving checkpoint to {chk_path}\")\n",
        "    else:\n",
        "        chk_path = os.path.join(save_path, f'checkpath_model.pth')\n",
        "        print(f\"Saving checkpoint to {chk_path}\")\n",
        "\n",
        "    # Combine model, optimizer, and history into one dictionary\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,  # Save the next epoch number for resuming\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'history': history  # Save history along with the model and optimizer\n",
        "    }\n",
        "\n",
        "    # Save everything in a single file using torch.save\n",
        "    torch.save(checkpoint, chk_path)\n",
        "    print(f\"Checkpoint saved at epoch {epoch + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "mZprkJQvCZC9"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(model, optimizer, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Load model and training state from a checkpoint\n",
        "    \"\"\"\n",
        "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path, weights_only = False)\n",
        "\n",
        "    # Load model and optimizer states\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    # Get the epoch number to resume from\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "    # Load training history with new metrics\n",
        "    history = checkpoint.get('history', {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_acc': [], 'val_acc': [],\n",
        "        'train_precision': [], 'train_recall': [], 'train_f1': [],\n",
        "        'val_precision': [], 'val_recall': [], 'val_f1': [],\n",
        "        'learning_rates': []\n",
        "    })\n",
        "\n",
        "    return model, optimizer, start_epoch, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "dkDP9PAlCZC9"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
        "    def __init__(self, patience=7, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        # on default = 7 successive val_loss increase stop\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "nNTAFuncCZC9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, dataset, num_epochs=50, patience=18, log_interval=10, checkpoint_path=None, unfreeze_epoch=5, num_layers_unfreeze=3):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4)\n",
        "\n",
        "    # Initialize early stopping\n",
        "    early_stopping = EarlyStopping(patience=patience, min_delta=1e-4)\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # Initialize history for loss, accuracy, precision, recall, and F1\n",
        "    history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_acc': [], 'val_acc': [],\n",
        "        'train_precision': [], 'train_recall': [], 'train_f1': [],\n",
        "        'val_precision': [], 'val_recall': [], 'val_f1': [],\n",
        "        'learning_rates': []\n",
        "    }\n",
        "\n",
        "    # Check for checkpoint and load if available\n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        model, optimizer, start_epoch, history = load_checkpoint(model, optimizer, checkpoint_path)\n",
        "        print(f\"Resuming training from epoch {start_epoch}\")\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        dataset.use_augmentation = True\n",
        "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        history['learning_rates'].append(current_lr)\n",
        "        print(f\"Current Learning Rate: {current_lr}\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
        "        train_true, train_pred = [], []\n",
        "\n",
        "        train_loader_tqdm = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n",
        "        for batch_idx, (inputs, labels) in train_loader_tqdm:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)  # Pass sequence lengths to model forward function\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "\n",
        "            # Collect true and predicted labels for precision/recall\n",
        "            train_true.extend(labels.cpu().numpy())\n",
        "            train_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "            # Log batch-level updates\n",
        "            if batch_idx % log_interval == 0:\n",
        "                train_loader_tqdm.set_postfix({\n",
        "                    'loss': train_loss / (BATCH_SIZE * (batch_idx + 1)),\n",
        "                    'accuracy': 100.0 * train_correct / train_total\n",
        "                })\n",
        "\n",
        "        # Calculate training metrics\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = 100.0 * train_correct / train_total\n",
        "        train_precision = precision_score(train_true, train_pred, average='weighted')\n",
        "        train_recall = recall_score(train_true, train_pred, average='weighted')\n",
        "        train_f1 = f1_score(train_true, train_pred, average='weighted')\n",
        "\n",
        "        dataset.use_augmentation = False\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        val_true, val_pred = [], []\n",
        "\n",
        "        val_loader_tqdm = tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validation\")\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, labels) in val_loader_tqdm:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)  # Pass sequence lengths to model forward function\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "                # Collect true and predicted labels for precision/recall\n",
        "                val_true.extend(labels.cpu().numpy())\n",
        "                val_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "                # Log batch-level updates for validation\n",
        "                if batch_idx % log_interval == 0:\n",
        "                    val_loader_tqdm.set_postfix({\n",
        "                        'loss': val_loss / (BATCH_SIZE * (batch_idx + 1)),\n",
        "                        'accuracy': 100.0 * val_correct / val_total\n",
        "                    })\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = 100.0 * val_correct / val_total\n",
        "        val_precision = precision_score(val_true, val_pred, average='weighted')\n",
        "        val_recall = recall_score(val_true, val_pred, average='weighted')\n",
        "        val_f1 = f1_score(val_true, val_pred, average='weighted')\n",
        "\n",
        "        # Update history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['train_precision'].append(train_precision)\n",
        "        history['train_recall'].append(train_recall)\n",
        "        history['train_f1'].append(train_f1)\n",
        "        history['val_precision'].append(val_precision)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['val_f1'].append(val_f1)\n",
        "\n",
        "        # Print metrics at the end of the epoch\n",
        "        print(f'\\nEpoch {epoch + 1}/{num_epochs} Summary:')\n",
        "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Train Precision: {train_precision:.2f} | Train Recall: {train_recall:.2f} | Train F1: {train_f1:.2f}')\n",
        "        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | Val Precision: {val_precision:.2f} | Val Recall: {val_recall:.2f} | Val F1: {val_f1:.2f}')\n",
        "\n",
        "        # Save the best model checkpoint\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_path = os.path.join(SAVE_PATH, 'best_model.pth')\n",
        "            if best_model_path is not None:\n",
        "                print(best_model_path)\n",
        "            save_checkpoint(model, optimizer, epoch, history, SAVE_PATH, best_model_path)\n",
        "            print(f\"New best model saved! Validation Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        # Adjust learning rate based on validation loss\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Check for early stopping\n",
        "        early_stopping(val_loss)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    return model, history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "yjp-JMKQCZC-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion, class_names,spath=SAVE_PATH, fsave='confusion_matrix.png'):\n",
        "    \"\"\"\n",
        "    Evaluate model on test set\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        test_loader: DataLoader for test data\n",
        "        criterion: Loss function\n",
        "        class_names: List of class names\n",
        "        save_path: Directory to save the plot\n",
        "        fsave: Filename for confusion matrix plot\n",
        "    \"\"\"\n",
        "    csave = os.path.join(spath, fsave)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Create progress bar\n",
        "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader_tqdm:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            # Get predictions\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            # Calculate accuracy\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "            test_total += labels.size(0)\n",
        "\n",
        "            # Store predictions and labels for confusion matrix\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    accuracy = 100 * test_correct / test_total\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(csave)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "7EWkYX8sCZC-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "def train_val_test_split(dataset, test_split = TEST_SPLIT, val_split= VAL_SPLIT):\n",
        "    total_size = len(dataset)\n",
        "    test_size = int(test_split * total_size)\n",
        "    val_size = int(val_split * total_size)\n",
        "    train_size = total_size - val_size - test_size\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(\n",
        "        dataset,\n",
        "        [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
        "    )\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "def create_data_loaders(train_dataset, val_dataset, test_dataset, batch_size = BATCH_SIZE):\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        # num_workers=2,\n",
        "        pin_memory= True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        # num_workers=2,\n",
        "        pin_memory= True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        # num_workers=2\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "-nVQoc_DCZC-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_training_curves(history, fsave='training_curves.png'):\n",
        "    tsave = os.path.join(SAVE_PATH, fsave)\n",
        "    # plt.style.use('seaborn')\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "    # Loss curves\n",
        "    axs[0, 0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "    axs[0, 0].plot(history['val_loss'], label='Validation Loss', marker='o')\n",
        "    axs[0, 0].set_title('Loss')\n",
        "    axs[0, 0].legend()\n",
        "\n",
        "    # Accuracy curves\n",
        "    axs[0, 1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
        "    axs[0, 1].plot(history['val_acc'], label='Validation Accuracy', marker='o')\n",
        "    axs[0, 1].set_title('Accuracy')\n",
        "    axs[0, 1].legend()\n",
        "\n",
        "    # Learning rate\n",
        "    axs[0, 2].plot(history['learning_rates'], label='Learning Rate', marker='o')\n",
        "    axs[0, 2].set_title('Learning Rate')\n",
        "    axs[0, 2].set_yscale('log')\n",
        "    axs[0, 2].legend()\n",
        "\n",
        "    # Precision\n",
        "    axs[1, 0].plot(history['train_precision'], label='Train Precision', marker='o')\n",
        "    axs[1, 0].plot(history['val_precision'], label='Validation Precision', marker='o')\n",
        "    axs[1, 0].set_title('Precision')\n",
        "    axs[1, 0].legend()\n",
        "\n",
        "    # Recall\n",
        "    axs[1, 1].plot(history['train_recall'], label='Train Recall', marker='o')\n",
        "    axs[1, 1].plot(history['val_recall'], label='Validation Recall', marker='o')\n",
        "    axs[1, 1].set_title('Recall')\n",
        "    axs[1, 1].legend()\n",
        "\n",
        "    # F1 Score\n",
        "    axs[1, 2].plot(history['train_f1'], label='Train F1', marker='o')\n",
        "    axs[1, 2].plot(history['val_f1'], label='Validation F1', marker='o')\n",
        "    axs[1, 2].set_title('F1 Score')\n",
        "    axs[1, 2].legend()\n",
        "\n",
        "    for ax in axs.flat:\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(tsave)\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "7LXXcX28u5Ar"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from collections import Counter\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "def get_class_weights(pose_list, num_classes, strategy='balanced'):\n",
        "    \"\"\"\n",
        "    Calculate class weights with proper class index alignment.\n",
        "\n",
        "    Args:\n",
        "        pose_list: List of labels/poses in the dataset\n",
        "        num_classes: Total number of classes\n",
        "        strategy: Weighting strategy ('balanced', 'inverse', 'effective_samples', 'sqrt_inverse')\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Class weights tensor aligned with class indices\n",
        "    \"\"\"\n",
        "    # Count samples per class\n",
        "    class_counts = Counter(pose_list)\n",
        "    total_samples = len(pose_list)\n",
        "\n",
        "    # Initialize weights array with zeros for all possible classes\n",
        "    weights = np.zeros(num_classes)\n",
        "\n",
        "    if strategy == 'balanced':\n",
        "        # Use sklearn's balanced weighting\n",
        "        unique_classes = sorted(class_counts.keys())\n",
        "        sklearn_weights = compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=np.array(unique_classes),\n",
        "            y=pose_list\n",
        "        )\n",
        "        # Map weights to correct indices\n",
        "        for idx, class_label in enumerate(unique_classes):\n",
        "            weights[class_label] = sklearn_weights[idx]\n",
        "\n",
        "    elif strategy == 'inverse':\n",
        "        # Inverse of sample frequency\n",
        "        for class_label, count in class_counts.items():\n",
        "            weights[class_label] = total_samples / (num_classes * count)\n",
        "\n",
        "    elif strategy == 'effective_samples':\n",
        "        # Effective number of samples weighting\n",
        "        beta = 0.9999\n",
        "        for class_label, count in class_counts.items():\n",
        "            weights[class_label] = (1 - beta) / (1 - beta ** count)\n",
        "\n",
        "    elif strategy == 'sqrt_inverse':\n",
        "        # Square root of inverse frequency\n",
        "        for class_label, count in class_counts.items():\n",
        "            weights[class_label] = np.sqrt(total_samples / (num_classes * count))\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown weighting strategy: {strategy}\")\n",
        "\n",
        "    # Convert to tensor and normalize\n",
        "    weights = torch.FloatTensor(weights)\n",
        "    weights = weights / weights.sum() * len(weights)\n",
        "\n",
        "    return weights\n",
        "\n",
        "def create_weighted_criterion(pose_list, num_classes, strategy='balanced'):\n",
        "    \"\"\"\n",
        "    Create a weighted CrossEntropyLoss criterion.\n",
        "\n",
        "    Args:\n",
        "        pose_list: List of labels/poses in the dataset\n",
        "        num_classes: Total number of classes\n",
        "        strategy: Weighting strategy for calculating class weights\n",
        "\n",
        "    Returns:\n",
        "        nn.CrossEntropyLoss: Weighted loss criterion\n",
        "    \"\"\"\n",
        "    weights = get_class_weights(pose_list, num_classes, strategy)\n",
        "    print(\"Class weights aligned with indices:\", weights)\n",
        "    if torch.cuda.is_available():\n",
        "        weights = weights.cuda()\n",
        "    return nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "def analyze_class_distribution(pose_list):\n",
        "    \"\"\"\n",
        "    Analyze and print class distribution information.\n",
        "\n",
        "    Args:\n",
        "        pose_list: List of labels/poses in the dataset\n",
        "    \"\"\"\n",
        "    class_counts = Counter(pose_list)\n",
        "    total_samples = len(pose_list)\n",
        "\n",
        "    print(\"\\nClass Distribution Analysis:\")\n",
        "    print(\"-\" * 50)\n",
        "    for class_idx, count in sorted(class_counts.items()):\n",
        "        percentage = (count / total_samples) * 100\n",
        "        print(f\"Class {class_idx}: {count} samples ({percentage:.2f}%)\")\n",
        "\n",
        "    # Calculate imbalance metrics\n",
        "    max_count = max(class_counts.values())\n",
        "    min_count = min(class_counts.values())\n",
        "    imbalance_ratio = max_count / min_count\n",
        "\n",
        "    print(\"\\nImbalance Statistics:\")\n",
        "    print(f\"Imbalance Ratio (max/min): {imbalance_ratio:.2f}\")\n",
        "    print(f\"Maximum class size: {max_count}\")\n",
        "    print(f\"Minimum class size: {min_count}\")\n",
        "    print(f\"Average class size: {total_samples/len(class_counts):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "KaE3iYzvCZC-"
      },
      "outputs": [],
      "source": [
        "def main(in_channels = 3, hidden_channels= 64, num_classes= NUM_CLASSES, num_frames= 20, LR = 0.0001, Epochs =50):\n",
        "    transforms = Compose([\n",
        "        RandomApply(AddGaussianNoise, p=0.5),\n",
        "        RandomApply(RandomRotate, p=0.5),\n",
        "        RandomApply(RandomScale, p=0.5),\n",
        "        RandomApply(RandomTranslate, p=0.5),\n",
        "        # TimeReverse(p=0.5)\n",
        "        # Normalize,\n",
        "    ])\n",
        "\n",
        "    dataset = Yoga3DDataset(read_meta_data(), transform=transforms)\n",
        "    train_dataset, val_dataset, test_dataset = train_val_test_split(dataset)\n",
        "    train_loader, val_loader, test_loader = create_data_loaders(train_dataset, val_dataset, test_dataset)\n",
        "\n",
        "    print(\"start\")\n",
        "    all_labels = [dataset[i][1] for i in range(len(dataset))]\n",
        "    print(\"Finished\")\n",
        "    analyze_class_distribution(all_labels)\n",
        "\n",
        "    # Create weighted loss criterion\n",
        "    criterion = create_weighted_criterion(\n",
        "        all_labels,\n",
        "        num_classes= NUM_CLASSES,\n",
        "        strategy='effective_samples'  # Try different strategies\n",
        "    )\n",
        "    model = STSAE_GCN(in_channels, hidden_channels, num_classes, num_frames)\n",
        "    # criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "\n",
        "    print(\"Training the model\")\n",
        "    checkpoint_path = os.path.join(SAVE_PATH, 'best_model.pth')\n",
        "\n",
        "    model, history = train_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        dataset,\n",
        "        Epochs,\n",
        "        patience=20,\n",
        "        log_interval=1,\n",
        "        checkpoint_path=None\n",
        "    )\n",
        "    # Plot the training curves\n",
        "    plot_training_curves(history)\n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "            model, optimizer, start_epoch, history = load_checkpoint(\n",
        "                model, optimizer, checkpoint_path\n",
        "            )\n",
        "            print(f\"Resuming training from epoch {start_epoch}\")\n",
        "    evaluate_model(model, test_loader, criterion, pose_list)\n",
        "\n",
        "    model_save_path = os.path.join(SAVE_PATH, 'my_model.pth')\n",
        "    torch.save(model.state_dict(), model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "GpaMPADECZC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "10b76499-37cb-4a46-e24b-be67d4c2d634"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "TimeReverse() missing 1 required positional argument: 'data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-972361fa1b80>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-107-f251ea19db95>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(in_channels, hidden_channels, num_classes, num_frames, LR, Epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mRandomApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomScale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mRandomApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomTranslate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mTimeReverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Normalize,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     ])\n",
            "\u001b[0;31mTypeError\u001b[0m: TimeReverse() missing 1 required positional argument: 'data'"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "zNhSc5nau5Ar"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "\n",
        "def find_sus(model, test_loader, criterion, class_names, spath=SAVE_PATH, fsave='confusion_matrix_all.png'):\n",
        "    \"\"\"\n",
        "    Evaluate model on test set\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        test_loader: DataLoader for test data\n",
        "        criterion: Loss function\n",
        "        class_names: List of class names\n",
        "        save_path: Directory to save the plot\n",
        "        fsave: Filename for confusion matrix plot\n",
        "    \"\"\"\n",
        "    csave = os.path.join(spath, fsave)\n",
        "    sussave = os.path.join(spath, 'sus.csv')\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    misclassified_data = []\n",
        "\n",
        "    # Create progress bar\n",
        "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(test_loader_tqdm):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            # Get predictions\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            # Calculate accuracy\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "            test_total += labels.size(0)\n",
        "\n",
        "            # Store predictions and labels for confusion matrix\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Check if the sample is misclassified\n",
        "            misclassified_indices = (predicted != labels).nonzero(as_tuple=True)[0]\n",
        "            for misclassified_idx in misclassified_indices:\n",
        "                global_idx = batch_idx * inputs.size(0) + misclassified_idx.item()\n",
        "                sequence_id = test_loader.dataset.idx_to_seq[global_idx]\n",
        "                correct_label = class_names[labels[misclassified_idx].item()]\n",
        "                prediction = class_names[predicted[misclassified_idx].item()]\n",
        "                misclassified_data.append([sequence_id, correct_label, prediction])\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    accuracy = 100 * test_correct / test_total\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=pose_list, yticklabels=pose_list)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(csave)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # Save misclassified data to CSV\n",
        "    with open(sussave, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['sequence_id', 'correct_label', 'prediction'])\n",
        "        writer.writerows(misclassified_data)\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "id": "60euC5Fmu5As",
        "outputId": "9ededd84-3a72-4ac1-aff8-c978fc73b0d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights aligned with indices: tensor([1.2515, 0.9880, 0.9177, 0.8428])\n",
            "Loading checkpoint from /content/gdrive/MyDrive/yoga_proj/nov24_weighted_loss/best_model.pth\n",
            "Resuming training from epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|| 53/53 [00:01<00:00, 39.62it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1457\n",
            "Test Accuracy: 96.33%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.14573716442321397, 96.32701421800948)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "dataset = Yoga3DDataset(read_meta_data())\n",
        "label_to_pose = {v:k for k,v in dataset.pose_to_label.items()}\n",
        "\n",
        "model = STSAE_GCN(3, 64, 4, 20)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "all_labels = [dataset[i][1] for i in range(len(dataset))]\n",
        "criterion = create_weighted_criterion(\n",
        "        all_labels,\n",
        "        num_classes= NUM_CLASSES,\n",
        "        strategy='inverse'  # Try different strategies\n",
        "    )\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "checkpoint_path = os.path.join(SAVE_PATH, 'best_model.pth')\n",
        "# Plot the training curves\n",
        "if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        model, optimizer, start_epoch, history = load_checkpoint(\n",
        "            model, optimizer, checkpoint_path\n",
        "        )\n",
        "        print(f\"Resuming training from epoch {start_epoch}\")\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "# plot_training_curves(history)\n",
        "find_sus(model, loader, criterion, label_to_pose)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1dkqFDp2y5HK"
      },
      "execution_count": 97,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}