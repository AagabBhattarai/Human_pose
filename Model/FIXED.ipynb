{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEcYREdIKc3_",
        "outputId": "9a2e61c1-27fc-43ca-a393-e84b555d2a04"
      },
      "outputs": [],
      "source": [
        "# %pip install opencv-python\n",
        "%pip install imageio[ffmpeg]\n",
        "%pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve64pLu4Kc4F",
        "outputId": "baaa6d88-743c-4769-cbe3-33a7e715920c"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "# Define base folder path\n",
        "base_path = '/content/gdrive/MyDrive/RGB_data_stream'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgF2d1uVKc4G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "csv_path = os.path.join(base_path,'data/3DYoga90.csv')\n",
        "sequence_path = os.path.join(base_path, 'short/downloaded_log.txt')\n",
        "save_path = os.path.join(base_path, 'mobile_net_nov2')\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "pose_list = ['mountain', 'half-way-lift', 'standing-forward-bend', 'downward-dog']\n",
        "NUM_CLASSES = len(pose_list)\n",
        "video_dir = os.path.join(base_path, 'short')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4o0CzWLKc4H"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "FRAME_HEIGHT = 224  # VGG16 input size\n",
        "FRAME_WIDTH = 224\n",
        "SEQUENCE_LENGTH = 16\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.001\n",
        "VALIDATION_SPLIT = 0.2\n",
        "TEST_SPLIT = 0.1\n",
        "NUM_EPOCHS = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxUMJ-OkKc4H"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "Work Left\n",
        "1. Data Augmentation\n",
        "2. Expanding to more classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-weN6y5Kc4J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import imageio\n",
        "\n",
        "class YogaVideoDataset(Dataset):\n",
        "    def __init__(self, csv_path, sequence_path, pose_list, video_dir):\n",
        "        with open(sequence_path) as f:\n",
        "            sequence_list = f.read().splitlines()\n",
        "            sequence_list = [int(x) for x in sequence_list]\n",
        "\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        # Keep only downloaded sequences\n",
        "        self.df = self.df[self.df['sequence_id'].isin(sequence_list)]\n",
        "        # Keep only required classes\n",
        "        self.df = self.df[self.df['l3_pose'].isin(pose_list)]\n",
        "\n",
        "        self.pose_to_idx = {pose: idx for idx, pose in enumerate(pose_list)}\n",
        "\n",
        "        self.length_of_dataset = len(self.df)\n",
        "\n",
        "        self.video_dir = video_dir\n",
        "\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.Resize((FRAME_HEIGHT, FRAME_WIDTH)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                              std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_of_dataset\n",
        "\n",
        "    def print(self):\n",
        "        print(len(self.df))\n",
        "        print(self.pose_to_idx)\n",
        "        print(len(self))\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        sequence_id = self.df.iloc[i]['sequence_id']\n",
        "        # print(sequence_id)\n",
        "        video_path = os.path.join(self.video_dir, f\"{sequence_id}.mp4\")\n",
        "        pose = self.df.iloc[i]['l3_pose']\n",
        "\n",
        "        label = self.pose_to_idx[pose]\n",
        "\n",
        "        frames = self._get_frames(video_path)\n",
        "        # print(frames.shape)\n",
        "\n",
        "        return frames, label\n",
        "\n",
        "    def _get_frames(self, video_path):\n",
        "        reader = imageio.get_reader(video_path, 'ffmpeg')\n",
        "        total_frames = reader.count_frames()\n",
        "        # print(total_frames)\n",
        "        indices = np.linspace(0, total_frames-1, SEQUENCE_LENGTH, dtype=int)\n",
        "\n",
        "        frames = []\n",
        "        for i, frame in enumerate(reader):\n",
        "            if i in indices:\n",
        "                frame = Image.fromarray(frame)\n",
        "                frame = self.transforms(frame)\n",
        "                frames.append(frame)\n",
        "\n",
        "        reader.close()\n",
        "        frames = torch.stack([torch.tensor(np.array(f)) for f in frames])\n",
        "        return frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U4u_UQWKc4K"
      },
      "source": [
        "# Model\n",
        "``` (mobile_net to get feature map and LSTM to go through the frame sequences)```\n",
        "Trying out average of LSTM from each time_step\n",
        "Work Left\n",
        "1. Using only last time step output from LSTM to using average value, max value, using attention mechanism\n",
        "2. Using other imagenet model to extract the feature map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taCxNt4YKc4K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNLSTM(nn.Module):\n",
        "    def __init__(self, num_classes, lstm_hidden_size=512, lstm_layers=2, dropout=0.5):\n",
        "        super(CNNLSTM, self).__init__()\n",
        "\n",
        "        # Load pretrained MobileNetV2\n",
        "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "        # Remove the classifier\n",
        "        self.features = nn.Sequential(*list(mobilenet.features))\n",
        "\n",
        "        # Add adaptive pooling to get fixed size output\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Freeze MobileNetV2 parameters\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # MobileNetV2 outputs 1280 features after pooling\n",
        "        self.feature_size = 1280\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.feature_size,\n",
        "            hidden_size=lstm_hidden_size,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_hidden_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_length, c, h, w = x.size()\n",
        "\n",
        "        # Process each frame through CNN\n",
        "        x = x.view(batch_size * seq_length, c, h, w)\n",
        "        x = self.features(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Reshape for LSTM: flatten the spatial dimensions\n",
        "        x = x.view(batch_size, seq_length, self.feature_size)\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Average the LSTM outputs across time steps\n",
        "        x = torch.mean(lstm_out, dim=1)\n",
        "\n",
        "        # Classification\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeGvP73aKc4L"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "def train_val_test_split(dataset):\n",
        "    total_size = len(dataset)\n",
        "    test_size = int(TEST_SPLIT * total_size)\n",
        "    val_size = int(VALIDATION_SPLIT * total_size)\n",
        "    train_size = total_size - val_size - test_size\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(\n",
        "        dataset,\n",
        "        [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
        "    )\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "def create_data_loaders(train_dataset, val_dataset, test_dataset):\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory = True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory = True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory = True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yu8Wt-JWKc4M"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_curves(history, fsave='training_curves.png'):\n",
        "    \"\"\"Plot training curves including learning rate\"\"\"\n",
        "    tsave = os.path.join(save_path, fsave)\n",
        "    plt.style.use('seaborn')\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    # Plot loss curves\n",
        "    ax1.plot(history['train_loss'], label='Training Loss', marker='o')\n",
        "    ax1.plot(history['val_loss'], label='Validation Loss', marker='o')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.set_title('Training and Validation Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot accuracy curves\n",
        "    ax2.plot(history['train_acc'], label='Training Accuracy', marker='o')\n",
        "    ax2.plot(history['val_acc'], label='Validation Accuracy', marker='o')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy (%)')\n",
        "    ax2.set_title('Training and Validation Accuracy')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    # Plot learning rate\n",
        "    ax3.plot(history['learning_rates'], label='Learning Rate', marker='o')\n",
        "    ax3.set_xlabel('Epoch')\n",
        "    ax3.set_ylabel('Learning Rate')\n",
        "    ax3.set_title('Learning Rate over Time')\n",
        "    ax3.set_yscale('log')\n",
        "    ax3.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(tsave)\n",
        "    plt.show()\n",
        "    plt.close()  # Close the plot to free up memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9hI_YPeKc4M"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
        "    def __init__(self, patience=7, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        # on default = 7 successive val_loss increase stop\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym8hfKK7YpbC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "def save_checkpoint(model, optimizer, epoch, history, best_path=None):\n",
        "    if best_path is not None:\n",
        "        chk_path = os.path.join(save_path, f'best_model.pth')\n",
        "        print(f\"Saving checkpoint to {chk_path}\")\n",
        "    else:\n",
        "        chk_path = os.path.join(save_path, f'checkpath_model.pth')\n",
        "        print(f\"Saving checkpoint to {chk_path}\")\n",
        "\n",
        "    # Combine model, optimizer, and history into one dictionary\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,  # Save the next epoch number for resuming\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'history': history  # Save history along with the model and optimizer\n",
        "    }\n",
        "\n",
        "    # Save everything in a single file using torch.save\n",
        "    torch.save(checkpoint, chk_path)\n",
        "    print(f\"Checkpoint saved at epoch {epoch + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTWiSzTLPAGj"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(model, optimizer, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Load model and training state from a checkpoint\n",
        "    \"\"\"\n",
        "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    # Load model and optimizer states\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    # Get the epoch number to resume from\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "    # Load training history\n",
        "    history = checkpoint.get('history', {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_acc': [],\n",
        "        'learning_rates': []\n",
        "    })\n",
        "\n",
        "    return model, optimizer, start_epoch, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWy0HheUKc4M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer,\n",
        "                num_epochs=50, patience=7, log_interval=10, checkpoint_path=None):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # model = torch.compile(model)\n",
        "    # Initialize scheduler\n",
        "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "    # Initialize early stopping\n",
        "    # early_stopping = EarlyStopping(patience=patience)\n",
        "    early_stopping = EarlyStopping(patience=7, min_delta=1e-4)\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_val_loss = float('inf')\n",
        "    # Initialize history\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_acc': [],\n",
        "        'learning_rates': []\n",
        "    }\n",
        "        # Load checkpoint if provided\n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        model, optimizer, start_epoch, history = load_checkpoint(\n",
        "            model, optimizer, checkpoint_path\n",
        "        )\n",
        "        print(f\"Resuming training from epoch {start_epoch}\")\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "        # Store current learning rate\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        history['learning_rates'].append(current_lr)\n",
        "        print(f\"Current Learning Rate: {current_lr}\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        train_loader_tqdm = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n",
        "        for batch_idx, (inputs, labels) in train_loader_tqdm:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "\n",
        "            # Log batch-level updates\n",
        "            if batch_idx % log_interval == 0:\n",
        "                train_loader_tqdm.set_postfix({\n",
        "                    'loss': train_loss / (batch_idx + 1),\n",
        "                    'accuracy': 100.0 * train_correct / train_total\n",
        "                })\n",
        "\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        train_acc = 100.0 * train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        val_loader_tqdm = tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validation\")\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, labels) in val_loader_tqdm:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "                # Log batch-level updates for validation\n",
        "                if batch_idx % log_interval == 0:\n",
        "                    val_loader_tqdm.set_postfix({\n",
        "                        'loss': val_loss / (batch_idx + 1),\n",
        "                        'accuracy': 100.0 * val_correct / val_total\n",
        "                    })\n",
        "\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_acc = 100.0 * val_correct / val_total\n",
        "\n",
        "        # Update history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        # Print metrics at the end of the epoch\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs} Summary:')\n",
        "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
        "        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
        "        print(f'Learning Rate: {current_lr}')\n",
        "\n",
        "\n",
        "        save_checkpoint(model, optimizer, epoch, history, best_path=None)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_path = os.path.join(save_path, 'best_model.pth')\n",
        "            save_checkpoint(model, optimizer, epoch, history, best_model_path)\n",
        "            print(f\"New best model saved! Validation Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Early stopping check\n",
        "        early_stopping(val_loss)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    return model, history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qt54or3XzJE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion, class_names,spath=save_path, fsave='confusion_matrix.png'):\n",
        "    \"\"\"\n",
        "    Evaluate model on test set\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        test_loader: DataLoader for test data\n",
        "        criterion: Loss function\n",
        "        class_names: List of class names\n",
        "        save_path: Directory to save the plot\n",
        "        fsave: Filename for confusion matrix plot\n",
        "    \"\"\"\n",
        "    csave = os.path.join(spath, fsave)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Create progress bar\n",
        "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader_tqdm:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            # Calculate accuracy\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "            test_total += labels.size(0)\n",
        "\n",
        "            # Store predictions and labels for confusion matrix\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100 * test_correct / test_total\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(csave)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2DtznLJKc4N",
        "outputId": "b7bfb744-448b-4ca1-e2ee-00afd434a438"
      },
      "outputs": [],
      "source": [
        "print(\"Loading Data\")\n",
        "dataset = YogaVideoDataset(csv_path, sequence_path, pose_list, video_dir)\n",
        "train_dataset, val_dataset, test_dataset = train_val_test_split(dataset)\n",
        "train_loader, val_loader, test_loader = create_data_loaders(train_dataset, val_dataset, test_dataset)\n",
        "print(\"Finished Loading Data\")\n",
        "\n",
        "model = CNNLSTM(num_classes=NUM_CLASSES)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(\"Training the model\")\n",
        "checkpoint_path = os.path.join(save_path, 'checkpath_model.pth')\n",
        "model, history = train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    NUM_EPOCHS,\n",
        "    patience=7,\n",
        "    log_interval=10,\n",
        "    checkpoint_path=checkpoint_path\n",
        ")\n",
        "# Plot the training curves\n",
        "plot_training_curves(history)\n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        model, optimizer, start_epoch, history = load_checkpoint(\n",
        "            model, optimizer, checkpoint_path\n",
        "        )\n",
        "        print(f\"Resuming training from epoch {start_epoch}\")\n",
        "evaluate_model(model, test_loader, criterion, pose_list)\n",
        "\n",
        "model_save_path = os.path.join(save_path, 'my_model.pth')\n",
        "torch.save(model.state_dict(), model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfIE_AxBdTzt"
      },
      "source": [
        "### For evaluation, model was again loaded because previously evaluation function was wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck9LrViq-aUJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"Loading Data\")\n",
        "dataset = YogaVideoDataset(csv_path, sequence_path, pose_list, video_dir)\n",
        "train_dataset, val_dataset, test_dataset = train_val_test_split(dataset)\n",
        "train_loader, val_loader, test_loader = create_data_loaders(train_dataset, val_dataset, test_dataset)\n",
        "\n",
        "model = CNNLSTM(num_classes=NUM_CLASSES)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "load_path = os.path.join(save_path, 'my_model.pth')\n",
        "model.load_state_dict(torch.load(load_path))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "evaluate_model(model, test_loader, criterion, pose_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "aWIAlUP2fWSe",
        "outputId": "446e2a55-92d1-4b7f-bd20-cacb1310b5ce"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "best_save_path = os.path.join(save_path, 'eight')\n",
        "os.makedirs(best_save_path, exist_ok = True)\n",
        "\n",
        "print(\"Loading Data\")\n",
        "dataset = YogaVideoDataset(csv_path, sequence_path, pose_list, video_dir)\n",
        "train_dataset, val_dataset, test_dataset = train_val_test_split(dataset)\n",
        "train_loader, val_loader, test_loader = create_data_loaders(train_dataset, val_dataset, test_dataset)\n",
        "\n",
        "model = CNNLSTM(num_classes=NUM_CLASSES)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "load_path = os.path.join(save_path, 'best_model_81.63.pth')\n",
        "model, optimizer, start_epoch, history = load_checkpoint(model, optimizer, load_path)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "evaluate_model(model, test_loader, criterion,pose_list, spath= best_save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
