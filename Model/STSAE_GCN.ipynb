{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "cu0Fn1p_CZC3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "5-EmS0rvCZC4"
      },
      "outputs": [],
      "source": [
        "TEST_SPLIT = 0.1\n",
        "VAL_SPLIT = 0.2\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFsLvlE_CZC5",
        "outputId": "4788b297-f78b-45ea-bfa3-be1abd6c031f"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# import os\n",
        "\n",
        "# drive.mount('/content/gdrive')\n",
        "# # Define base folder path\n",
        "# base_path = '/content/gdrive/MyDrive/yoga_proj'\n",
        "# !ls /content/gdrive/MyDrive/yoga_proj\n",
        "base_path = '../'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "1QiOQi7BCZC5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Gets label\n",
        "csv_path = os.path.join(base_path,'data/3DYoga90_corrected.csv')\n",
        "\n",
        "SAVE_PATH = os.path.join(base_path, 'nov16_unknown_attention')\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# Classification classes\n",
        "pose_list = ['mountain', 'half-way-lift', 'standing-forward-bend', 'downward-dog']\n",
        "NUM_CLASSES = len(pose_list)\n",
        "\n",
        "dataset_dir = os.path.join(base_path, 'official_dataset')\n",
        "assert os.path.isdir(dataset_dir), f\"Directory '{dataset_dir}' does not exist.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_mVAnHmCZC6",
        "outputId": "685e346e-3370-4080-f4a8-661e27c74843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SCqudip1CZC6",
        "outputId": "1cff5d21-0d88-4d80-fa89-b9b74dc39875"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level1_id</th>\n",
              "      <th>level1_pose</th>\n",
              "      <th>level2_id</th>\n",
              "      <th>level2_pose</th>\n",
              "      <th>l3_pose_id</th>\n",
              "      <th>13_pose</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>standing</td>\n",
              "      <td>11</td>\n",
              "      <td>standing-straight</td>\n",
              "      <td>101</td>\n",
              "      <td>mountain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>standing</td>\n",
              "      <td>11</td>\n",
              "      <td>standing-straight</td>\n",
              "      <td>102</td>\n",
              "      <td>goddess</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>standing</td>\n",
              "      <td>11</td>\n",
              "      <td>standing-straight</td>\n",
              "      <td>103</td>\n",
              "      <td>eagle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>standing</td>\n",
              "      <td>11</td>\n",
              "      <td>standing-straight</td>\n",
              "      <td>104</td>\n",
              "      <td>tree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>standing</td>\n",
              "      <td>11</td>\n",
              "      <td>standing-straight</td>\n",
              "      <td>105</td>\n",
              "      <td>chair</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   level1_id level1_pose  level2_id        level2_pose  l3_pose_id   13_pose\n",
              "0          1    standing         11  standing-straight         101  mountain\n",
              "1          1    standing         11  standing-straight         102   goddess\n",
              "2          1    standing         11  standing-straight         103     eagle\n",
              "3          1    standing         11  standing-straight         104      tree\n",
              "4          1    standing         11  standing-straight         105     chair"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta_info_path = os.path.join(base_path, 'data')\n",
        "pose_index = pd.read_csv(f'{meta_info_path}/pose-index.csv')\n",
        "sequence_index = pd.read_csv(f'{meta_info_path}/3DYoga90_corrected.csv')\n",
        "\n",
        "pose_index.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG2mAMJSCZC6",
        "outputId": "15082629-a085-44bb-fbe1-6ea3561029c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('downward-dog', 246), ('standing-forward-bend', 225), ('half-way-lift', 210), ('mountain', 164), ('chair', 140), ('cobra', 129), ('cockerel', 120), ('extended-triangle', 107), ('extended-side-angle', 101), ('corpse', 95), ('staff', 94), ('wind-relieving', 94), ('fish', 93), ('happy-baby', 93), ('shoulder-pressing', 92), ('reclining-cobbler', 91), ('reclining-hero', 82), ('frog', 80), ('tree', 69), ('intense-side-stretch', 59)]\n",
            "mountain 164\n",
            "half-way-lift 210\n",
            "standing-forward-bend 225\n",
            "downward-dog 246\n",
            "high-lunge 42\n",
            "low-lunge 44\n",
            "warrior-3 47\n",
            "side-plank 48\n",
            "balancing-table 44\n",
            "child 47\n",
            "tree 69\n",
            "extended-triangle 107\n",
            "bridge 41\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1334"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list_poses = [p for p in sequence_index['l3_pose']]\n",
        "pose_dict = dict()\n",
        "for poses in list_poses:\n",
        "    if poses in pose_dict:\n",
        "        pose_dict[poses] += 1\n",
        "    else:\n",
        "        pose_dict[poses] =1\n",
        "sorted_poses = sorted(pose_dict.items(), key= lambda item: item[1], reverse=True)\n",
        "print(sorted_poses[:20])\n",
        "poses = ['mountain',\n",
        "'half-way-lift',\n",
        "'standing-forward-bend',\n",
        "'downward-dog',\n",
        "'high-lunge',\n",
        "'low-lunge',\n",
        "'warrior-3',\n",
        "'side-plank',\n",
        "'balancing-table',\n",
        "'child',\n",
        "'tree',\n",
        "'extended-triangle',\n",
        "'bridge']\n",
        "for keys in poses:\n",
        "    print(keys, pose_dict[keys])\n",
        "\n",
        "sum(map(lambda k: pose_dict[k], poses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpLOGWwACZC7"
      },
      "source": [
        "What does each file tell?\n",
        "\n",
        "1.) pose-index.csv -> Shows Heirarchical organization (THEN NOTHING MORE)\n",
        "\n",
        "2.) 3DYoga90.csv -> Total Main Info(i.e. along with RGB stream){\n",
        "    SequneceID: Parquet_FILE_NAME,\n",
        "    URL,\n",
        "    Frame Start and Frame Stop,\n",
        "    Pose Name, Training Test Split\n",
        "} `Difference between train and test? where to get the validation set from? How to do data augmentation?\n",
        "\n",
        "3.) Parquet Files -> {\n",
        "    Frame Number {\n",
        "        33 Landmarks\n",
        "    },\n",
        "    row-id: FrameNumber-TYPE-Landmark_index,\n",
        "    Coordinates: {x, y, z}\n",
        "}\n",
        "\n",
        "`PLEASE NOTE: The landmark coordinates are all normalized`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y0RRgDxCZC7"
      },
      "source": [
        "# Getting the data ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Kg3fH4QhCZC8"
      },
      "outputs": [],
      "source": [
        "the_desired_poses = [\n",
        "  'downward-dog',\n",
        "  'high-lunge',\n",
        "  'low-lunge',\n",
        "  'warrior-3',\n",
        "  'side-plank',\n",
        "  'balancing-table',\n",
        "  'child',\n",
        "  'tree',\n",
        "  'extended-triangle',\n",
        "  'bridge']\n",
        "\n",
        "# subset_of_poses = [\n",
        "#   'mountain',\n",
        "#   'downward-dog',\n",
        "#   'standing-foward-bend',\n",
        "#   'half-way-lift'\n",
        "# ]\n",
        "\n",
        "subset_of_poses = pose_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "JD1fgbe3CZC8"
      },
      "outputs": [],
      "source": [
        "# Keep only relevant columns\n",
        "def read_meta_data():\n",
        "    meta_info_path = os.path.join(base_path, 'data')\n",
        "    pose_index = pd.read_csv(f'{meta_info_path}/pose-index.csv')\n",
        "    sequence_index = pd.read_csv(f'{meta_info_path}/3DYoga90_corrected.csv')\n",
        "    parquet_index = sequence_index[['sequence_id', 'l3_pose', 'split']]\n",
        "    return parquet_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def AddGaussianNoise(data, mean=0., std=0.01):\n",
        "    noise = torch.randn_like(data) * std + mean\n",
        "    return data + noise\n",
        "\n",
        "def RandomRotate(data, max_angle=30):\n",
        "    angle = torch.rand(1) * 2 * max_angle - max_angle  # Range: [-max_angle, max_angle] in degrees\n",
        "    angle_rad = torch.deg2rad(angle)\n",
        "    cos_theta = torch.cos(angle_rad)\n",
        "    sin_theta = torch.sin(angle_rad)\n",
        "    \n",
        "    rotation_matrix = torch.tensor([\n",
        "        [cos_theta, 0, sin_theta],\n",
        "        [0, 1, 0],\n",
        "        [-sin_theta, 0, cos_theta]\n",
        "    ]).squeeze()\n",
        "    \n",
        "    # print(data.shape)\n",
        "    # print(rotation_matrix.shape)\n",
        "    # data = torch.matmul(rotation_matrix, data)\n",
        "    data = torch.einsum('ij, jkl -> ikl', rotation_matrix, data)\n",
        "    return data\n",
        "\n",
        "def RandomScale(data, scale_range=(0.9, 1.1)):\n",
        "    scale =  scale_range[0] + torch.rand(1) * (scale_range[1] - scale_range[0]) # 0.9 + 0.2 * percentage \n",
        "    return data * scale\n",
        "\n",
        "def RandomTranslate(data, max_translate=0.1):\n",
        "    translate = torch.rand(3) * 2 * max_translate - max_translate  # Range: [-max_translate, max_translate]\n",
        "    return data + translate.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "def TimeReverse(data, p=0.5):\n",
        "    if torch.rand(1) < p:\n",
        "        return torch.flip(data, [1])\n",
        "    else:\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "zaw3MmIFCZC8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class Yoga3DDataset(Dataset):\n",
        "    def __init__(self, parquet_index, root_dir =  dataset_dir,subset_of_poses= subset_of_poses, sub_sampling_length = 20, transform=None, max_frames=None):\n",
        "        self.parquet_index = parquet_index\n",
        "        self.parquet_index = self.parquet_index[self.parquet_index['l3_pose'].isin(subset_of_poses)]\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.max_frames = max_frames\n",
        "        self.sub_sampling_length = sub_sampling_length\n",
        "        self.pose_to_label = {pose: i for i, pose in enumerate(subset_of_poses)}\n",
        "        self.use_augmentation = False\n",
        "\n",
        "        self.cache = dict()\n",
        "    def __len__(self):\n",
        "        return len(self.parquet_index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx in self.cache:\n",
        "            data, label = self.cache[idx]\n",
        "        else:\n",
        "            fname, pose_name, _ = self.parquet_index.iloc[idx]\n",
        "            label = self.pose_to_label[pose_name]\n",
        "\n",
        "            path = os.path.join(self.root_dir, f'{fname}.parquet')\n",
        "\n",
        "            df = pd.read_parquet(path)\n",
        "            df = df.drop(columns=['frame', 'row_id', 'type','landmark_index'])\n",
        "\n",
        "            data = self.to_tensor(df)\n",
        "            data = self.sub_sample(data)\n",
        "            data = data.permute(1,0,2)\n",
        "            self.cache[idx] = (data, label)\n",
        "\n",
        "        if self.transform and self.use_augmentation:\n",
        "            data = self.transform(data.clone())\n",
        "            \n",
        "        return data, label # C, T , V\n",
        "\n",
        "    def sub_sample(self, data):\n",
        "        # data(Number_of_frames, 3, 33)\n",
        "        total_frames = data.shape[0]\n",
        "        indices = torch.linspace(0, total_frames -1 , self.sub_sampling_length, dtype= int)\n",
        "        return data[indices]\n",
        "\n",
        "    def to_tensor(self, df):\n",
        "        # Reshape the data to (num_frames, num_landmarks, 3)  ## WHAT WHAT? this doesn't make sense remove this line you are doing (number of frames, 3 , 33)\n",
        "        num_frames = len(df) // 33  # Assuming 33 landmarks per frame\n",
        "        data = df.values.reshape(num_frames, 33, 3)\n",
        "        return torch.FloatTensor(data).permute(0, 2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, data):\n",
        "        for transform in self.transforms:\n",
        "            data = transform(data)\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RandomApply:\n",
        "    def __init__(self, transform, p=0.5):\n",
        "        self.transform = transform\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, data):\n",
        "        if torch.rand(1) < self.p:\n",
        "            return self.transform(data)\n",
        "        else:\n",
        "            return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "x8-j_6zmCZC8"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class AGCN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(AGCN, self).__init__()\n",
        "\n",
        "        # Initialize adjacency matrix for BlazePose (33 joints)\n",
        "        self.num_nodes = 33\n",
        "        # Define the natural connections in BlazePose skeleton\n",
        "        self.edges = [\n",
        "            # Torso\n",
        "            (11, 12), (12, 24), (24, 23), (23, 11),  # shoulders to hips\n",
        "            # Right arm\n",
        "            (12, 14), (14, 16), (16, 18), (18, 20), (20, 22),  # shoulder to fingertip\n",
        "            # Left arm\n",
        "            (11, 13), (13, 15), (15, 17), (17, 19), (19, 21),  # shoulder to fingertip\n",
        "            # Right leg\n",
        "            (24, 26), (26, 28), (28, 30), (30, 32),  # hip to foot\n",
        "            # Left leg\n",
        "            (23, 25), (25, 27), (27, 29), (29, 31),  # hip to foot\n",
        "            # Face\n",
        "            (0, 1), (1, 2), (2, 3), (3, 7),  # right eye\n",
        "            (0, 4), (4, 5), (5, 6), (6, 8),  # left eye\n",
        "            (9, 10),  # mouth\n",
        "            # Add connections to nose (0) from shoulders\n",
        "            # (0, 11), (0, 12)  # do we include this connection dear friend?\n",
        "        ]\n",
        "\n",
        "        # Create adjacency matrix\n",
        "        A = np.zeros((self.num_nodes, self.num_nodes))\n",
        "        for i, j in self.edges:\n",
        "            A[i, j] = 1\n",
        "            A[j, i] = 1  # Undirected graph\n",
        "\n",
        "        # Convert to tensor and make it a parameter\n",
        "        self.A = nn.Parameter(torch.from_numpy(A.astype(np.float32)))\n",
        "\n",
        "        # Create identity matrix\n",
        "        self.identity = nn.Parameter(torch.eye(self.num_nodes), requires_grad=False)\n",
        "\n",
        "        # 1x1 convolution for feature transformation\n",
        "        self.W = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Compute degree matrix\n",
        "        D = torch.sum(self.A, dim=1)\n",
        "        D = torch.diag(torch.pow(D, -0.5))\n",
        "        # D_r = torch.diag(torch.pow(D, 0.5))\n",
        "\n",
        "        # Normalized adjacency matrix\n",
        "        A_norm = torch.matmul(torch.matmul(D, self.A + self.identity), D)\n",
        "\n",
        "        # Reshape input for matrix multiplication\n",
        "        # N, C, T, V = x.size()\n",
        "        x_reshape = x.permute(0, 2, 3, 1).contiguous()  # N, T, V, C\n",
        "        # Apply GCN operation\n",
        "        x_gc = torch.matmul(A_norm, x_reshape)  # N, T, V, C\n",
        "\n",
        "        # Reshape back\n",
        "        x_gc = x_gc.permute(0, 3, 1, 2).contiguous()  # N, C, T, V\n",
        "\n",
        "        # Apply 1x1 convolution\n",
        "        out = self.W(x_gc)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Wtn_mpv9CZC8"
      },
      "outputs": [],
      "source": [
        "# agcn = AGCN(3, 64)\n",
        "# D = torch.sum(agcn.A, dim=1)\n",
        "# D = torch.diag(torch.pow(D, -0.5))\n",
        "# A_norm = torch.matmul(torch.matmul(D, agcn.A + agcn.identity), D)\n",
        "# # A_norm\n",
        "# agcn.A.shape\n",
        "# D.shape\n",
        "# torch.matmul(torch.matmul(D, agcn.A + agcn.identity), D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn5818CLCZC8"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "CNv13nUNCZC9"
      },
      "outputs": [],
      "source": [
        "class STSAM(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(STSAM, self).__init__()\n",
        "\n",
        "        # 1x1 convolutions for Q, K, V\n",
        "        self.query_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "\n",
        "        # 1x1 convolutions for scaling attention maps\n",
        "        self.Ws = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
        "        self.Wt = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, T, V = x.size()\n",
        "\n",
        "        # Generate Q, K, V\n",
        "        Q = self.query_conv(x)\n",
        "        K = self.key_conv(x)\n",
        "        V = self.value_conv(x)\n",
        "\n",
        "        # Spatial attention\n",
        "        Qs = torch.mean(Q, dim=2, keepdim=True)  # (N, C, 1, V)\n",
        "        Ks = torch.mean(K, dim=2, keepdim=True)  # (N, C, 1, V)\n",
        "        Vs = torch.mean(V, dim=2, keepdim=True)  # (N, C, 1, V)\n",
        "\n",
        "        # Temporal attention\n",
        "        Qt = torch.mean(Q, dim=3, keepdim=True)  # (N, C, T, 1)\n",
        "        Kt = torch.mean(K, dim=3, keepdim=True)  # (N, C, T, 1)\n",
        "        Vt = torch.mean(V, dim=3, keepdim=True)  # (N, C, T, 1)\n",
        "\n",
        "        # Compute attention maps\n",
        "        Ms = torch.matmul(Qs.transpose(2, 3), Ks) / torch.sqrt(torch.tensor(C, dtype=torch.float))  # Spatial attention\n",
        "        Ms = torch.softmax(Ms, dim=-1)\n",
        "        Ms = torch.matmul(Ms, Vs.transpose(2, 3)).transpose(2, 3)\n",
        "\n",
        "        Mt = torch.matmul(Qt.transpose(2, 3), Kt) / torch.sqrt(torch.tensor(C, dtype=torch.float))  # Temporal attention\n",
        "        Mt = torch.softmax(Mt, dim=-1)\n",
        "        Mt = torch.matmul(Mt, Vt.transpose(2, 3)).transpose(2, 3)\n",
        "\n",
        "        # Scale attention maps\n",
        "        Ms1 = torch.sigmoid(self.Ws(Ms))  # (N, 1, 1, V)\n",
        "        Mt1 = torch.sigmoid(self.Wt(Mt))  # (N, 1, T, 1)\n",
        "\n",
        "        # Apply attention with residual connections\n",
        "        out = (x + x * Ms1) + (x + x * Mt1)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "bnCm6QuhCZC9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MTCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=None):\n",
        "        super(MTCN, self).__init__()\n",
        "\n",
        "        # If hidden_channels not specified, make it divisible by 6\n",
        "        if hidden_channels is None:\n",
        "            hidden_channels = in_channels - (in_channels % 6)\n",
        "\n",
        "        assert hidden_channels % 6 == 0, \"var: hidden_channels should always be multple of 6 because 6 branches\"\n",
        "\n",
        "        self.branch_channels = hidden_channels // 6\n",
        "\n",
        "        # Initial 1x1 conv to reduce channels\n",
        "        self.init_conv = nn.Conv2d(\n",
        "            in_channels,\n",
        "            hidden_channels,\n",
        "            kernel_size=1\n",
        "        )\n",
        "\n",
        "        # Branch 1: 1x1 Conv\n",
        "        self.branch1 = nn.Conv2d(\n",
        "            hidden_channels,\n",
        "            self.branch_channels,\n",
        "            kernel_size=1\n",
        "        )\n",
        "\n",
        "        # Branch 2: Max Pooling followed by 1x1 Conv to adjust channels\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=(1, 3), padding=(0, 1), stride=1),\n",
        "            nn.Conv2d(hidden_channels, self.branch_channels, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        # Branches 3-6: 1D Conv with different dilations\n",
        "        self.branches = nn.ModuleList([\n",
        "            nn.Conv2d(\n",
        "                hidden_channels,\n",
        "                self.branch_channels,\n",
        "                kernel_size=(1, 3),\n",
        "                padding=(0, dilation),\n",
        "                dilation=(1, dilation)\n",
        "            ) for dilation in range(1, 5)\n",
        "        ])\n",
        "\n",
        "        # Final 1x1 conv to restore original channel count\n",
        "        self.final_conv = nn.Conv2d(hidden_channels, in_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, C, V, T)\n",
        "\n",
        "        # Initial channel reduction\n",
        "        x = self.init_conv(x)\n",
        "\n",
        "        # Process each branch\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "\n",
        "        # Process dilated convolution branches\n",
        "        branch_outputs = [branch1, branch2]\n",
        "        for branch in self.branches:\n",
        "            branch_outputs.append(branch(x))\n",
        "\n",
        "        # Concatenate all branch outputs\n",
        "        x = torch.cat(branch_outputs, dim=1)\n",
        "\n",
        "        # Final 1x1 conv\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "EfgmXSoiCZC9"
      },
      "outputs": [],
      "source": [
        "\n",
        "class STSAE_GCN_Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(STSAE_GCN_Block, self).__init__()\n",
        "        self.agcn = AGCN(in_channels, out_channels)\n",
        "        self.stsam = STSAM(out_channels)\n",
        "        self.mtcn = MTCN(out_channels, 48)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.agcn(x)\n",
        "        x = self.stsam(x)\n",
        "        x = self.mtcn(x)\n",
        "        return x\n",
        "\n",
        "class STSAE_GCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, num_classes, num_frames, num_blocks=9):\n",
        "        super(STSAE_GCN, self).__init__()\n",
        "        self.num_blocks = num_blocks\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            STSAE_GCN_Block(in_channels if i == 0 else hidden_channels,\n",
        "                            hidden_channels)\n",
        "            for i in range(num_blocks)\n",
        "        ])\n",
        "        num_nodes = 33\n",
        "        self.fc = nn.Linear(hidden_channels * num_nodes * num_frames, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, in_channels, num_frames, num_nodes)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Global average pooling\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def count_parameters(self):\n",
        "        total_params = 0\n",
        "        for name, parameter in self.named_parameters():\n",
        "            if parameter.requires_grad:\n",
        "                params = parameter.numel()\n",
        "                print(f\"{name}: {params}\")\n",
        "                total_params += params\n",
        "        print(f\"Total Trainable Params: {total_params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "GFgBfmOSCZC9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "def save_checkpoint(model, optimizer, epoch, history, save_path = SAVE_PATH, best_path=None):\n",
        "    if best_path is not None:\n",
        "        chk_path = os.path.join(save_path, f'best_model.pth')\n",
        "        print(f\"Saving checkpoint to {chk_path}\")\n",
        "    else:\n",
        "        chk_path = os.path.join(save_path, f'checkpath_model.pth')\n",
        "        print(f\"Saving checkpoint to {chk_path}\")\n",
        "\n",
        "    # Combine model, optimizer, and history into one dictionary\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,  # Save the next epoch number for resuming\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'history': history  # Save history along with the model and optimizer\n",
        "    }\n",
        "\n",
        "    # Save everything in a single file using torch.save\n",
        "    torch.save(checkpoint, chk_path)\n",
        "    print(f\"Checkpoint saved at epoch {epoch + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "mZprkJQvCZC9"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(model, optimizer, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Load model and training state from a checkpoint\n",
        "    \"\"\"\n",
        "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path, weights_only = False)\n",
        "\n",
        "    # Load model and optimizer states\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    # Get the epoch number to resume from\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "    # Load training history with new metrics\n",
        "    history = checkpoint.get('history', {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_acc': [], 'val_acc': [],\n",
        "        'train_precision': [], 'train_recall': [], 'train_f1': [],\n",
        "        'val_precision': [], 'val_recall': [], 'val_f1': [],\n",
        "        'learning_rates': []\n",
        "    })\n",
        "\n",
        "    return model, optimizer, start_epoch, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "dkDP9PAlCZC9"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
        "    def __init__(self, patience=7, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        # on default = 7 successive val_loss increase stop\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "nNTAFuncCZC9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, dataset, num_epochs=50, patience=18, log_interval=10, checkpoint_path=None, unfreeze_epoch=5, num_layers_unfreeze=3):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4)\n",
        "\n",
        "    # Initialize early stopping\n",
        "    early_stopping = EarlyStopping(patience=patience, min_delta=1e-4)\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # Initialize history for loss, accuracy, precision, recall, and F1\n",
        "    history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_acc': [], 'val_acc': [],\n",
        "        'train_precision': [], 'train_recall': [], 'train_f1': [],\n",
        "        'val_precision': [], 'val_recall': [], 'val_f1': [],\n",
        "        'learning_rates': []\n",
        "    }\n",
        "\n",
        "    # Check for checkpoint and load if available\n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        model, optimizer, start_epoch, history = load_checkpoint(model, optimizer, checkpoint_path)\n",
        "        print(f\"Resuming training from epoch {start_epoch}\")\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        dataset.use_augmentation = True\n",
        "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        history['learning_rates'].append(current_lr)\n",
        "        print(f\"Current Learning Rate: {current_lr}\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
        "        train_true, train_pred = [], []\n",
        "\n",
        "        train_loader_tqdm = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n",
        "        for batch_idx, (inputs, labels) in train_loader_tqdm:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)  # Pass sequence lengths to model forward function\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "\n",
        "            # Collect true and predicted labels for precision/recall\n",
        "            train_true.extend(labels.cpu().numpy())\n",
        "            train_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "            # Log batch-level updates\n",
        "            if batch_idx % log_interval == 0:\n",
        "                train_loader_tqdm.set_postfix({\n",
        "                    'loss': train_loss / (BATCH_SIZE * (batch_idx + 1)),\n",
        "                    'accuracy': 100.0 * train_correct / train_total\n",
        "                })\n",
        "\n",
        "        # Calculate training metrics\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = 100.0 * train_correct / train_total\n",
        "        train_precision = precision_score(train_true, train_pred, average='weighted')\n",
        "        train_recall = recall_score(train_true, train_pred, average='weighted')\n",
        "        train_f1 = f1_score(train_true, train_pred, average='weighted')\n",
        "\n",
        "        dataset.use_augmentation = False\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        val_true, val_pred = [], []\n",
        "\n",
        "        val_loader_tqdm = tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validation\")\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, labels) in val_loader_tqdm:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)  # Pass sequence lengths to model forward function\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "                # Collect true and predicted labels for precision/recall\n",
        "                val_true.extend(labels.cpu().numpy())\n",
        "                val_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "                # Log batch-level updates for validation\n",
        "                if batch_idx % log_interval == 0:\n",
        "                    val_loader_tqdm.set_postfix({\n",
        "                        'loss': val_loss / (BATCH_SIZE * (batch_idx + 1)),\n",
        "                        'accuracy': 100.0 * val_correct / val_total\n",
        "                    })\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = 100.0 * val_correct / val_total\n",
        "        val_precision = precision_score(val_true, val_pred, average='weighted')\n",
        "        val_recall = recall_score(val_true, val_pred, average='weighted')\n",
        "        val_f1 = f1_score(val_true, val_pred, average='weighted')\n",
        "\n",
        "        # Update history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['train_precision'].append(train_precision)\n",
        "        history['train_recall'].append(train_recall)\n",
        "        history['train_f1'].append(train_f1)\n",
        "        history['val_precision'].append(val_precision)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['val_f1'].append(val_f1)\n",
        "\n",
        "        # Print metrics at the end of the epoch\n",
        "        print(f'\\nEpoch {epoch + 1}/{num_epochs} Summary:')\n",
        "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Train Precision: {train_precision:.2f} | Train Recall: {train_recall:.2f} | Train F1: {train_f1:.2f}')\n",
        "        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | Val Precision: {val_precision:.2f} | Val Recall: {val_recall:.2f} | Val F1: {val_f1:.2f}')\n",
        "\n",
        "        # Save the best model checkpoint\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_path = os.path.join(SAVE_PATH, 'best_model.pth')\n",
        "            if best_model_path is not None:\n",
        "                print(best_model_path)\n",
        "            save_checkpoint(model, optimizer, epoch, history, SAVE_PATH, best_model_path)\n",
        "            print(f\"New best model saved! Validation Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        # Adjust learning rate based on validation loss\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Check for early stopping\n",
        "        early_stopping(val_loss)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    return model, history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "yjp-JMKQCZC-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion, class_names,spath=SAVE_PATH, fsave='confusion_matrix.png'):\n",
        "    \"\"\"\n",
        "    Evaluate model on test set\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        test_loader: DataLoader for test data\n",
        "        criterion: Loss function\n",
        "        class_names: List of class names\n",
        "        save_path: Directory to save the plot\n",
        "        fsave: Filename for confusion matrix plot\n",
        "    \"\"\"\n",
        "    csave = os.path.join(spath, fsave)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Create progress bar\n",
        "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader_tqdm:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            # Get predictions\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            # Calculate accuracy\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "            test_total += labels.size(0)\n",
        "\n",
        "            # Store predictions and labels for confusion matrix\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    accuracy = 100 * test_correct / test_total\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(csave)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "7EWkYX8sCZC-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "def train_val_test_split(dataset, test_split = TEST_SPLIT, val_split= VAL_SPLIT):\n",
        "    total_size = len(dataset)\n",
        "    test_size = int(test_split * total_size)\n",
        "    val_size = int(val_split * total_size)\n",
        "    train_size = total_size - val_size - test_size\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(\n",
        "        dataset,\n",
        "        [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
        "    )\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "def create_data_loaders(train_dataset, val_dataset, test_dataset, batch_size = BATCH_SIZE):\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        # num_workers=2,\n",
        "        pin_memory= True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        # num_workers=2,\n",
        "        pin_memory= True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        # num_workers=2\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "-nVQoc_DCZC-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_training_curves(history, fsave='training_curves.png'):\n",
        "    tsave = os.path.join(SAVE_PATH, fsave)\n",
        "    # plt.style.use('seaborn')\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "    # Loss curves\n",
        "    axs[0, 0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "    axs[0, 0].plot(history['val_loss'], label='Validation Loss', marker='o')\n",
        "    axs[0, 0].set_title('Loss')\n",
        "    axs[0, 0].legend()\n",
        "\n",
        "    # Accuracy curves\n",
        "    axs[0, 1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
        "    axs[0, 1].plot(history['val_acc'], label='Validation Accuracy', marker='o')\n",
        "    axs[0, 1].set_title('Accuracy')\n",
        "    axs[0, 1].legend()\n",
        "\n",
        "    # Learning rate\n",
        "    axs[0, 2].plot(history['learning_rates'], label='Learning Rate', marker='o')\n",
        "    axs[0, 2].set_title('Learning Rate')\n",
        "    axs[0, 2].set_yscale('log')\n",
        "    axs[0, 2].legend()\n",
        "\n",
        "    # Precision\n",
        "    axs[1, 0].plot(history['train_precision'], label='Train Precision', marker='o')\n",
        "    axs[1, 0].plot(history['val_precision'], label='Validation Precision', marker='o')\n",
        "    axs[1, 0].set_title('Precision')\n",
        "    axs[1, 0].legend()\n",
        "\n",
        "    # Recall\n",
        "    axs[1, 1].plot(history['train_recall'], label='Train Recall', marker='o')\n",
        "    axs[1, 1].plot(history['val_recall'], label='Validation Recall', marker='o')\n",
        "    axs[1, 1].set_title('Recall')\n",
        "    axs[1, 1].legend()\n",
        "\n",
        "    # F1 Score\n",
        "    axs[1, 2].plot(history['train_f1'], label='Train F1', marker='o')\n",
        "    axs[1, 2].plot(history['val_f1'], label='Validation F1', marker='o')\n",
        "    axs[1, 2].set_title('F1 Score')\n",
        "    axs[1, 2].legend()\n",
        "\n",
        "    for ax in axs.flat:\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(tsave)\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "KaE3iYzvCZC-"
      },
      "outputs": [],
      "source": [
        "def main(in_channels = 3, hidden_channels= 64, num_classes= NUM_CLASSES, num_frames= 20, LR = 0.001, Epochs =50):\n",
        "    transforms = Compose([\n",
        "        RandomApply(AddGaussianNoise, p=0.5),\n",
        "        RandomApply(RandomRotate, p=0.5),\n",
        "        RandomApply(RandomScale, p=0.5),\n",
        "        RandomApply(RandomTranslate, p=0.5)\n",
        "        # TimeReverse(p=0.5),\n",
        "        # Normalize,\n",
        "    ])\n",
        "    \n",
        "    dataset = Yoga3DDataset(read_meta_data(), transform=transforms)\n",
        "    train_dataset, val_dataset, test_dataset = train_val_test_split(dataset)\n",
        "    train_loader, val_loader, test_loader = create_data_loaders(train_dataset, val_dataset, test_dataset)\n",
        "\n",
        "    # for data in test_dataset:\n",
        "    #     print(data)\n",
        "    #     break\n",
        "\n",
        "    model = STSAE_GCN(in_channels, hidden_channels, num_classes, num_frames)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    print(\"Training the model\")\n",
        "    checkpoint_path = os.path.join(SAVE_PATH, 'best_model.pth')\n",
        "    for input, label in train_loader:\n",
        "        print(input.size(0))\n",
        "    model, history = train_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        dataset,\n",
        "        Epochs,\n",
        "        patience=10,\n",
        "        log_interval=1,\n",
        "        checkpoint_path=None\n",
        "    )\n",
        "    # Plot the training curves\n",
        "    plot_training_curves(history)\n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "            model, optimizer, start_epoch, history = load_checkpoint(\n",
        "                model, optimizer, checkpoint_path\n",
        "            )\n",
        "            print(f\"Resuming training from epoch {start_epoch}\")\n",
        "    evaluate_model(model, test_loader, criterion, pose_list)\n",
        "\n",
        "    model_save_path = os.path.join(SAVE_PATH, 'my_model.pth')\n",
        "    torch.save(model.state_dict(), model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "GpaMPADECZC-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training the model\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "16\n",
            "Using device: cpu\n",
            "\n",
            "Epoch 1/50\n",
            "Current Learning Rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 37/37 [04:46<00:00,  7.73s/it, loss=1.76, accuracy=44.1]\n",
            "Validation: 100%|| 11/11 [00:01<00:00,  5.58it/s, loss=1.45, accuracy=29.6]\n",
            "c:\\Users\\aagab\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/50 Summary:\n",
            "Train Loss: 1.7582 | Train Acc: 44.09% | Train Precision: 0.44 | Train Recall: 0.44 | Train F1: 0.43\n",
            "Val Loss: 1.5066 | Val Acc: 29.59% | Val Precision: 0.09 | Val Recall: 0.30 | Val F1: 0.14\n",
            "../nov16_unknown_attention\\best_model.pth\n",
            "Saving checkpoint to ../nov16_unknown_attention\\best_model.pth\n",
            "Checkpoint saved at epoch 1\n",
            "New best model saved! Validation Loss: 1.5066\n",
            "\n",
            "Epoch 2/50\n",
            "Current Learning Rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 37/37 [00:12<00:00,  2.96it/s, loss=1.14, accuracy=66.7]\n",
            "Validation: 100%|| 11/11 [00:01<00:00,  6.97it/s, loss=0.466, accuracy=88.8]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/50 Summary:\n",
            "Train Loss: 1.1412 | Train Acc: 66.72% | Train Precision: 0.67 | Train Recall: 0.67 | Train F1: 0.67\n",
            "Val Loss: 0.4850 | Val Acc: 88.76% | Val Precision: 0.90 | Val Recall: 0.89 | Val F1: 0.88\n",
            "../nov16_unknown_attention\\best_model.pth\n",
            "Saving checkpoint to ../nov16_unknown_attention\\best_model.pth\n",
            "Checkpoint saved at epoch 2\n",
            "New best model saved! Validation Loss: 0.4850\n",
            "\n",
            "Epoch 3/50\n",
            "Current Learning Rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  84%| | 31/37 [00:11<00:02,  2.61it/s, loss=0.89, accuracy=75.6] \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[85], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     main()\n",
            "Cell \u001b[1;32mIn[84], line 27\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(in_channels, hidden_channels, num_classes, num_frames, LR, Epochs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, label \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m---> 27\u001b[0m model, history \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[0;32m     28\u001b[0m     model,\n\u001b[0;32m     29\u001b[0m     train_loader,\n\u001b[0;32m     30\u001b[0m     val_loader,\n\u001b[0;32m     31\u001b[0m     criterion,\n\u001b[0;32m     32\u001b[0m     optimizer,\n\u001b[0;32m     33\u001b[0m     dataset,\n\u001b[0;32m     34\u001b[0m     Epochs,\n\u001b[0;32m     35\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     36\u001b[0m     log_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     37\u001b[0m     checkpoint_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Plot the training curves\u001b[39;00m\n\u001b[0;32m     40\u001b[0m plot_training_curves(history)\n",
            "Cell \u001b[1;32mIn[80], line 55\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, dataset, num_epochs, patience, log_interval, checkpoint_path, unfreeze_epoch, num_layers_unfreeze)\u001b[0m\n\u001b[0;32m     53\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)  \u001b[38;5;66;03m# Pass sequence lengths to model forward function\u001b[39;00m\n\u001b[0;32m     54\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 55\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     56\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     57\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[1;32mc:\\Users\\aagab\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    523\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\aagab\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[0;32m    290\u001b[0m     tensors,\n\u001b[0;32m    291\u001b[0m     grad_tensors_,\n\u001b[0;32m    292\u001b[0m     retain_graph,\n\u001b[0;32m    293\u001b[0m     create_graph,\n\u001b[0;32m    294\u001b[0m     inputs,\n\u001b[0;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    297\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\aagab\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
