{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.516925Z",
     "iopub.status.busy": "2025-02-26T09:07:03.516556Z",
     "iopub.status.idle": "2025-02-26T09:07:03.520889Z",
     "shell.execute_reply": "2025-02-26T09:07:03.519914Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.516896Z"
    },
    "id": "cu0Fn1p_CZC3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.522264Z",
     "iopub.status.busy": "2025-02-26T09:07:03.521979Z",
     "iopub.status.idle": "2025-02-26T09:07:03.538106Z",
     "shell.execute_reply": "2025-02-26T09:07:03.537370Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.522236Z"
    },
    "id": "VqZWlAq2mGn6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "# VALIDATION_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.1\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Constants\n",
    "FRAME_HEIGHT = 224\n",
    "FRAME_WIDTH = 224\n",
    "SEQUENCE_LENGTH = 30\n",
    "\n",
    "ARCHITECTURE = '2D_CNN_LSTM'\n",
    "# CNN_TYPE = 'resnet18'\n",
    "# CNN_TYPE = 'mobilenet_v3'\n",
    "CNN_TYPE = 'vgg16'\n",
    "# LSTM_HIDDEN_SIZE=512\n",
    "LSTM_HIDDEN_SIZE= 512\n",
    "LSTM_LAYERS = 1\n",
    "DROPOUT = 0.5\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_LAYERS_TO_UNFREEZE = 1\n",
    "FROZEN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.539494Z",
     "iopub.status.busy": "2025-02-26T09:07:03.539274Z",
     "iopub.status.idle": "2025-02-26T09:07:03.555815Z",
     "shell.execute_reply": "2025-02-26T09:07:03.555192Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.539476Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset root: /kaggle/input/updated-yoga-dataset/\n",
      "video directory: /kaggle/input/yoga-video/NEW_SHORTS/\n",
      "metadata directory: /kaggle/input/updated-yoga-dataset/data/data/\n",
      "csv path: /kaggle/input/updated-yoga-dataset/data/data/3DYoga90_corrected.csv\n",
      "metadata info path: /kaggle/working/fold_save\n",
      "valid sequences log: /kaggle/input/yoga-video/NEW_SHORTS/downloaded_log.txt\n",
      "preprocessed data directory: /kaggle/input/updated-yoga-dataset/RESIZED_DATA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# root directory of uploaded dataset\n",
    "dataset_root = \"/kaggle/input/updated-yoga-dataset/\"\n",
    "video_dataset_root = '/kaggle/input/yoga-video/'\n",
    "\n",
    "video_dir = os.path.join(video_dataset_root, \"NEW_SHORTS/\")\n",
    "metadata_dir = os.path.join(dataset_root, \"data/data/\")\n",
    "\n",
    "# csv file containing labels\n",
    "csv_path = os.path.join(metadata_dir, \"3DYoga90_corrected.csv\")\n",
    "\n",
    "# path to store additional metadata files\n",
    "meta_info_path = os.path.join('/kaggle/working/', 'fold_save')  # same as metadata_dir\n",
    "os.makedirs(meta_info_path, exist_ok=True)\n",
    "# paths for logging valid and corrupted samples\n",
    "sequence_path = os.path.join(video_dir, \"downloaded_log.txt\")\n",
    "corrupted_path = os.path.join('/kaggle/working/', \"corrupted_log.txt\")\n",
    "\n",
    "# directory to store preprocessed videos\n",
    "preprocessed_dir = os.path.join(dataset_root, \"RESIZED_DATA\")\n",
    "\n",
    "FOLD_CHECKPOINT_PATH = os.path.join('/kaggle/working/', 'FOLD_CHECKPOINT')\n",
    "\n",
    "\n",
    "# print paths for verification\n",
    "print(f\"dataset root: {dataset_root}\")\n",
    "print(f\"video directory: {video_dir}\")\n",
    "print(f\"metadata directory: {metadata_dir}\")\n",
    "print(f\"csv path: {csv_path}\")\n",
    "print(f\"metadata info path: {meta_info_path}\")\n",
    "print(f\"valid sequences log: {sequence_path}\")\n",
    "# print(f\"corrupted sequences log: {corrupted_log_path}\")\n",
    "print(f\"preprocessed data directory: {preprocessed_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.557182Z",
     "iopub.status.busy": "2025-02-26T09:07:03.556971Z",
     "iopub.status.idle": "2025-02-26T09:07:03.695679Z",
     "shell.execute_reply": "2025-02-26T09:07:03.694811Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.557164Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  RESIZED_DATA  short\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/yoga-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.696971Z",
     "iopub.status.busy": "2025-02-26T09:07:03.696653Z",
     "iopub.status.idle": "2025-02-26T09:07:03.706140Z",
     "shell.execute_reply": "2025-02-26T09:07:03.705322Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.696934Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] dataset root exists and is a directory: /kaggle/input/updated-yoga-dataset/\n",
      "[✔] video directory exists and is a directory: /kaggle/input/yoga-video/NEW_SHORTS/\n",
      "[✔] metadata directory exists and is a directory: /kaggle/input/updated-yoga-dataset/data/data/\n",
      "[✔] csv file exists and is a file: /kaggle/input/updated-yoga-dataset/data/data/3DYoga90_corrected.csv\n",
      "[✔] metadata info path exists and is a directory: /kaggle/working/fold_save\n",
      "[✔] valid sequences log exists and is a file: /kaggle/input/yoga-video/NEW_SHORTS/downloaded_log.txt\n",
      "[✘] corrupted sequences log does NOT exist: /kaggle/working/corrupted_log.txt\n",
      "[✔] preprocessed data directory exists and is a directory: /kaggle/input/updated-yoga-dataset/RESIZED_DATA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define paths\n",
    "paths_to_check = {\n",
    "    \"dataset root\": dataset_root,\n",
    "    \"video directory\": video_dir,\n",
    "    \"metadata directory\": metadata_dir,\n",
    "    \"csv file\": csv_path,\n",
    "    \"metadata info path\": meta_info_path,\n",
    "    \"valid sequences log\": sequence_path,\n",
    "    \"corrupted sequences log\": corrupted_path,\n",
    "    \"preprocessed data directory\": preprocessed_dir\n",
    "}\n",
    "\n",
    "# Check existence\n",
    "for name, path in paths_to_check.items():\n",
    "    if os.path.exists(path):\n",
    "        if os.path.isfile(path):\n",
    "            print(f\"[✔] {name} exists and is a file: {path}\")\n",
    "        elif os.path.isdir(path):\n",
    "            print(f\"[✔] {name} exists and is a directory: {path}\")\n",
    "    else:\n",
    "        print(f\"[✘] {name} does NOT exist: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.707277Z",
     "iopub.status.busy": "2025-02-26T09:07:03.707020Z",
     "iopub.status.idle": "2025-02-26T09:07:03.721576Z",
     "shell.execute_reply": "2025-02-26T09:07:03.720765Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.707252Z"
    },
    "id": "AikpWHK1oNj4",
    "outputId": "3dec5be8-8ddc-4d4d-f11c-91dc7533aa79",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in missing_videos.txt: 1556\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(video_dir, \"downloaded_log.txt\")\n",
    "\n",
    "# Count lines in the file\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    line_count = sum(1 for _ in f)\n",
    "\n",
    "print(f\"Number of lines in missing_videos.txt: {line_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.722669Z",
     "iopub.status.busy": "2025-02-26T09:07:03.722418Z",
     "iopub.status.idle": "2025-02-26T09:07:03.857114Z",
     "shell.execute_reply": "2025-02-26T09:07:03.856268Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.722650Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_save\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.860068Z",
     "iopub.status.busy": "2025-02-26T09:07:03.859768Z",
     "iopub.status.idle": "2025-02-26T09:07:03.866074Z",
     "shell.execute_reply": "2025-02-26T09:07:03.865185Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.860044Z"
    },
    "id": "1QiOQi7BCZC5",
    "outputId": "0a9df3fd-c15a-44c6-9f87-61cb0853fcff",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/BS32_KAGGLE_CROSS_FOLD_2D_CNN_LSTM_2025-02-26_LR0.001_LHS512_LL1_CTmobilenet_v3_FROZEN_True_NLUF_1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "SAVE_PATH = os.path.join(\n",
    "    '/kaggle/working/',\n",
    "    f'BS{BATCH_SIZE}_KAGGLE_CROSS_FOLD_{ARCHITECTURE}_LR{LEARNING_RATE}_LHS{LSTM_HIDDEN_SIZE}_LL{LSTM_LAYERS}_CT{CNN_TYPE}_FROZEN_{FROZEN}_NLUF_{NUM_LAYERS_TO_UNFREEZE}'\n",
    ")\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "print(SAVE_PATH)\n",
    "\n",
    "pose_list = ['downward-dog','standing-forward-bend','half-way-lift',\n",
    "             'mountain','chair','cobra','cockerel','extended-triangle',\n",
    "             'extended-side-angle','corpse','staff','wind-relieving','fish'\n",
    "            ]\n",
    "\n",
    "subset_of_poses = pose_list\n",
    "NUM_CLASSES = len(pose_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.867778Z",
     "iopub.status.busy": "2025-02-26T09:07:03.867578Z",
     "iopub.status.idle": "2025-02-26T09:07:03.879780Z",
     "shell.execute_reply": "2025-02-26T09:07:03.878919Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.867760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# SAVE_PATH = '/kaggle/working/BS32_KAGGLE_CROSS_FOLD_2D_CNN_LSTM_2025-02-23_LR0.001_LHS512_LL1_CTresnet18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.880915Z",
     "iopub.status.busy": "2025-02-26T09:07:03.880644Z",
     "iopub.status.idle": "2025-02-26T09:07:03.947505Z",
     "shell.execute_reply": "2025-02-26T09:07:03.946678Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.880895Z"
    },
    "id": "H_mVAnHmCZC6",
    "outputId": "cdfb009e-8b2f-4beb-c4df-9d77fa77cb97",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.948605Z",
     "iopub.status.busy": "2025-02-26T09:07:03.948310Z",
     "iopub.status.idle": "2025-02-26T09:07:03.960443Z",
     "shell.execute_reply": "2025-02-26T09:07:03.959717Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.948572Z"
    },
    "id": "SCqudip1CZC6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# meta_info_path = os.path.join(base_path, 'data')\n",
    "# pose_index = pd.read_csv(f'{meta_info_path}/pose-index.csv')\n",
    "# sequence_index = pd.read_csv(f'{meta_info_path}/3DYoga90_corrected.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpLOGWwACZC7"
   },
   "source": [
    "What does each file tell?\n",
    "\n",
    "1.) pose-index.csv -> Shows Heirarchical organization (THEN NOTHING MORE)\n",
    "\n",
    "2.) 3DYoga90.csv -> Total Main Info(i.e. along with RGB stream){\n",
    "    SequneceID: Parquet_FILE_NAME,\n",
    "    URL,\n",
    "    Frame Start and Frame Stop,\n",
    "    Pose Name, Training Test Split\n",
    "} `Difference between train and test? where to get the validation set from? How to do data augmentation?\n",
    "\n",
    "3.) Parquet Files -> {\n",
    "    Frame Number {\n",
    "        33 Landmarks\n",
    "    },\n",
    "    row-id: FrameNumber-TYPE-Landmark_index,\n",
    "    Coordinates: {x, y, z}\n",
    "}\n",
    "\n",
    "`PLEASE NOTE: The landmark coordinates are all normalized`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1y0RRgDxCZC7"
   },
   "source": [
    "# Getting the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:03.961601Z",
     "iopub.status.busy": "2025-02-26T09:07:03.961286Z",
     "iopub.status.idle": "2025-02-26T09:07:06.562672Z",
     "shell.execute_reply": "2025-02-26T09:07:06.561793Z",
     "shell.execute_reply.started": "2025-02-26T09:07:03.961541Z"
    },
    "id": "Kg3fH4QhCZC8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.v2 as T\n",
    "import random\n",
    "\n",
    "class VideoAugmentationPipeline:\n",
    "    \"\"\"Video augmentation pipeline using batch transforms from torchvision.transforms.v2\"\"\"\n",
    "    def __init__(self, spatial_aug_config=None, temporal_aug_config=None):\n",
    "        # Default config with all augmentations enabled\n",
    "        default_spatial_config = {\n",
    "            'random_resized_crop': {'enabled': False, 'scale': (0.9, 1.0)},\n",
    "            'random_horizontal_flip': {'enabled': True, 'p': 0.5},\n",
    "            'color_jitter': {'enabled': True, 'brightness': 0.1, 'contrast': 0.1, 'saturation': 0.1, 'p': 0.5},\n",
    "            'gaussian_blur': {'enabled': True, 'p': 0.5},\n",
    "            'random_rotation': {'enabled': True, 'degrees': (-5, 5),'p':0.5},\n",
    "        }\n",
    "\n",
    "        default_temporal_config = {\n",
    "            'temporal_crop': {'enabled': True, 'crop_size': 0.9},\n",
    "            'temporal_mask': {'enabled': True, 'n_masks': 1, 'mask_size': 0.1},\n",
    "        }\n",
    "\n",
    "        # Update default config with user-provided config\n",
    "        self.spatial_aug_config = self._update_config(default_spatial_config, spatial_aug_config)\n",
    "        self.temporal_aug_config = self._update_config(default_temporal_config, temporal_aug_config)\n",
    "\n",
    "        # Build transforms that can handle batch inputs\n",
    "        self.spatial_transforms = self._build_spatial_transforms()\n",
    "\n",
    "    def _update_config(self, default_config, user_config):\n",
    "        \"\"\"Update default config with user config, disabling augmentations not in user config\"\"\"\n",
    "        if user_config is None:\n",
    "            return default_config\n",
    "\n",
    "        updated_config = default_config.copy()\n",
    "        for aug_name in updated_config:\n",
    "            if aug_name in user_config:\n",
    "                # # Update probability if provided\n",
    "                # if isinstance(user_config[aug_name], dict):\n",
    "                #     updated_config[aug_name].update(user_config[aug_name])\n",
    "                # else:\n",
    "                    updated_config[aug_name]['p'] = user_config[aug_name]\n",
    "            else:\n",
    "                # Disable augmentation if not in user config\n",
    "                updated_config[aug_name]['enabled'] = False\n",
    "        return updated_config\n",
    "\n",
    "    def _build_spatial_transforms(self):\n",
    "        \"\"\"Build composition of spatial transforms that support batch processing\"\"\"\n",
    "        transform_list = []\n",
    "\n",
    "        if self.spatial_aug_config['random_resized_crop']['enabled']:\n",
    "            transform_list.append(\n",
    "                T.RandomResizedCrop(\n",
    "                    size=(224, 224),\n",
    "                    scale=self.spatial_aug_config['random_resized_crop']['scale'],\n",
    "                    antialias=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if self.spatial_aug_config['random_horizontal_flip']['enabled']:\n",
    "            transform_list.append(\n",
    "                T.RandomHorizontalFlip(p=self.spatial_aug_config['random_horizontal_flip']['p'])\n",
    "            )\n",
    "\n",
    "        if self.spatial_aug_config['color_jitter']['enabled']:\n",
    "            transform_list.append(\n",
    "                T.ColorJitter(\n",
    "                    brightness=self.spatial_aug_config['color_jitter']['brightness'],\n",
    "                    contrast=self.spatial_aug_config['color_jitter']['contrast'],\n",
    "                    saturation=self.spatial_aug_config['color_jitter']['saturation']\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if self.spatial_aug_config['gaussian_blur']['enabled']:\n",
    "            transform_list.append(\n",
    "                T.GaussianBlur(\n",
    "                    kernel_size=(5, 5),\n",
    "                    sigma=(0.1, 1.0)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if self.spatial_aug_config['random_rotation']['enabled']:\n",
    "            if random.random() < self.spatial_aug_config['random_rotation']['p']:\n",
    "                transform_list.append(\n",
    "                    T.RandomRotation(\n",
    "                        degrees=self.spatial_aug_config['random_rotation']['degrees'],\n",
    "                        interpolation=T.InterpolationMode.BILINEAR\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return T.Compose(transform_list)\n",
    "\n",
    "    def apply_temporal_augmentation(self, video_tensor):\n",
    "        \"\"\"Apply temporal augmentations to video tensor\"\"\"\n",
    "        if not any(cfg['enabled'] for cfg in self.temporal_aug_config.values()):\n",
    "            return video_tensor\n",
    "\n",
    "        T, C, H, W = video_tensor.shape\n",
    "\n",
    "        # Temporal crop\n",
    "        if self.temporal_aug_config['temporal_crop']['enabled']:\n",
    "            crop_size = int(T * self.temporal_aug_config['temporal_crop']['crop_size'])\n",
    "            start_idx = random.randint(0, T - crop_size)\n",
    "            video_tensor = video_tensor[start_idx:start_idx + crop_size]\n",
    "\n",
    "        # Temporal masking\n",
    "        if self.temporal_aug_config['temporal_mask']['enabled']:\n",
    "            T = len(video_tensor)\n",
    "            mask_size = int(T * self.temporal_aug_config['temporal_mask']['mask_size'])\n",
    "            for _ in range(self.temporal_aug_config['temporal_mask']['n_masks']):\n",
    "                if random.random() < 0.5:\n",
    "                    start_idx = random.randint(0, T - mask_size)\n",
    "                    video_tensor[start_idx:start_idx + mask_size] = 0\n",
    "\n",
    "        return video_tensor\n",
    "\n",
    "    def __call__(self, video_tensor):\n",
    "        \"\"\"Apply transforms to entire video tensor at once\"\"\"\n",
    "        # Input shape: [T, C, H, W]\n",
    "        # Reshape to [T, C, H, W] -> [1, T, C, H, W] for batch processing\n",
    "        video_tensor = video_tensor.unsqueeze(0)\n",
    "\n",
    "        # Apply spatial transforms to entire video tensor at once\n",
    "        # transforms.v2 will maintain temporal consistency automatically\n",
    "        video_tensor = self.spatial_transforms(video_tensor)\n",
    "\n",
    "        # Remove batch dimension\n",
    "        video_tensor = video_tensor.squeeze(0)\n",
    "\n",
    "        # Apply temporal augmentations\n",
    "        # video_tensor = self.apply_temporal_augmentation(video_tensor)\n",
    "\n",
    "        return video_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:06.564124Z",
     "iopub.status.busy": "2025-02-26T09:07:06.563620Z",
     "iopub.status.idle": "2025-02-26T09:07:06.624006Z",
     "shell.execute_reply": "2025-02-26T09:07:06.623330Z",
     "shell.execute_reply.started": "2025-02-26T09:07:06.564094Z"
    },
    "id": "PP9lZQ6YmGn8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import random\n",
    "\n",
    "class YogaVideoDataset(Dataset):\n",
    "    def __init__(self, csv_path, sequence_path, pose_list, video_dir, preprocessed_dir,\n",
    "                 spatial_aug_config=None, temporal_aug_config=None, use_augmentation=True, aug_ratio = 0.5):\n",
    "        with open(sequence_path) as f:\n",
    "            sequence_list = f.read().splitlines()\n",
    "            sequence_list = [int(x) for x in sequence_list]\n",
    "\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.df = self.df[self.df['sequence_id'].isin(sequence_list)]\n",
    "        self.df = self.df[self.df['l3_pose'].isin(pose_list)]\n",
    "\n",
    "        self.pose_to_label = {pose: idx for idx, pose in enumerate(pose_list)}\n",
    "        self.length_of_dataset = len(self.df)\n",
    "        self.idx_to_label = {}\n",
    "\n",
    "        self.video_dir = video_dir\n",
    "        self.preprocessed_dir = preprocessed_dir\n",
    "        os.makedirs(self.preprocessed_dir, exist_ok=True)\n",
    "\n",
    "        # Initialize augmentation pipeline\n",
    "        self.augmentation_pipeline = VideoAugmentationPipeline(\n",
    "            spatial_aug_config=spatial_aug_config,\n",
    "            temporal_aug_config=temporal_aug_config\n",
    "        )\n",
    "\n",
    "        self.cache = dict()\n",
    "        self.augmentation_ratio = aug_ratio\n",
    "        self.use_augmentation = use_augmentation\n",
    "\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize((FRAME_HEIGHT, FRAME_WIDTH)),\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "            #                      std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.normalization = transforms.Compose([\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return self.length_of_dataset\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sequence_id = self.df.iloc[i]['sequence_id']\n",
    "        pose = self.df.iloc[i]['l3_pose']\n",
    "        label = self.pose_to_label[pose]\n",
    "        self.idx_to_label[i] = sequence_id\n",
    "        # Load preprocessed frames\n",
    "        if sequence_id in self.cache:\n",
    "            frames = self.cache[sequence_id]\n",
    "        else:\n",
    "            file_path = os.path.join(self.preprocessed_dir, f\"{sequence_id}.pt\")\n",
    "            if not os.path.exists(file_path):\n",
    "                video_path = os.path.join(self.video_dir, f\"{sequence_id}.mp4\")\n",
    "                frames = self._get_frames(video_path)\n",
    "                torch.save(frames, file_path)\n",
    "            else:\n",
    "                frames = torch.load(file_path, weights_only=True)\n",
    "            # self.cache[sequence_id] = frames\n",
    "\n",
    "        # Choose whether to use augmented or original data\n",
    "        use_augmented_data = self.use_augmentation and self.augmentation_ratio < random.random()\n",
    "        if use_augmented_data:\n",
    "            frames = self.augmentation_pipeline(frames)\n",
    "\n",
    "        frames = self.normalization(frames)\n",
    "        return frames, label\n",
    "\n",
    "    def _get_frames(self, video_path, sequence_length=SEQUENCE_LENGTH, corrupted_log_path = corrupted_path):\n",
    "        reader = imageio.get_reader(video_path, 'ffmpeg')\n",
    "        fps = imageio.get_reader(video_path, 'ffmpeg').get_meta_data()['fps'] // 1\n",
    "        total_frames = reader.count_frames()\n",
    "\n",
    "\n",
    "\n",
    "        # Calculate frame indices to sample\n",
    "        indices = np.linspace(0, total_frames - 1, num=sequence_length, dtype=int)\n",
    "        t_indices =[]\n",
    "        frames = []\n",
    "        for i, frame in enumerate(reader):\n",
    "            if i in indices:\n",
    "                frame = Image.fromarray(frame)\n",
    "                frame = self.transforms(frame)\n",
    "                frames.append(frame)\n",
    "                t_indices.append(i)\n",
    "                # print('Frame number', i % fps, 'Frame', i)\n",
    "\n",
    "        reader.close()\n",
    "\n",
    "        # If extracted frames do not match sequence_length, log to corrupted_log_path\n",
    "        if len(frames) != sequence_length:\n",
    "            with open(corrupted_log_path, \"a\") as f:\n",
    "                f.write(f\"Corrupted video: {video_path}\\n\")\n",
    "                f.write(f\"Expected {sequence_length} frames, got {len(frames)}\\n\")\n",
    "                f.write(f\"Selected frame indices: {t_indices}\\n\\n\")\n",
    "            print(f\"Processing video: {video_path}\")\n",
    "            print(f\"Total frames: {total_frames}\")\n",
    "            print(f\"Total frames: {t_indices}\")\n",
    "            print(f\"Final frame count: {len(frames)}\")\n",
    "\n",
    "\n",
    "        # Ensure frames tensor has correct shape\n",
    "        if frames:\n",
    "            frames = torch.stack(frames)\n",
    "        else:\n",
    "            frames = torch.empty(0)  # Return an empty tensor if no frames are found\n",
    "\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:06.624991Z",
     "iopub.status.busy": "2025-02-26T09:07:06.624780Z",
     "iopub.status.idle": "2025-02-26T09:07:06.642174Z",
     "shell.execute_reply": "2025-02-26T09:07:06.641161Z",
     "shell.execute_reply.started": "2025-02-26T09:07:06.624974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torchvision.models as models\n",
    "# import torch.nn.functional as F\n",
    "# import torch.nn.utils.rnn as rnn_utils\n",
    "# import math\n",
    "\n",
    "# class AttentionLayer(nn.Module):\n",
    "#     \"\"\"Basic attention mechanism for sequence processing\"\"\"\n",
    "#     def __init__(self, input_size, hidden_size):\n",
    "#         super().__init__()\n",
    "#         self.W = nn.Linear(input_size, hidden_size)\n",
    "#         self.V = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "#         # Initialize attention weights\n",
    "#         nn.init.xavier_uniform_(self.W.weight)\n",
    "#         nn.init.xavier_uniform_(self.V.weight)\n",
    "#         nn.init.zeros_(self.W.bias)\n",
    "#         nn.init.zeros_(self.V.bias)\n",
    "\n",
    "#     def forward(self, lstm_output, mask=None):\n",
    "#         att_scores = self.V(torch.tanh(self.W(lstm_output))).squeeze(-1)\n",
    "\n",
    "#         if mask is not None:\n",
    "#             att_scores = att_scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "#         att_weights = F.softmax(att_scores, dim=1)\n",
    "#         context = (lstm_output * att_weights.unsqueeze(-1)).sum(1)\n",
    "#         return context, att_weights\n",
    "\n",
    "# class CNNLSTM(nn.Module):\n",
    "#     \"\"\"Modular video action classifier with various configuration options\"\"\"\n",
    "#     def __init__(self, num_classes,\n",
    "#                  lstm_hidden_size=512,\n",
    "#                  lstm_layers=1,\n",
    "#                  dropout=0.5,\n",
    "#                  freeze_cnn=True,\n",
    "#                  use_attention=False,\n",
    "#                  cnn_model='resnet18'):\n",
    "\n",
    "#         super().__init__()\n",
    "#         self.use_attention = use_attention\n",
    "#         self.cnn_model = cnn_model\n",
    "\n",
    "#         # CNN Feature Extractor\n",
    "#         self.cnn, self.cnn_feature_size = self._build_cnn(cnn_model)\n",
    "#         self._set_cnn_freeze(freeze_cnn)\n",
    "\n",
    "#         # Adjust LSTM input size based on CNN feature size\n",
    "#         lstm_input_size = self.cnn_feature_size\n",
    "\n",
    "#         # Sequence Processing\n",
    "#         self.lstm = nn.LSTM(\n",
    "#             input_size=lstm_input_size,\n",
    "#             hidden_size=lstm_hidden_size,\n",
    "#             num_layers=lstm_layers,\n",
    "#             batch_first=True,\n",
    "#             dropout=dropout if lstm_layers > 1 else 0\n",
    "#         )\n",
    "        \n",
    "#         # Initialize LSTM weights properly\n",
    "#         self._init_lstm_weights()\n",
    "\n",
    "#         # Attention Mechanism\n",
    "#         if self.use_attention:\n",
    "#             self.attention = AttentionLayer(\n",
    "#                 input_size=lstm_hidden_size,\n",
    "#                 hidden_size=lstm_hidden_size\n",
    "#             )\n",
    "\n",
    "#         # Simplified Classification Head\n",
    "#         self.classifier = self._build_classifier(\n",
    "#             lstm_hidden_size,\n",
    "#             num_classes,\n",
    "#             dropout\n",
    "#         )\n",
    "\n",
    "#         # Initialize classifier weights\n",
    "#         self._initialize_weights()\n",
    "\n",
    "#     def _build_cnn(self, model_name):\n",
    "#         \"\"\"Initialize CNN feature extractor with proper feature sizes\"\"\"\n",
    "#         if model_name == 'resnet18':\n",
    "#             cnn = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "#             return nn.Sequential(*list(cnn.children())[:-2]), 512  # Remove avgpool and fc\n",
    "#         elif model_name == 'mobilenet_v3':\n",
    "#             cnn = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "#             # Remove classifier and avgpool layers\n",
    "#             return nn.Sequential(*list(cnn.children())[:-2]), 576  # Feature size for mobilenet_v3_small\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported CNN model: {model_name}\")\n",
    "\n",
    "#     def _build_classifier(self, input_size, num_classes, dropout):\n",
    "#         \"\"\"Build a minimal classification head with a single layer\"\"\"\n",
    "#         return nn.Sequential(\n",
    "#             nn.Dropout(dropout),\n",
    "#             nn.Linear(input_size, num_classes)\n",
    "#         )\n",
    "#     def _init_lstm_weights(self):\n",
    "#         \"\"\"Initialize LSTM weights using orthogonal initialization\"\"\"\n",
    "#         for name, param in self.lstm.named_parameters():\n",
    "#             if 'weight_ih' in name:\n",
    "#                 nn.init.xavier_uniform_(param)\n",
    "#             elif 'weight_hh' in name:\n",
    "#                 nn.init.orthogonal_(param)\n",
    "#             elif 'bias' in name:\n",
    "#                 nn.init.zeros_(param)\n",
    "#     def _initialize_weights(self):\n",
    "#         for m in self.classifier.modules():\n",
    "#             if isinstance(m, nn.Linear):\n",
    "#                 nn.init.xavier_normal_(m.weight)  # Replace Kaiming with Xavier\n",
    "#                 if m.bias is not None:\n",
    "#                     nn.init.constant_(m.bias, 0)\n",
    "#     def _set_cnn_freeze(self, freeze):\n",
    "#         \"\"\"Freeze/unfreeze CNN parameters\"\"\"\n",
    "#         for param in self.cnn.parameters():\n",
    "#             param.requires_grad = not freeze\n",
    "\n",
    "#     def forward(self, x, lengths):\n",
    "#         # Process frames through CNN\n",
    "#         batch_size, seq_len = x.size(0), x.size(1)\n",
    "#         x = x.view(batch_size*seq_len, *x.size()[2:])\n",
    "#         x = self.cnn(x)\n",
    "        \n",
    "#         # Use same adaptive pooling for both models for consistency\n",
    "#         x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "            \n",
    "#         # Reshape for sequence processing\n",
    "#         x = x.view(batch_size, seq_len, -1)\n",
    "\n",
    "#         # Process sequence through LSTM\n",
    "#         packed_x = rnn_utils.pack_padded_sequence(\n",
    "#             x, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "#         )\n",
    "#         packed_out, _ = self.lstm(packed_x)\n",
    "#         lstm_out, _ = rnn_utils.pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "#         # Get final representation\n",
    "#         if self.use_attention:\n",
    "#             mask = self._create_attention_mask(lstm_out.size(1), lengths)\n",
    "#             context, _ = self.attention(lstm_out, mask)\n",
    "#         else:\n",
    "#             # Get last valid time step output\n",
    "#             indices = torch.clamp(lengths - 1, min=0)  # Prevent negative indices\n",
    "#             context = lstm_out[torch.arange(batch_size), indices, :]\n",
    "\n",
    "#         return self.classifier(context)\n",
    "\n",
    "#     def _create_attention_mask(self, max_len, lengths):\n",
    "#         \"\"\"Create attention mask from sequence lengths\"\"\"\n",
    "#         device = lengths.device\n",
    "#         return torch.arange(max_len, device=device).expand(len(lengths), max_len) < lengths.unsqueeze(1)\n",
    "\n",
    "#     def unfreeze_cnn_layers(self, num_layers=3, start_from_end=True):\n",
    "#         \"\"\"Gradually unfreeze CNN layers for fine-tuning\"\"\"\n",
    "#         # Get all CNN layers, not just conv layers\n",
    "#         all_cnn_layers = []\n",
    "#         for name, module in self.cnn.named_modules():\n",
    "#             if isinstance(module, (nn.Conv2d, nn.BatchNorm2d)):\n",
    "#                 all_cnn_layers.append(module)\n",
    "        \n",
    "#         # Sort conv layers first then BN layers\n",
    "#         conv_layers = [l for l in all_cnn_layers if isinstance(l, nn.Conv2d)]\n",
    "#         bn_layers = [l for l in all_cnn_layers if isinstance(l, nn.BatchNorm2d)]\n",
    "        \n",
    "#         # Decide which layers to unfreeze\n",
    "#         if start_from_end:\n",
    "#             layers_to_unfreeze = conv_layers[-num_layers:]\n",
    "#             # Also unfreeze corresponding BN layers\n",
    "#             bn_to_unfreeze = bn_layers[-num_layers:]\n",
    "#         else:\n",
    "#             layers_to_unfreeze = conv_layers[:num_layers]\n",
    "#             bn_to_unfreeze = bn_layers[:num_layers]\n",
    "        \n",
    "#         # Unfreeze selected layers\n",
    "#         for layer in layers_to_unfreeze + bn_to_unfreeze:\n",
    "#             for param in layer.parameters():\n",
    "#                 param.requires_grad = True\n",
    "\n",
    "#     def count_parameters(self):\n",
    "#         \"\"\"Count trainable parameters\"\"\"\n",
    "#         total_params = 0\n",
    "#         for name, parameter in self.named_parameters():\n",
    "#             if parameter.requires_grad:\n",
    "#                 params = parameter.numel()\n",
    "#                 print(f\"{name}: {params}\")\n",
    "#                 total_params += params\n",
    "#         print(f\"Total Trainable Params: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import math\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    \"\"\"Basic attention mechanism for sequence processing\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(input_size, hidden_size)\n",
    "        self.V = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.W.weight)\n",
    "        nn.init.xavier_uniform_(self.V.weight)\n",
    "        nn.init.zeros_(self.W.bias)\n",
    "        nn.init.zeros_(self.V.bias)\n",
    "\n",
    "    def forward(self, lstm_output, mask=None):\n",
    "        att_scores = self.V(torch.tanh(self.W(lstm_output))).squeeze(-1)\n",
    "        if mask is not None:\n",
    "            att_scores = att_scores.masked_fill(mask == 0, -1e9)\n",
    "        att_weights = F.softmax(att_scores, dim=1)\n",
    "        context = (lstm_output * att_weights.unsqueeze(-1)).sum(1)\n",
    "        return context, att_weights\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    \"\"\"Modular video action classifier with various configuration options\"\"\"\n",
    "    def __init__(self, num_classes,\n",
    "                 lstm_hidden_size=512,\n",
    "                 lstm_layers=1,\n",
    "                 dropout=0.5,\n",
    "                 freeze_cnn=True,\n",
    "                 use_attention=False,\n",
    "                 cnn_model='resnet18'):\n",
    "\n",
    "        super().__init__()\n",
    "        self.use_attention = use_attention\n",
    "        self.cnn_model = cnn_model\n",
    "\n",
    "        # CNN Feature Extractor\n",
    "        self.cnn, self.cnn_feature_size = self._build_cnn(cnn_model)\n",
    "        self._set_cnn_freeze(freeze_cnn)\n",
    "\n",
    "        lstm_input_size = self.cnn_feature_size\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_size,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self._init_lstm_weights()\n",
    "\n",
    "        if self.use_attention:\n",
    "            self.attention = AttentionLayer(\n",
    "                input_size=lstm_hidden_size,\n",
    "                hidden_size=lstm_hidden_size\n",
    "            )\n",
    "\n",
    "        self.classifier = self._build_classifier(\n",
    "            lstm_hidden_size,\n",
    "            num_classes,\n",
    "            dropout\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _build_cnn(self, model_name):\n",
    "        \"\"\"Initialize CNN feature extractor with proper feature sizes\"\"\"\n",
    "        if model_name == 'resnet18':\n",
    "            cnn = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.children())[:-2]), 512\n",
    "        elif model_name == 'mobilenet_v3':\n",
    "            cnn = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.children())[:-2]), 576\n",
    "        elif model_name == 'vgg16':\n",
    "            cnn = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.features)), 512\n",
    "        elif model_name == 'vgg19':\n",
    "            cnn = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.features)), 512\n",
    "        elif model_name == 'densenet121':\n",
    "            cnn = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.children())[:-1]), 1024\n",
    "        elif model_name == 'densenet201':\n",
    "            cnn = models.densenet201(weights=models.DenseNet201_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.children())[:-1]), 1920\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported CNN model: {model_name}\")\n",
    "\n",
    "    def _build_classifier(self, input_size, num_classes, dropout):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def _init_lstm_weights(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _set_cnn_freeze(self, freeze):\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = not freeze\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        batch_size, seq_len = x.size(0), x.size(1)\n",
    "        x = x.view(batch_size*seq_len, *x.size()[2:])\n",
    "        x = self.cnn(x)\n",
    "        \n",
    "        # Handle different CNN output shapes\n",
    "        if self.cnn_model in ['resnet18', 'mobilenet_v3', 'vgg16', 'vgg19', 'densenet121', 'densenet201']:\n",
    "            x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "            \n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "\n",
    "        packed_x = rnn_utils.pack_padded_sequence(\n",
    "            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_out, _ = self.lstm(packed_x)\n",
    "        lstm_out, _ = rnn_utils.pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        if self.use_attention:\n",
    "            mask = self._create_attention_mask(lstm_out.size(1), lengths)\n",
    "            context, _ = self.attention(lstm_out, mask)\n",
    "        else:\n",
    "            # print(lengths)\n",
    "            indices = torch.clamp(lengths - 1, min=0)\n",
    "            # print(indices)\n",
    "            context = lstm_out[torch.arange(batch_size), indices, :]\n",
    "\n",
    "        return self.classifier(context)\n",
    "\n",
    "    def _create_attention_mask(self, max_len, lengths):\n",
    "        device = lengths.device\n",
    "        return torch.arange(max_len, device=device).expand(len(lengths), max_len) < lengths.unsqueeze(1)\n",
    "\n",
    "    def unfreeze_cnn_layers(self, num_layers=3, start_from_end=True):\n",
    "        all_cnn_layers = []\n",
    "        for name, module in self.cnn.named_modules():\n",
    "            if isinstance(module, (nn.Conv2d, nn.BatchNorm2d)):\n",
    "                all_cnn_layers.append(module)\n",
    "        \n",
    "        conv_layers = [l for l in all_cnn_layers if isinstance(l, nn.Conv2d)]\n",
    "        bn_layers = [l for l in all_cnn_layers if isinstance(l, nn.BatchNorm2d)]\n",
    "        \n",
    "        if start_from_end:\n",
    "            layers_to_unfreeze = conv_layers[-num_layers:]\n",
    "            bn_to_unfreeze = bn_layers[-num_layers:] if bn_layers else []\n",
    "        else:\n",
    "            layers_to_unfreeze = conv_layers[:num_layers]\n",
    "            bn_to_unfreeze = bn_layers[:num_layers] if bn_layers else []\n",
    "        \n",
    "        for layer in layers_to_unfreeze + bn_to_unfreeze:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def count_parameters(self):\n",
    "        total_params = 0\n",
    "        for name, parameter in self.named_parameters():\n",
    "            if parameter.requires_grad:\n",
    "                params = parameter.numel()\n",
    "                print(f\"{name}: {params}\")\n",
    "                total_params += params\n",
    "        print(f\"Total Trainable Params: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:06.643307Z",
     "iopub.status.busy": "2025-02-26T09:07:06.643026Z",
     "iopub.status.idle": "2025-02-26T09:07:09.001724Z",
     "shell.execute_reply": "2025-02-26T09:07:09.000847Z",
     "shell.execute_reply.started": "2025-02-26T09:07:06.643278Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 10, 3, 224, 224])\n",
      "Output shape: torch.Size([4, 13])\n",
      "Loss value: 2.6924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNLSTM(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(512, 512, batch_first=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=512, out_features=13, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create model instance\n",
    "model = CNNLSTM(\n",
    "    num_classes=13,\n",
    "    lstm_hidden_size=512,\n",
    "    cnn_model=CNN_TYPE,\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Create dummy input\n",
    "batch_size = 4\n",
    "seq_length = 10\n",
    "channels = 3\n",
    "height = 224\n",
    "width = 224\n",
    "\n",
    "# Create random input tensor and labels\n",
    "x = torch.randn(batch_size, seq_length, channels, height, width).to(device)\n",
    "lengths = torch.full((batch_size,), seq_length, dtype=torch.long).to(device)\n",
    "labels = torch.randint(0, 13, (batch_size,)).to(device)  # Generate labels between 0 and 12 (13 classes)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(x, lengths)\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {outputs.shape}\")\n",
    "print(f\"Loss value: {loss.item():.4f}\")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:09.002946Z",
     "iopub.status.busy": "2025-02-26T09:07:09.002646Z",
     "iopub.status.idle": "2025-02-26T09:07:09.007971Z",
     "shell.execute_reply": "2025-02-26T09:07:09.007124Z",
     "shell.execute_reply.started": "2025-02-26T09:07:09.002913Z"
    },
    "id": "GFgBfmOSCZC9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "def save_checkpoint(model, optimizer, epoch, history, save_path = SAVE_PATH, best_path=None):\n",
    "    if best_path is not None:\n",
    "        # chk_path = os.path.join(save_path, f'best_model.pth')\n",
    "        chk_path = best_path\n",
    "        print(f\"Saving checkpoint to {chk_path}\")\n",
    "    else:\n",
    "        chk_path = os.path.join(save_path, f'checkpath_model.pth')\n",
    "        print(f\"Saving checkpoint to {chk_path}\")\n",
    "\n",
    "    # Combine model, optimizer, and history into one dictionary\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,  # Save the next epoch number for resuming\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'history': history  # Save history along with the model and optimizer\n",
    "    }\n",
    "\n",
    "    # Save everything in a single file using torch.save\n",
    "    torch.save(checkpoint, chk_path)\n",
    "    print(f\"Checkpoint saved at epoch {epoch + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:09.009074Z",
     "iopub.status.busy": "2025-02-26T09:07:09.008769Z",
     "iopub.status.idle": "2025-02-26T09:07:09.023879Z",
     "shell.execute_reply": "2025-02-26T09:07:09.023147Z",
     "shell.execute_reply.started": "2025-02-26T09:07:09.009046Z"
    },
    "id": "mZprkJQvCZC9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Load model and training state from a checkpoint\n",
    "    \"\"\"\n",
    "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only = False)\n",
    "\n",
    "    # Load model and optimizer states\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    # Get the epoch number to resume from\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "    # Load training history with new metrics\n",
    "    history = checkpoint.get('history', {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': [],\n",
    "        'train_precision': [], 'train_recall': [], 'train_f1': [],\n",
    "        'val_precision': [], 'val_recall': [], 'val_f1': [],\n",
    "        'learning_rates': []\n",
    "    })\n",
    "\n",
    "    return model, optimizer, start_epoch, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:09.024911Z",
     "iopub.status.busy": "2025-02-26T09:07:09.024661Z",
     "iopub.status.idle": "2025-02-26T09:07:09.042008Z",
     "shell.execute_reply": "2025-02-26T09:07:09.041198Z",
     "shell.execute_reply.started": "2025-02-26T09:07:09.024878Z"
    },
    "id": "dkDP9PAlCZC9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
    "    def __init__(self, patience=7, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        # on default = 7 successive val_loss increase stop\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:09.043109Z",
     "iopub.status.busy": "2025-02-26T09:07:09.042817Z",
     "iopub.status.idle": "2025-02-26T09:07:09.057692Z",
     "shell.execute_reply": "2025-02-26T09:07:09.056922Z",
     "shell.execute_reply.started": "2025-02-26T09:07:09.043081Z"
    },
    "id": "g8OLd0ZqOHVS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_per_class_metric(precision, recall, f1, epoch=0, pose_list=None, master_save_path=SAVE_PATH, fold= None):\n",
    "    \"\"\"\n",
    "    Plots and saves per-class metrics (Precision, Recall, F1-score) for the given epoch.\n",
    "\n",
    "    Args:\n",
    "        precision (list): Per-class precision values.\n",
    "        recall (list): Per-class recall values.\n",
    "        f1 (list): Per-class F1-score values.\n",
    "        epoch (int): Current epoch number.\n",
    "        pose_list (list): List of class names (strings) corresponding to class indices.\n",
    "        master_save_path (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    if pose_list is None:\n",
    "        pose_list = [str(i) for i in range(len(precision))]  # Default to numeric labels\n",
    "\n",
    "    save_dir = os.path.join(master_save_path, f'per_class_metric_{fold}')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    save_file_path = os.path.join(save_dir, f'per_class_metric_epoch_{epoch}.png')\n",
    "\n",
    "    # Adjust x-axis positions for grouped bars\n",
    "    x = range(len(pose_list))\n",
    "\n",
    "    plt.bar([i - 0.2 for i in x], precision, width=0.2, label='Precision', align='center')\n",
    "    plt.bar(x, recall, width=0.2, label='Recall', align='center')\n",
    "    plt.bar([i + 0.2 for i in x], f1, width=0.2, label='F1-Score', align='center')\n",
    "\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(f'Per-Class Metrics - Epoch {epoch}')\n",
    "    plt.xticks(x, pose_list, rotation=45, ha='right')  # Use pose_list for x-axis labels\n",
    "    plt.legend()\n",
    "    plt.tight_layout()  # Adjust layout to fit rotated labels\n",
    "    plt.savefig(save_file_path)\n",
    "    plt.show()\n",
    "\n",
    "def per_class_metric(true, pred, epoch, pose_list=pose_list, average=None, fold=None):\n",
    "    \"\"\"\n",
    "    Computes and logs per-class metrics (Precision, Recall, F1-score).\n",
    "\n",
    "    Args:\n",
    "        true (list): Ground-truth labels.\n",
    "        pred (list): Predicted labels.\n",
    "        epoch (int): Current epoch number.\n",
    "        pose_list (list): List of class names (strings) corresponding to class indices.\n",
    "        average (str or None): Averaging method for sklearn metrics (None for per-class).\n",
    "    \"\"\"\n",
    "    per_class_precision = precision_score(true, pred, average=average, zero_division=0)\n",
    "    per_class_recall = recall_score(true, pred, average=average, zero_division=0)\n",
    "    per_class_f1 = f1_score(true, pred, average=average, zero_division=0)\n",
    "\n",
    "    print(f\"Per-Class Metrics for Epoch {epoch}:\")\n",
    "    for i, (prec, rec, f1) in enumerate(zip(per_class_precision, per_class_recall, per_class_f1)):\n",
    "        class_name = pose_list[i] if pose_list else f\"Class {i}\"\n",
    "        print(f\"{class_name}: Precision={prec:.2f}, Recall={rec:.2f}, F1-Score={f1:.2f}\")\n",
    "\n",
    "    plot_per_class_metric(per_class_precision, per_class_recall, per_class_f1, epoch, pose_list, fold=fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:09.058892Z",
     "iopub.status.busy": "2025-02-26T09:07:09.058531Z",
     "iopub.status.idle": "2025-02-26T09:07:09.078149Z",
     "shell.execute_reply": "2025-02-26T09:07:09.077366Z",
     "shell.execute_reply.started": "2025-02-26T09:07:09.058862Z"
    },
    "id": "nNTAFuncCZC9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, dataset,fold, num_epochs=50, patience=18, log_interval=10, checkpoint_path=None, unfreeze_epoch=5, num_layers_unfreeze=3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # Initialize scheduler\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=patience, min_delta=1e-4)\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Initialize history for loss, accuracy, precision, recall, and F1\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': [],\n",
    "        'train_precision': [], 'train_recall': [], 'train_f1': [],\n",
    "        'val_precision': [], 'val_recall': [], 'val_f1': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "\n",
    "    # Check for checkpoint and load if available\n",
    "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        model, optimizer, start_epoch, history = load_checkpoint(model, optimizer, checkpoint_path)\n",
    "        print(f\"Resuming training from epoch {start_epoch}\")\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        if epoch == 14 and not FROZEN:\n",
    "            print(\"UNFREEZING CNN LAYERS:\", NUM_LAYERS_TO_UNFREEZE)\n",
    "            model.unfreeze_cnn_layers(num_layers=NUM_LAYERS_TO_UNFREEZE)\n",
    "        dataset.use_augmentation = True #############\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        history['learning_rates'].append(current_lr)\n",
    "        print(f\"Current Learning Rate: {current_lr}\")\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        train_loader_tqdm = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n",
    "        for batch_idx, (inputs, labels, lengths) in train_loader_tqdm:\n",
    "            inputs, labels, lengths = inputs.to(device), labels.to(device), lengths.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "            if inputs.size(0) != BATCH_SIZE:\n",
    "                print(\"INPUT_SIZE:\", inputs.size(0))\n",
    "            # Collect true and predicted labels for precision/recall\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "            train_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Log batch-level updates\n",
    "            if batch_idx % log_interval == 0:\n",
    "                train_loader_tqdm.set_postfix({\n",
    "                    'loss': train_loss / (BATCH_SIZE * (batch_idx + 1)),\n",
    "                    'accuracy': 100.0 * train_correct / train_total\n",
    "                })\n",
    "\n",
    "        # Calculate training metrics\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        print(\"TRAIN LOADER LENGTH:\", len(train_loader.dataset))\n",
    "        print(\"TRAIN TOTAL:\", train_total)\n",
    "        train_acc = 100.0 * train_correct / train_total\n",
    "        train_precision = precision_score(train_true, train_pred, average='macro')\n",
    "        train_recall = recall_score(train_true, train_pred, average='macro')\n",
    "        train_f1 = f1_score(train_true, train_pred, average='macro')\n",
    "\n",
    "        per_class_metric(train_true, train_pred, epoch, fold=fold)\n",
    "\n",
    "        dataset.use_augmentation = False\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        val_true, val_pred = [], []\n",
    "\n",
    "        val_loader_tqdm = tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validation\")\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels, lengths) in val_loader_tqdm:\n",
    "                inputs, labels, lengths = inputs.to(device), labels.to(device), lengths.to(device)\n",
    "                outputs = model(inputs, lengths)  # Pass sequence lengths to model forward function\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                # Collect true and predicted labels for precision/recall\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "                val_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "                # Log batch-level updates for validation\n",
    "                if batch_idx % log_interval == 0:\n",
    "                    val_loader_tqdm.set_postfix({\n",
    "                        'loss': val_loss / (BATCH_SIZE * (batch_idx + 1)),\n",
    "                        'accuracy': 100.0 * val_correct / val_total\n",
    "                    })\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = 100.0 * val_correct / val_total\n",
    "        val_precision = precision_score(val_true, val_pred, average='macro')\n",
    "        val_recall = recall_score(val_true, val_pred, average='macro')\n",
    "        val_f1 = f1_score(val_true, val_pred, average='macro')\n",
    "        # Per-class metrics for validation\n",
    "        per_class_metric(val_true, val_pred, epoch, fold=fold)\n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['train_precision'].append(train_precision)\n",
    "        history['train_recall'].append(train_recall)\n",
    "        history['train_f1'].append(train_f1)\n",
    "        history['val_precision'].append(val_precision)\n",
    "        history['val_recall'].append(val_recall)\n",
    "        history['val_f1'].append(val_f1)\n",
    "\n",
    "        # Print metrics at the end of the epoch\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs} Summary:')\n",
    "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Train Precision: {train_precision:.2f} | Train Recall: {train_recall:.2f} | Train F1: {train_f1:.2f}')\n",
    "        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | Val Precision: {val_precision:.2f} | Val Recall: {val_recall:.2f} | Val F1: {val_f1:.2f}')\n",
    "\n",
    "        # Save the best model checkpoint\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_path = os.path.join(SAVE_PATH, f'best_model_fold_{fold}.pth')\n",
    "            if best_model_path is not None:\n",
    "                print(best_model_path)\n",
    "            save_checkpoint(model, optimizer, epoch, history, SAVE_PATH, best_model_path)\n",
    "            print(f\"New best model saved! Validation Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "        # Adjust learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Check for early stopping\n",
    "        # early_stopping(val_loss)\n",
    "        # if early_stopping.early_stop:\n",
    "        #     print(\"Early stopping triggered\")\n",
    "        #     break\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:09.079201Z",
     "iopub.status.busy": "2025-02-26T09:07:09.078988Z",
     "iopub.status.idle": "2025-02-26T09:07:09.400546Z",
     "shell.execute_reply": "2025-02-26T09:07:09.399896Z",
     "shell.execute_reply.started": "2025-02-26T09:07:09.079183Z"
    },
    "id": "8MayBbiF0gtk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, class_names, spath=SAVE_PATH, fsave='confusion_matrix_accuracy.png', fold = None):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        test_loader: DataLoader for test data\n",
    "        criterion: Loss function\n",
    "        class_names: List of class names\n",
    "        spath: Directory to save the plot\n",
    "        fsave: Filename for confusion matrix plot\n",
    "\n",
    "    Returns:\n",
    "        test_loss: Average test loss\n",
    "        accuracy: Test accuracy\n",
    "        precision: Macro precision score\n",
    "        recall: Macro recall score\n",
    "        f1: Macro F1 score\n",
    "    \"\"\"\n",
    "    ffsave = f'fold_{fold}_{fsave}'\n",
    "    csave = os.path.join(spath, ffsave)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in test_loader_tqdm:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            outputs = model(inputs, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    accuracy = 100 * test_correct / test_total\n",
    "\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))  # Increased figure size\n",
    "    plt.subplot(111, position=[0.1, 0.2, 0.8, 0.7])  # Adjust main plot position to leave room for text\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    \n",
    "    # Prepare metrics text\n",
    "    metrics_text = (f'Test Loss: {test_loss:.4f}\\n'\n",
    "                    f'Test Accuracy: {accuracy:.2f}%\\n'\n",
    "                    f'Precision (Weighted): {precision:.4f}\\n'\n",
    "                    f'Recall (Weighted): {recall:.4f}\\n'\n",
    "                    f'F1 Score (Weighted): {f1:.4f}')\n",
    "    \n",
    "    # Add metrics text to the figure\n",
    "    plt.gcf().text(0, 0.01, metrics_text, fontsize=12, ha='left', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2)  # Leave space at bottom for metrics\n",
    "    plt.savefig(csave, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Precision (Weighted): {precision:.4f}')\n",
    "    print(f'Recall (Weighted): {recall:.4f}')\n",
    "    print(f'F1 Score (Weighted): {f1:.4f}')\n",
    "    \n",
    "    # Store metrics in a dictionary\n",
    "    metrics = {\n",
    "        'loss': test_loss,       # Test loss value\n",
    "        'accuracy': accuracy,    # Test accuracy percentage\n",
    "        'precision': precision,  # Weighted precision\n",
    "        'recall': recall,        # Weighted recall\n",
    "        'f1': f1                 # Weighted F1 score\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "    # Calculate metrics with macro averaging\n",
    "    # precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "    # recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "    # f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "    \n",
    "    # plt.figure(figsize=(12, 10))  # Increased figure size\n",
    "    # plt.subplot(111, position=[0.1, 0.2, 0.8, 0.7])  # Adjust main plot position to leave room for text\n",
    "    # cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    # # plt.figure(figsize=(10, 8))\n",
    "    # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "    #             xticklabels=class_names, yticklabels=class_names)\n",
    "    # plt.title('Confusion Matrix')\n",
    "    # plt.xlabel('Predicted')\n",
    "    # plt.ylabel('True')\n",
    "\n",
    "    # # Prepare metrics text\n",
    "    # metrics_text = (f'Test Loss: {test_loss:.4f}\\n'\n",
    "    #                 f'Test Accuracy: {accuracy:.2f}%\\n'\n",
    "    #                 f'Precision (Macro): {precision:.4f}\\n'\n",
    "    #                 f'Recall (Macro): {recall:.4f}\\n'\n",
    "    #                 f'F1 Score (Macro): {f1:.4f}')\n",
    "\n",
    "    # # Add metrics text to the figure\n",
    "    # plt.gcf().text(0, 0.01, metrics_text, fontsize=12, ha='left', va='bottom')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.subplots_adjust(bottom=0.2)  # Leave space at bottom for metrics\n",
    "    # # Save with tight layout to include all elements\n",
    "    # plt.savefig(csave, bbox_inches='tight')\n",
    "    # plt.show()\n",
    "    # plt.close()\n",
    "\n",
    "    # print(f'Test Loss: {test_loss:.4f}')\n",
    "    # print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    # print(f'Precision (Macro): {precision:.4f}')\n",
    "    # print(f'Recall (Macro): {recall:.4f}')\n",
    "    # print(f'F1 Score (Macro): {f1:.4f}')\n",
    "\n",
    "    # # return test_loss, accuracy, precision, recall, f1\n",
    "    # metrics = {\n",
    "    # 'loss': test_loss,       # Test loss value\n",
    "    # 'accuracy': accuracy,    # Test accuracy percentage\n",
    "    # 'precision': precision,  # Macro-averaged precision\n",
    "    # 'recall': recall,        # Macro-averaged recall\n",
    "    # 'f1': f1                 # Macro-averaged F1 score\n",
    "    # }\n",
    "\n",
    "    # # return test_loss, accuracy, precision, recall, f1\n",
    "    # return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:09.404006Z",
     "iopub.status.busy": "2025-02-26T09:07:09.403618Z",
     "iopub.status.idle": "2025-02-26T09:07:21.198192Z",
     "shell.execute_reply": "2025-02-26T09:07:21.197340Z",
     "shell.execute_reply.started": "2025-02-26T09:07:09.403983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def evaluate_model_normalized(model, test_loader, criterion, class_names, writer=None, global_step=0, spath=SAVE_PATH, fsave='confusion_matrix_normalized.png', fold=None):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set and log results to TensorBoard.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        test_loader: DataLoader for test data\n",
    "        criterion: Loss function\n",
    "        class_names: List of class names\n",
    "        writer: TensorBoard SummaryWriter (optional)\n",
    "        global_step: Step for logging test metrics (e.g., epoch number)\n",
    "        spath: Directory to save the plot\n",
    "        fsave: Filename for confusion matrix plot\n",
    "\n",
    "    Returns:\n",
    "        test_loss: Average test loss\n",
    "        accuracy: Test accuracy\n",
    "        precision: Macro precision score\n",
    "        recall: Macro recall score\n",
    "        f1: Macro F1 score\n",
    "    \"\"\"\n",
    "    # csave = os.path.join(spath, fsave)\n",
    "    ffsave = f'fold_{fold}_{fsave}'\n",
    "    # csave = os.path.join(spath, fsave)\n",
    "    csave = os.path.join(spath, ffsave)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in test_loader_tqdm:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            outputs = model(inputs, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    accuracy = 100 * test_correct / test_total\n",
    "\n",
    "    # Calculate metrics with macro averaging\n",
    "    precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "    recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "\n",
    "    plt.figure(figsize=(12, 10))  # Increased figure size\n",
    "    plt.subplot(111, position=[0.1, 0.2, 0.8, 0.7])  # Adjust main plot position to leave room for text\n",
    "\n",
    "    # Calculate confusion matrix and normalize it\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    # Replace NaN values (from division by zero) with 0\n",
    "    cm_normalized = np.nan_to_num(cm_normalized)\n",
    "\n",
    "    # plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Prepare metrics text\n",
    "    metrics_text = (f'Test Loss: {test_loss:.4f}\\n'\n",
    "                    f'Test Accuracy: {accuracy:.2f}%\\n'\n",
    "                    f'Precision (Macro): {precision:.4f}\\n'\n",
    "                    f'Recall (Macro): {recall:.4f}\\n'\n",
    "                    f'F1 Score (Macro): {f1:.4f}')\n",
    "\n",
    "    # Add metrics text to the figure\n",
    "    plt.gcf().text(0, 0, metrics_text, fontsize=12, ha='left', va='bottom')\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.2)  # Leave space at bottom for metrics\n",
    "\n",
    "    # Save with tight layout to include all elements\n",
    "    plt.savefig(csave, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Precision (Macro): {precision:.4f}')\n",
    "    print(f'Recall (Macro): {recall:.4f}')\n",
    "    print(f'F1 Score (Macro): {f1:.4f}')\n",
    "\n",
    "    metrics = {\n",
    "    'loss': test_loss,       # Test loss value\n",
    "    'accuracy': accuracy,    # Test accuracy percentage\n",
    "    'precision': precision,  # Macro-averaged precision\n",
    "    'recall': recall,        # Macro-averaged recall\n",
    "    'f1': f1                 # Macro-averaged F1 score\n",
    "    }\n",
    "\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.200220Z",
     "iopub.status.busy": "2025-02-26T09:07:21.199711Z",
     "iopub.status.idle": "2025-02-26T09:07:21.204638Z",
     "shell.execute_reply": "2025-02-26T09:07:21.203673Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.200195Z"
    },
    "id": "YagSnOqwmGn9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    frames, labels = zip(*batch)  # Separate frames and labels\n",
    "    # FRAMES == DATA same thing shape (N, T, C, H, W)\n",
    "    # Pad the sequences of frames for each video in the batch along the sequence dimension\n",
    "    frames_padded = pad_sequence(frames, batch_first=True, padding_value=0)  # Shape: [batch_size, max_seq_len, 3, 224, 224]\n",
    "    lengths = torch.tensor([len(seq) for seq in frames])  # Record original sequence lengths\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return frames_padded, labels, lengths  # Return lengths for packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.205966Z",
     "iopub.status.busy": "2025-02-26T09:07:21.205521Z",
     "iopub.status.idle": "2025-02-26T09:07:21.240729Z",
     "shell.execute_reply": "2025-02-26T09:07:21.239787Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.205936Z"
    },
    "id": "7EWkYX8sCZC-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "def train_test_split(dataset, test_split = TEST_SPLIT):\n",
    "    total_size = len(dataset)\n",
    "    test_size = int(test_split * total_size)\n",
    "    train_size = total_size - test_size\n",
    "\n",
    "    train_dataset, test_dataset = random_split(\n",
    "        dataset,\n",
    "        [train_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
    "    )\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def create_data_loaders(train_dataset, test_dataset, batch_size = BATCH_SIZE):\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        # num_workers=,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.241984Z",
     "iopub.status.busy": "2025-02-26T09:07:21.241665Z",
     "iopub.status.idle": "2025-02-26T09:07:21.257247Z",
     "shell.execute_reply": "2025-02-26T09:07:21.256521Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.241955Z"
    },
    "id": "-nVQoc_DCZC-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_training_curves(history, fold):\n",
    "    fsave=f'training_curves_fold_{fold}.png'\n",
    "    tsave = os.path.join(SAVE_PATH, fsave)\n",
    "    # plt.style.use('seaborn')\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "    # Loss curves\n",
    "    axs[0, 0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "    axs[0, 0].plot(history['val_loss'], label='Validation Loss', marker='o')\n",
    "    axs[0, 0].set_title('Loss')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    # Accuracy curves\n",
    "    axs[0, 1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "    axs[0, 1].plot(history['val_acc'], label='Validation Accuracy', marker='o')\n",
    "    axs[0, 1].set_title('Accuracy')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # Learning rate\n",
    "    axs[0, 2].plot(history['learning_rates'], label='Learning Rate', marker='o')\n",
    "    axs[0, 2].set_title('Learning Rate')\n",
    "    axs[0, 2].set_yscale('log')\n",
    "    axs[0, 2].legend()\n",
    "\n",
    "    # Precision\n",
    "    axs[1, 0].plot(history['train_precision'], label='Train Precision', marker='o')\n",
    "    axs[1, 0].plot(history['val_precision'], label='Validation Precision', marker='o')\n",
    "    axs[1, 0].set_title('Precision')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    # Recall\n",
    "    axs[1, 1].plot(history['train_recall'], label='Train Recall', marker='o')\n",
    "    axs[1, 1].plot(history['val_recall'], label='Validation Recall', marker='o')\n",
    "    axs[1, 1].set_title('Recall')\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    # F1 Score\n",
    "    axs[1, 2].plot(history['train_f1'], label='Train F1', marker='o')\n",
    "    axs[1, 2].plot(history['val_f1'], label='Validation F1', marker='o')\n",
    "    axs[1, 2].set_title('F1 Score')\n",
    "    axs[1, 2].legend()\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(tsave)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.258331Z",
     "iopub.status.busy": "2025-02-26T09:07:21.258044Z",
     "iopub.status.idle": "2025-02-26T09:07:21.279656Z",
     "shell.execute_reply": "2025-02-26T09:07:21.278732Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.258306Z"
    },
    "id": "7LXXcX28u5Ar",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def get_class_weights(pose_list, num_classes, strategy='balanced'):\n",
    "    \"\"\"\n",
    "    Calculate class weights with proper class index alignment.\n",
    "\n",
    "    Args:\n",
    "        pose_list: List of labels/poses in the dataset\n",
    "        num_classes: Total number of classes\n",
    "        strategy: Weighting strategy ('balanced', 'inverse', 'effective_samples', 'sqrt_inverse')\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Class weights tensor aligned with class indices\n",
    "    \"\"\"\n",
    "    # Count samples per class\n",
    "    class_counts = Counter(pose_list)\n",
    "    total_samples = len(pose_list)\n",
    "\n",
    "    # Initialize weights array with zeros for all possible classes\n",
    "    weights = np.zeros(num_classes)\n",
    "\n",
    "    if strategy == 'balanced':\n",
    "        # Use sklearn's balanced weighting\n",
    "        unique_classes = sorted(class_counts.keys())\n",
    "        sklearn_weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.array(unique_classes),\n",
    "            y=pose_list\n",
    "        )\n",
    "        # Map weights to correct indices\n",
    "        for idx, class_label in enumerate(unique_classes):\n",
    "            weights[class_label] = sklearn_weights[idx]\n",
    "\n",
    "    elif strategy == 'inverse':\n",
    "        # Inverse of sample frequency\n",
    "        for class_label, count in class_counts.items():\n",
    "            weights[class_label] = total_samples / (num_classes * count)\n",
    "\n",
    "    elif strategy == 'effective_samples':\n",
    "        # Effective number of samples weighting\n",
    "        beta = 0.9999\n",
    "        for class_label, count in class_counts.items():\n",
    "            weights[class_label] = (1 - beta) / (1 - beta ** count)\n",
    "\n",
    "    elif strategy == 'sqrt_inverse':\n",
    "        # Square root of inverse frequency\n",
    "        for class_label, count in class_counts.items():\n",
    "            weights[class_label] = np.sqrt(total_samples / (num_classes * count))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown weighting strategy: {strategy}\")\n",
    "\n",
    "    # Convert to tensor and normalize\n",
    "    weights = torch.FloatTensor(weights)\n",
    "    weights = weights / weights.sum() * len(weights)\n",
    "\n",
    "    return weights\n",
    "\n",
    "def create_weighted_criterion(pose_list, num_classes, strategy='balanced'):\n",
    "    \"\"\"\n",
    "    Create a weighted CrossEntropyLoss criterion.\n",
    "\n",
    "    Args:\n",
    "        pose_list: List of labels/poses in the dataset\n",
    "        num_classes: Total number of classes\n",
    "        strategy: Weighting strategy for calculating class weights\n",
    "\n",
    "    Returns:\n",
    "        nn.CrossEntropyLoss: Weighted loss criterion\n",
    "    \"\"\"\n",
    "    weights = get_class_weights(pose_list, num_classes, strategy)\n",
    "    print(\"Class weights aligned with indices:\", weights)\n",
    "    if torch.cuda.is_available():\n",
    "        weights = weights.cuda()\n",
    "    return nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "def analyze_class_distribution(pose_list):\n",
    "    \"\"\"\n",
    "    Analyze and print class distribution information.\n",
    "\n",
    "    Args:\n",
    "        pose_list: List of labels/poses in the dataset\n",
    "    \"\"\"\n",
    "    class_counts = Counter(pose_list)\n",
    "    total_samples = len(pose_list)\n",
    "\n",
    "    print(\"\\nClass Distribution Analysis:\")\n",
    "    print(\"-\" * 50)\n",
    "    for class_idx, count in sorted(class_counts.items()):\n",
    "        percentage = (count / total_samples) * 100\n",
    "        print(f\"Class {class_idx}: {count} samples ({percentage:.2f}%)\")\n",
    "\n",
    "    # Calculate imbalance metrics\n",
    "    max_count = max(class_counts.values())\n",
    "    min_count = min(class_counts.values())\n",
    "    imbalance_ratio = max_count / min_count\n",
    "\n",
    "    print(\"\\nImbalance Statistics:\")\n",
    "    print(f\"Imbalance Ratio (max/min): {imbalance_ratio:.2f}\")\n",
    "    print(f\"Maximum class size: {max_count}\")\n",
    "    print(f\"Minimum class size: {min_count}\")\n",
    "    print(f\"Average class size: {total_samples/len(class_counts):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.280757Z",
     "iopub.status.busy": "2025-02-26T09:07:21.280437Z",
     "iopub.status.idle": "2025-02-26T09:07:21.298821Z",
     "shell.execute_reply": "2025-02-26T09:07:21.297910Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.280732Z"
    },
    "id": "fqt2Ho_GOHVT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "def create_data_loaders(train_idx, val_idx, dataset, batch_size=BATCH_SIZE):\n",
    "    # Create subsets for this fold\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "    # Create data loaders with optional collate_fn\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.299828Z",
     "iopub.status.busy": "2025-02-26T09:07:21.299616Z",
     "iopub.status.idle": "2025-02-26T09:07:21.317094Z",
     "shell.execute_reply": "2025-02-26T09:07:21.316011Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.299807Z"
    },
    "id": "RcWrvy4ZNiYj",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_average_history(histories):\n",
    "    \"\"\"\n",
    "    Compute the average history across multiple folds.\n",
    "\n",
    "    Args:\n",
    "        histories (list of dict): List of history dictionaries from all folds. Each dictionary contains\n",
    "                                  metrics like 'train_loss', 'val_loss', 'train_accuracy', etc., as lists.\n",
    "\n",
    "    Returns:\n",
    "        dict: Averaged history containing the same keys as the input histories.\n",
    "    \"\"\"\n",
    "    avg_history = {}\n",
    "    num_folds = len(histories)\n",
    "\n",
    "    for key in histories[0]:  # Iterate over metric names\n",
    "        # Initialize a list for each metric\n",
    "        avg_history[key] = [0.0] * len(histories[0][key])  # Assume all folds have same length histories\n",
    "\n",
    "        # Sum across all folds\n",
    "        for fold_history in histories:\n",
    "            for i, value in enumerate(fold_history[key]):\n",
    "                avg_history[key][i] += value\n",
    "\n",
    "        # Divide by the number of folds to compute the average\n",
    "        avg_history[key] = [val / num_folds for val in avg_history[key]]\n",
    "\n",
    "    return avg_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.318964Z",
     "iopub.status.busy": "2025-02-26T09:07:21.318595Z",
     "iopub.status.idle": "2025-02-26T09:07:21.340827Z",
     "shell.execute_reply": "2025-02-26T09:07:21.340131Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.318881Z"
    },
    "id": "gX9YM1zJNj3A",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def save_folds(meta_info_path, skf, folds, architecture=ARCHITECTURE):\n",
    "    if architecture == '2D_CNN_LSTM':\n",
    "        folds_path = os.path.join(meta_info_path, f\"{architecture}_folds.pkl\")\n",
    "        skf_path = os.path.join(meta_info_path, f\"{architecture}_skf.pkl\")\n",
    "    else:\n",
    "        folds_path = os.path.join(meta_info_path, \"folds.pkl\")\n",
    "        skf_path = os.path.join(meta_info_path, \"skf.pkl\")\n",
    "\n",
    "    with open(folds_path, \"wb\") as f:\n",
    "        pickle.dump(folds, f)\n",
    "\n",
    "    with open(skf_path, \"wb\") as f:\n",
    "        pickle.dump(skf, f)\n",
    "\n",
    "def load_folds(meta_info_path, architecture=ARCHITECTURE):\n",
    "    if architecture == '2D_CNN_LSTM':\n",
    "        folds_path = os.path.join(meta_info_path, f\"{architecture}_folds.pkl\")\n",
    "        skf_path = os.path.join(meta_info_path, f\"{architecture}_skf.pkl\")\n",
    "    else:\n",
    "        folds_path = os.path.join(meta_info_path, \"folds.pkl\")\n",
    "        skf_path = os.path.join(meta_info_path, \"skf.pkl\")\n",
    "\n",
    "    if os.path.exists(folds_path) and os.path.exists(skf_path):\n",
    "        with open(folds_path, \"rb\") as f:\n",
    "            folds = pickle.load(f)\n",
    "        with open(skf_path, \"rb\") as f:\n",
    "            skf = pickle.load(f)\n",
    "        return skf, folds\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.342100Z",
     "iopub.status.busy": "2025-02-26T09:07:21.341747Z",
     "iopub.status.idle": "2025-02-26T09:07:21.349732Z",
     "shell.execute_reply": "2025-02-26T09:07:21.348915Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.342070Z"
    },
    "id": "Vn5XpTqG6_6J",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "def get_weighted_loss_criterion(train_dataset, train_indices=None, meta_info_path=None, fold=None):\n",
    "    \"\"\"\n",
    "    Get or compute weighted loss criterion, with caching support.\n",
    "\n",
    "    Args:\n",
    "        train_dataset: The training dataset\n",
    "        train_indices: Optional indices for cross-validation fold\n",
    "        meta_info_path: Path to save/load cached criteria\n",
    "        fold: Current fold number (required if using caching)\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.CrossEntropyLoss with computed weights\n",
    "    \"\"\"\n",
    "    if meta_info_path and fold is not None:\n",
    "        criterion_cache_path = os.path.join(meta_info_path, f'criterion_fold_{fold}.pkl')\n",
    "\n",
    "        # Try to load cached criterion\n",
    "        if os.path.exists(criterion_cache_path):\n",
    "            try:\n",
    "                with open(criterion_cache_path, 'rb') as f:\n",
    "                    cached_data = pickle.load(f)\n",
    "\n",
    "                # Verify the cached criterion matches current data\n",
    "                if verify_criterion_cache(cached_data, train_indices):\n",
    "                    print(f\"Loading cached criterion for fold {fold}\")\n",
    "                    return cached_data['criterion']\n",
    "                else:\n",
    "                    print(f\"Cached criterion for fold {fold} is invalid, recomputing...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading cached criterion: {e}, recomputing...\")\n",
    "\n",
    "    # Compute criterion if no cache exists or verification failed\n",
    "    if train_indices is not None:\n",
    "        labels = [train_dataset[i][1] for i in train_indices]\n",
    "    else:\n",
    "        labels = [train_dataset[i][1] for i in range(len(train_dataset))]\n",
    "\n",
    "    analyze_class_distribution(labels)\n",
    "    criterion = create_weighted_criterion(\n",
    "        labels,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        strategy='effective_samples'\n",
    "    )\n",
    "\n",
    "    # Cache the computed criterion if path is provided\n",
    "    if meta_info_path and fold is not None:\n",
    "        os.makedirs(meta_info_path, exist_ok=True)\n",
    "        cache_data = {\n",
    "            'criterion': criterion,\n",
    "            'train_indices': train_indices,\n",
    "            'fold': fold\n",
    "        }\n",
    "        with open(criterion_cache_path, 'wb') as f:\n",
    "            pickle.dump(cache_data, f)\n",
    "        print(f\"Cached criterion for fold {fold}\")\n",
    "\n",
    "    return criterion\n",
    "\n",
    "def verify_criterion_cache(cached_data, current_train_indices):\n",
    "    \"\"\"\n",
    "    Verify that cached criterion matches current training indices.\n",
    "\n",
    "    Args:\n",
    "        cached_data: Dictionary containing cached criterion and metadata\n",
    "        current_train_indices: Current training indices to verify against\n",
    "\n",
    "    Returns:\n",
    "        bool: True if cache is valid, False otherwise\n",
    "    \"\"\"\n",
    "    cached_indices = cached_data['train_indices']\n",
    "    if cached_indices is None and current_train_indices is None:\n",
    "        return True\n",
    "    if cached_indices is None or current_train_indices is None:\n",
    "        return False\n",
    "    return len(cached_indices) == len(current_train_indices) and all(\n",
    "        a == b for a, b in zip(sorted(cached_indices), sorted(current_train_indices))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.350656Z",
     "iopub.status.busy": "2025-02-26T09:07:21.350418Z",
     "iopub.status.idle": "2025-02-26T09:07:21.669630Z",
     "shell.execute_reply": "2025-02-26T09:07:21.668623Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.350628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model_final(model, train_loader, criterion, optimizer, dataset, fold, num_epochs, log_interval=10, writer=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Train the final model on the full dataset without a validation set.\n",
    "    Logs training metrics to TensorBoard and saves the model.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # Initialize scheduler (optional, based on training loss since no validation)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4)\n",
    "\n",
    "    # Initialize history for training metrics only\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'train_precision': [],\n",
    "        'train_recall': [],\n",
    "        'train_f1': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        dataset.use_augmentation = True  # Enable augmentation\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        history['learning_rates'].append(current_lr)\n",
    "        print(f\"Current Learning Rate: {current_lr}\")\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        train_loader_tqdm = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n",
    "        for batch_idx, (inputs, labels, lengths) in train_loader_tqdm:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            # Collect true and predicted labels for precision/recall\n",
    "            train_true.extend(labels.cpu().numpy())\n",
    "            train_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                train_loader_tqdm.set_postfix({\n",
    "                    'loss': train_loss / (BATCH_SIZE * (batch_idx + 1)),\n",
    "                    'accuracy': 100.0 * train_correct / train_total\n",
    "                })\n",
    "\n",
    "        # Calculate training metrics\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = 100.0 * train_correct / train_total\n",
    "        train_precision = precision_score(train_true, train_pred, average='macro')\n",
    "        train_recall = recall_score(train_true, train_pred, average='macro')\n",
    "        train_f1 = f1_score(train_true, train_pred, average='macro')\n",
    "\n",
    "        # Store metrics in history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_precision'].append(train_precision)\n",
    "        history['train_recall'].append(train_recall)\n",
    "        history['train_f1'].append(train_f1)\n",
    "\n",
    "        # Log metrics to TensorBoard if writer is provided\n",
    "        if writer:\n",
    "            writer.add_scalar(f'Final/train_loss', train_loss, epoch)\n",
    "            writer.add_scalar(f'Final/train_acc', train_acc, epoch)\n",
    "            writer.add_scalar(f'Final/train_precision', train_precision, epoch)\n",
    "            writer.add_scalar(f'Final/train_recall', train_recall, epoch)\n",
    "            writer.add_scalar(f'Final/train_f1', train_f1, epoch)\n",
    "            writer.add_scalar(f'Final/learning_rate', current_lr, epoch)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs} Summary:')\n",
    "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Train Precision: {train_precision:.2f} | Train Recall: {train_recall:.2f} | Train F1: {train_f1:.2f}')\n",
    "\n",
    "        # Adjust learning rate based on training loss (since no validation)\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    if save_path:\n",
    "        model_save_path = os.path.join(save_path, f'final_model_fold_{fold}.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Final model saved at {model_save_path}\")\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.670951Z",
     "iopub.status.busy": "2025-02-26T09:07:21.670588Z",
     "iopub.status.idle": "2025-02-26T09:07:21.702256Z",
     "shell.execute_reply": "2025-02-26T09:07:21.701468Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.670917Z"
    },
    "id": "_G8_YTgfNq3R",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# def main(lstm_hidden_size= LSTM_HIDDEN_SIZE,lstm_layers = LSTM_LAYERS, num_classes=NUM_CLASSES,LR=LEARNING_RATE, Epochs=50):\n",
    "    \n",
    "#     # Create TensorBoard log directory\n",
    "#     tensorboard_dir = os.path.join(SAVE_PATH, 'tensorboard_logs')\n",
    "#     os.makedirs(tensorboard_dir, exist_ok=True)\n",
    "#     writer = SummaryWriter(log_dir=tensorboard_dir)\n",
    "\n",
    "#     spatial_aug_config = {\n",
    "#         'gaussian_blur': 0.5,\n",
    "#         'random_horizontal_flip':  0.5,\n",
    "#         'color_jitter': 0.5,\n",
    "#         'random_rotation': 0.5\n",
    "#     }\n",
    "\n",
    "#     # temporal_aug_config = {\n",
    "#     #     'temporal_crop': {'enabled': True, 'crop_size': 0.8},\n",
    "#     #     'temporal_mask': {'enabled': True, 'mask_size': 0.2, 'n_masks': 2}\n",
    "#     # }\n",
    "#     dataset, train_dataset, test_dataset = prepare_dataset(spatial_aug_config=spatial_aug_config, temporal_aug_config=None)\n",
    "#     skf, folds = load_folds(meta_info_path, architecture=ARCHITECTURE)\n",
    "\n",
    "#     if folds is None:\n",
    "#         k_folds = 5\n",
    "#         skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "#         folds = list(skf.split(np.arange(len(train_dataset)), get_all_the_labels(train_dataset)))\n",
    "#         save_folds(meta_info_path, skf, folds,architecture=ARCHITECTURE)\n",
    "\n",
    "#     best_model = None\n",
    "#     best_val_loss = float('inf')\n",
    "#     best_fold = 0\n",
    "#     all_metrics = []\n",
    "\n",
    "#     print('Starting cross-validation...')\n",
    "\n",
    "#     # Create checkpoint directory if it doesn't exist\n",
    "#     os.makedirs(FOLD_CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "#     for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "#         # Check if checkpoint exists for this fold\n",
    "#         checkpoint_path = os.path.join(FOLD_CHECKPOINT_PATH, f'fold_{fold}_checkpoint.pth')\n",
    "#         if os.path.exists(checkpoint_path):\n",
    "#             print(f\"Loading checkpoint for fold {fold + 1}\")\n",
    "#             checkpoint = torch.load(checkpoint_path)\n",
    "#             model = checkpoint['model']\n",
    "#             optimizer = checkpoint['optimizer']\n",
    "#             history = checkpoint['history']\n",
    "#             all_metrics = checkpoint['all_metrics']\n",
    "#             best_model = checkpoint['best_model']\n",
    "#             best_val_loss = checkpoint['best_val_loss']\n",
    "#             best_fold = checkpoint['best_fold']\n",
    "#             continue\n",
    "\n",
    "#         print(f\"Fold {fold + 1}/{len(folds)}\")\n",
    "#         train_loader, val_loader = create_data_loaders(train_idx, val_idx, train_dataset)\n",
    "\n",
    "#         criterion = get_weighted_loss_criterion(\n",
    "#             train_dataset,\n",
    "#             train_idx,\n",
    "#             meta_info_path=meta_info_path,\n",
    "#             fold=fold\n",
    "#         ).to(device)\n",
    "#         model = CNNLSTM(num_classes=num_classes, lstm_hidden_size=lstm_hidden_size, lstm_layers=lstm_layers, dropout=DROPOUT,cnn_model=CNN_TYPE)\n",
    "#         print(model)\n",
    "#         print()\n",
    "#         optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "\n",
    "#         model, history = train_model(\n",
    "#             model,\n",
    "#             train_loader,\n",
    "#             val_loader,\n",
    "#             criterion,\n",
    "#             optimizer,\n",
    "#             dataset,\n",
    "#             fold=fold,\n",
    "#             num_epochs=Epochs,\n",
    "#             patience=10,\n",
    "#             log_interval=1,\n",
    "#             checkpoint_path=None\n",
    "#         )\n",
    "        \n",
    "#         # Log metrics to TensorBoard from history\n",
    "#         for epoch in range(len(history['train_loss'])):\n",
    "#             writer.add_scalar(f'Fold_{fold}/train_loss', history['train_loss'][epoch], epoch)\n",
    "#             writer.add_scalar(f'Fold_{fold}/val_loss', history['val_loss'][epoch], epoch)\n",
    "#             writer.add_scalar(f'Fold_{fold}/train_acc', history['train_acc'][epoch], epoch)\n",
    "#             writer.add_scalar(f'Fold_{fold}/val_acc', history['val_acc'][epoch], epoch)\n",
    "#             writer.add_scalar(f'Fold_{fold}/train_precision', history['train_precision'][epoch], epoch)\n",
    "#             writer.add_scalar(f'Fold_{fold}/train_recall', history['train_recall'][epoch], epoch)\n",
    "#             writer.add_scalar(f'Fold_{fold}/train_f1', history['train_f1'][epoch], epoch)\n",
    "#             writer.add_scalar(f'Fold_{fold}/val_precision', history['val_precision'][epoch], epoch)\n",
    "#             writer.add_scalar(f'Fold_{fold}/val_recall', history['val_recall'][epoch], epoch)\n",
    "#             writer.add_scalar(f'Fold_{fold}/val_f1', history['val_f1'][epoch], epoch)\n",
    "\n",
    "#         plot_training_curves(history, fold)\n",
    "#         all_metrics.append(history)\n",
    "\n",
    "#         if history['val_loss'][-1] < best_val_loss:\n",
    "#             best_val_loss = history['val_loss'][-1]\n",
    "#             best_model = model\n",
    "#             best_fold = fold\n",
    "\n",
    "#         # Save checkpoint after each successful fold\n",
    "#         checkpoint = {\n",
    "#             'model': model,\n",
    "#             'optimizer': optimizer,\n",
    "#             'history': history,\n",
    "#             'all_metrics': all_metrics,\n",
    "#             'best_model': best_model,\n",
    "#             'best_val_loss': best_val_loss,\n",
    "#             'best_fold': best_fold,\n",
    "#             'fold': fold\n",
    "#         }\n",
    "#         torch.save(checkpoint, checkpoint_path)\n",
    "#         print(f\"Saved checkpoint for fold {fold + 1}\")\n",
    "\n",
    "#     # Log average metrics\n",
    "#     avg_history = compute_average_history(all_metrics)\n",
    "#     for epoch in range(len(avg_history['train_loss'])):\n",
    "#         writer.add_scalar('Average/train_loss', avg_history['train_loss'][epoch], epoch)\n",
    "#         writer.add_scalar('Average/val_loss', avg_history['val_loss'][epoch], epoch)\n",
    "#         writer.add_scalar('Average/train_acc', avg_history['train_acc'][epoch], epoch)\n",
    "#         writer.add_scalar('Average/val_acc', avg_history['val_acc'][epoch], epoch)\n",
    "#         writer.add_scalar('Average/train_precision', avg_history['train_precision'][epoch], epoch)\n",
    "#         writer.add_scalar('Average/train_recall', avg_history['train_recall'][epoch], epoch)\n",
    "#         writer.add_scalar('Average/train_f1', avg_history['train_f1'][epoch], epoch)\n",
    "#         writer.add_scalar('Average/val_precision', avg_history['val_precision'][epoch], epoch)\n",
    "#         writer.add_scalar('Average/val_recall', avg_history['val_recall'][epoch], epoch)\n",
    "#         writer.add_scalar('Average/val_f1', avg_history['val_f1'][epoch], epoch)\n",
    "\n",
    "#     plot_training_curves(avg_history, 'average')\n",
    "\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn = collate_fn)\n",
    "#     # Directly use the best fold's training indices to create the correct criterion\n",
    "#     train_idx, _ = folds[best_fold]  # Extract train indices for best fold\n",
    "    \n",
    "#     criterion = get_weighted_loss_criterion(\n",
    "#         train_dataset,\n",
    "#         train_idx,\n",
    "#         meta_info_path=meta_info_path,\n",
    "#         fold=best_fold\n",
    "#     ).to(device)\n",
    "#     evaluate_model(best_model, test_loader, criterion, pose_list)\n",
    "#     evaluate_model_normalized(best_model, test_loader, criterion, pose_list, writer=writer, global_step=best_fold)\n",
    "\n",
    "#     model_save_path = os.path.join(SAVE_PATH, f'my_model_{best_fold}.pth')\n",
    "#     torch.save(best_model.state_dict(), model_save_path)\n",
    "    \n",
    "#     # Close the TensorBoard writer\n",
    "#     writer.close()\n",
    "\n",
    "# def prepare_dataset(spatial_aug_config=None, temporal_aug_config=None):\n",
    "#     dataset = YogaVideoDataset(csv_path, sequence_path, pose_list, video_dir, preprocessed_dir, spatial_aug_config=spatial_aug_config, temporal_aug_config=temporal_aug_config)\n",
    "#     print(len(dataset))\n",
    "#     train_dataset, test_dataset = train_test_split(dataset)\n",
    "#     return dataset,train_dataset,test_dataset\n",
    "\n",
    "# def get_all_the_labels(dataset):\n",
    "#     return [label for _, label in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.703365Z",
     "iopub.status.busy": "2025-02-26T09:07:21.703089Z",
     "iopub.status.idle": "2025-02-26T09:07:21.722699Z",
     "shell.execute_reply": "2025-02-26T09:07:21.721913Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.703341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_test_metrics(avg_test_loss, avg_test_acc, avg_test_precision, avg_test_recall, avg_test_f1, save_path=SAVE_PATH, filename='test_metrics_average.png'):\n",
    "    \"\"\"\n",
    "    Plot average test metrics as text and save to a PNG file.\n",
    "\n",
    "    Args:\n",
    "        avg_test_loss (float): Average test loss across folds\n",
    "        avg_test_acc (float): Average test accuracy across folds (percentage)\n",
    "        avg_test_precision (float): Average macro precision across folds\n",
    "        avg_test_recall (float): Average macro recall across folds\n",
    "        avg_test_f1 (float): Average macro F1 score across folds\n",
    "        save_path (str): Directory to save the plot\n",
    "        filename (str): Filename for the plot (default: 'test_metrics_average.png')\n",
    "    \"\"\"\n",
    "    # Create figure without axes\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))  # Adjust size as needed\n",
    "    ax.axis('off')  # Hide axes\n",
    "\n",
    "    # Define the text to display\n",
    "    metrics_text = (\n",
    "        f'Average Test Metrics Across Folds:\\n\\n'\n",
    "        f'Test Loss: {avg_test_loss:.4f}\\n'\n",
    "        f'Test Accuracy: {avg_test_acc:.2f}%\\n'\n",
    "        f'Precision (Macro): {avg_test_precision:.4f}\\n'\n",
    "        f'Recall (Macro): {avg_test_recall:.4f}\\n'\n",
    "        f'F1 Score (Macro): {avg_test_f1:.4f}'\n",
    "    )\n",
    "\n",
    "    # Place text in the center of the figure\n",
    "    ax.text(0.5, 0.5, metrics_text, ha='center', va='center', fontsize=12, fontfamily='monospace')\n",
    "\n",
    "    # Construct the full save path\n",
    "    save_file = os.path.join(save_path, filename)\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(save_file, bbox_inches='tight', dpi=300)\n",
    "    print(f\"Saved test metrics plot to {save_file}\")\n",
    "    plt.show()\n",
    "    # Close the figure to free memory\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.723704Z",
     "iopub.status.busy": "2025-02-26T09:07:21.723488Z",
     "iopub.status.idle": "2025-02-26T09:07:21.746396Z",
     "shell.execute_reply": "2025-02-26T09:07:21.745565Z",
     "shell.execute_reply.started": "2025-02-26T09:07:21.723685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def main(lstm_hidden_size=LSTM_HIDDEN_SIZE, lstm_layers=LSTM_LAYERS, num_classes=NUM_CLASSES, LR=LEARNING_RATE, Epochs=50):\n",
    "    \"\"\"\n",
    "    Main function implementing the new action plan with 5-fold CV on the entire dataset,\n",
    "    per-fold validation splits, and a final model trained on all data.\n",
    "    \"\"\"\n",
    "    # Create TensorBoard log directory\n",
    "    tensorboard_dir = os.path.join(SAVE_PATH, 'tensorboard_logs')\n",
    "    os.makedirs(tensorboard_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=tensorboard_dir)\n",
    "\n",
    "    # Define augmentation configurations\n",
    "    spatial_aug_config = {\n",
    "        'gaussian_blur': 0.5,\n",
    "        'random_horizontal_flip': 0.5,\n",
    "        'color_jitter': 0.5,\n",
    "        'random_rotation': 0.5\n",
    "    }\n",
    "\n",
    "    # Load the entire dataset without initial train-test split\n",
    "    dataset = prepare_dataset(spatial_aug_config=spatial_aug_config, temporal_aug_config=None)\n",
    "    labels = get_all_the_labels(dataset)\n",
    "\n",
    "    # Set up stratified 5-fold cross-validation on the entire dataset\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    folds = list(skf.split(np.arange(len(dataset)), labels))\n",
    "\n",
    "    all_metrics = []  # Store training history for each fold\n",
    "    all_test_metrics = []  # Store test metrics for each fold\n",
    "\n",
    "    print('Starting cross-validation...')\n",
    "\n",
    "    # Ensure checkpoint directory exists\n",
    "    os.makedirs(FOLD_CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(folds):\n",
    "        checkpoint_path = os.path.join(FOLD_CHECKPOINT_PATH, f'fold_{fold}_checkpoint.pth')\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            print(f\"Loading checkpoint for fold {fold + 1}\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            history = checkpoint['history']\n",
    "            test_metrics = checkpoint['test_metrics']\n",
    "            all_metrics.append(history)\n",
    "            all_test_metrics.append(test_metrics)\n",
    "            continue\n",
    "\n",
    "        print(f\"Fold {fold + 1}/{len(folds)}\")\n",
    "\n",
    "        # Further split train_idx into actual_train_idx and val_idx (90-10 split)\n",
    "        train_labels = [labels[i] for i in train_idx]\n",
    "        actual_train_idx, val_idx = train_test_split(\n",
    "            train_idx,\n",
    "            test_size=0.1,\n",
    "            stratify=train_labels,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Create data loaders for actual training, validation, and test sets\n",
    "        train_sub_dataset = Subset(dataset, actual_train_idx)\n",
    "        val_sub_dataset = Subset(dataset, val_idx)\n",
    "        test_sub_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_sub_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(val_sub_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "        test_loader = DataLoader(test_sub_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "        # Define loss criterion based on actual training indices\n",
    "        criterion = get_weighted_loss_criterion(\n",
    "            dataset,\n",
    "            actual_train_idx,\n",
    "            meta_info_path=meta_info_path,\n",
    "            fold=fold\n",
    "        ).to(device)\n",
    "\n",
    "        # Initialize the model\n",
    "        model = CNNLSTM(\n",
    "            num_classes=num_classes,\n",
    "            lstm_hidden_size=lstm_hidden_size,\n",
    "            lstm_layers=lstm_layers,\n",
    "            dropout=DROPOUT,\n",
    "            cnn_model=CNN_TYPE\n",
    "        ).to(device)\n",
    "        # optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "        \n",
    "\n",
    "\n",
    "        # Train the model\n",
    "        model, history = train_model(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            dataset,\n",
    "            fold=fold,\n",
    "            num_epochs=Epochs,\n",
    "            patience=10,\n",
    "            log_interval=1,\n",
    "            checkpoint_path=None\n",
    "        )\n",
    "\n",
    "        # Log training and validation metrics to TensorBoard\n",
    "        for epoch in range(len(history['train_loss'])):\n",
    "            writer.add_scalar(f'Fold_{fold}/train_loss', history['train_loss'][epoch], epoch)\n",
    "            writer.add_scalar(f'Fold_{fold}/val_loss', history['val_loss'][epoch], epoch)\n",
    "            writer.add_scalar(f'Fold_{fold}/train_acc', history['train_acc'][epoch], epoch)\n",
    "            writer.add_scalar(f'Fold_{fold}/val_acc', history['val_acc'][epoch], epoch)\n",
    "            writer.add_scalar(f'Fold_{fold}/train_precision', history['train_precision'][epoch], epoch)\n",
    "            writer.add_scalar(f'Fold_{fold}/train_recall', history['train_recall'][epoch], epoch)\n",
    "            writer.add_scalar(f'Fold_{fold}/train_f1', history['train_f1'][epoch], epoch)\n",
    "            writer.add_scalar(f'Fold_{fold}/val_precision', history['val_precision'][epoch], epoch)\n",
    "            writer.add_scalar(f'Fold_{fold}/val_recall', history['val_recall'][epoch], epoch)\n",
    "            writer.add_scalar(f'Fold_{fold}/val_f1', history['val_f1'][epoch], epoch)\n",
    "\n",
    "        plot_training_curves(history, fold)\n",
    "        all_metrics.append(history)\n",
    "\n",
    "       # Evaluate on the fold's test set\n",
    "        evaluate_model(model, test_loader, criterion, pose_list, fold=fold)\n",
    "        test_metrics = evaluate_model_normalized(model, test_loader, criterion, pose_list, fold=fold)\n",
    "\n",
    "        all_test_metrics.append(test_metrics)\n",
    "\n",
    "        # Log test metrics to TensorBoard\n",
    "        writer.add_scalar(f'Fold_{fold}/test_loss', test_metrics['loss'], 0)\n",
    "        writer.add_scalar(f'Fold_{fold}/test_acc', test_metrics['accuracy'], 0)\n",
    "        writer.add_scalar(f'Fold_{fold}/test_precision', test_metrics['precision'], 0)\n",
    "        writer.add_scalar(f'Fold_{fold}/test_recall', test_metrics['recall'], 0)\n",
    "        writer.add_scalar(f'Fold_{fold}/test_f1', test_metrics['f1'], 0)\n",
    "\n",
    "\n",
    "        # Save checkpoint\n",
    "        checkpoint = {\n",
    "            'model': model,\n",
    "            'optimizer': optimizer,\n",
    "            'history': history,\n",
    "            'test_metrics': test_metrics,\n",
    "            'fold': fold\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Saved checkpoint for fold {fold + 1}\")\n",
    "\n",
    "    # Compute and log average metrics across folds\n",
    "    avg_history = compute_average_history(all_metrics)\n",
    "    for epoch in range(len(avg_history['train_loss'])):\n",
    "        writer.add_scalar('Average/train_loss', avg_history['train_loss'][epoch], epoch)\n",
    "        writer.add_scalar('Average/val_loss', avg_history['val_loss'][epoch], epoch)\n",
    "        writer.add_scalar('Average/train_acc', avg_history['train_acc'][epoch], epoch)\n",
    "        writer.add_scalar('Average/val_acc', avg_history['val_acc'][epoch], epoch)\n",
    "        writer.add_scalar('Average/train_precision', avg_history['train_precision'][epoch], epoch)\n",
    "        writer.add_scalar('Average/train_recall', avg_history['train_recall'][epoch], epoch)\n",
    "        writer.add_scalar('Average/train_f1', avg_history['train_f1'][epoch], epoch)\n",
    "        writer.add_scalar('Average/val_precision', avg_history['val_precision'][epoch], epoch)\n",
    "        writer.add_scalar('Average/val_recall', avg_history['val_recall'][epoch], epoch)\n",
    "        writer.add_scalar('Average/val_f1', avg_history['val_f1'][epoch], epoch)\n",
    "\n",
    "    plot_training_curves(avg_history, 'average')\n",
    "\n",
    "    # # Compute average test metrics\n",
    "    # avg_test_loss = np.mean([m['loss'] for m in all_test_metrics])\n",
    "    # avg_test_acc = np.mean([m['accuracy'] for m in all_test_metrics])\n",
    "    # writer.add_scalar('Average/test_loss', avg_test_loss, 0)\n",
    "    # writer.add_scalar('Average/test_acc', avg_test_acc, 0)\n",
    "    # # Add other average test metrics as needed\n",
    "    avg_test_loss = np.mean([m['loss'] for m in all_test_metrics])\n",
    "    avg_test_acc = np.mean([m['accuracy'] for m in all_test_metrics])\n",
    "    avg_test_precision = np.mean([m['precision'] for m in all_test_metrics])\n",
    "    avg_test_recall = np.mean([m['recall'] for m in all_test_metrics])\n",
    "    avg_test_f1 = np.mean([m['f1'] for m in all_test_metrics])\n",
    "\n",
    "    # Log to TensorBoard\n",
    "    writer.add_scalar('Average/test_loss', avg_test_loss, 0)\n",
    "    writer.add_scalar('Average/test_acc', avg_test_acc, 0)\n",
    "    writer.add_scalar('Average/test_precision', avg_test_precision, 0)\n",
    "    writer.add_scalar('Average/test_recall', avg_test_recall, 0)\n",
    "    writer.add_scalar('Average/test_f1', avg_test_f1, 0)\n",
    "    \n",
    "    plot_test_metrics(\n",
    "      avg_test_loss,\n",
    "      avg_test_acc,\n",
    "      avg_test_precision,\n",
    "      avg_test_recall,\n",
    "      avg_test_f1,\n",
    "      save_path=SAVE_PATH,\n",
    "      filename='test_metrics_average.png'\n",
    "    )\n",
    "\n",
    "    # Train final model on the entire dataset\n",
    "    final_train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    final_criterion = get_weighted_loss_criterion(\n",
    "        dataset,\n",
    "        np.arange(len(dataset)),\n",
    "        meta_info_path=meta_info_path,\n",
    "        fold='final'\n",
    "    ).to(device)\n",
    "    final_model = CNNLSTM(\n",
    "        num_classes=num_classes,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        dropout=DROPOUT,\n",
    "        cnn_model=CNN_TYPE\n",
    "    ).to(device)\n",
    "    final_optimizer = torch.optim.Adam(final_model.parameters(), lr=LR, weight_decay=0.01)\n",
    "\n",
    "    # Use average number of epochs from cross-validation\n",
    "    avg_epochs = int(np.mean([len(history['train_loss']) for history in all_metrics]))\n",
    "\n",
    "    final_model, final_history = train_model_final(\n",
    "        final_model,\n",
    "        final_train_loader,\n",
    "        final_criterion,\n",
    "        final_optimizer,\n",
    "        dataset,\n",
    "        fold='final',\n",
    "        num_epochs=avg_epochs,\n",
    "        log_interval=1,\n",
    "        writer=writer,  # Pass the TensorBoard writer\n",
    "        save_path=SAVE_PATH\n",
    "    )\n",
    "\n",
    "    # # Save the final model\n",
    "    model_save_path = os.path.join(SAVE_PATH, 'final_model.pth')\n",
    "    torch.save(final_model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at {model_save_path}\")\n",
    "\n",
    "    # Close TensorBoard writer\n",
    "    writer.close()\n",
    "def prepare_dataset(spatial_aug_config=None, temporal_aug_config=None):\n",
    "    dataset = YogaVideoDataset(\n",
    "        csv_path,\n",
    "        sequence_path,\n",
    "        pose_list,\n",
    "        video_dir,\n",
    "        preprocessed_dir,\n",
    "        spatial_aug_config=spatial_aug_config,\n",
    "        temporal_aug_config=temporal_aug_config\n",
    "    )\n",
    "    print(f\"Dataset size: {len(dataset)}\")\n",
    "    return dataset  # Return only the full dataset\n",
    "def get_all_the_labels(dataset):\n",
    "    return [label for _, label in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-02-26T09:07:21.747500Z",
     "iopub.status.busy": "2025-02-26T09:07:21.747226Z"
    },
    "id": "GpaMPADECZC-",
    "outputId": "fb2305d9-5d28-4215-fb6f-58d135a893c3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r /kaggle/working/vgg16__.zip /kaggle/working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNhSc5nau5Ar",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "def find_sus(model, test_loader, criterion, class_names, spath=SAVE_PATH, fsave='confusion_matrix_all.png'):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        test_loader: DataLoader for test data\n",
    "        criterion: Loss function\n",
    "        class_names: List of class names\n",
    "        save_path: Directory to save the plot\n",
    "        fsave: Filename for confusion matrix plot\n",
    "    \"\"\"\n",
    "    csave = os.path.join(spath, fsave)\n",
    "    sussave = os.path.join(spath, 'sus.csv')\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    misclassified_data = []\n",
    "\n",
    "    # Create progress bar\n",
    "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels, lengths) in enumerate(test_loader_tqdm):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(inputs, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            # Calculate accuracy\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "            # Store predictions and labels for confusion matrix\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Check if the sample is misclassified\n",
    "            misclassified_indices = (predicted != labels).nonzero(as_tuple=True)[0]\n",
    "            for misclassified_idx in misclassified_indices:\n",
    "                global_idx = batch_idx * inputs.size(0) + misclassified_idx.item()\n",
    "                sequence_id = test_loader.dataset.idx_to_label[global_idx]\n",
    "                correct_label = class_names[labels[misclassified_idx].item()]\n",
    "                prediction = class_names[predicted[misclassified_idx].item()]\n",
    "                misclassified_data.append([sequence_id, correct_label, prediction])\n",
    "\n",
    "    # Calculate metrics\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    accuracy = 100 * test_correct / test_total\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=pose_list, yticklabels=pose_list)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(csave)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Save misclassified data to CSV\n",
    "    with open(sussave, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['sequence_id', 'correct_label', 'prediction'])\n",
    "        writer.writerows(misclassified_data)\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60euC5Fmu5As",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset, train_dataset, test_dataset = prepare_dataset()\n",
    "label_to_pose = {v:k for k,v in dataset.pose_to_label.items()}\n",
    "\n",
    "model = CNNLSTM(num_classes=NUM_CLASSES, lstm_hidden_size=LSTM_HIDDEN_SIZE, lstm_layers=LSTM_LAYERS, dropout=DROPOUT, cnn_model = CNN_TYPE)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "all_labels = [dataset[i][1] for i in range(len(dataset))]\n",
    "criterion = create_weighted_criterion(\n",
    "        all_labels,\n",
    "        num_classes= NUM_CLASSES,\n",
    "        strategy='inverse'  # Try different strategies\n",
    "    )\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "checkpoint_path = os.path.join(SAVE_PATH, 'best_model.pth')\n",
    "# Plot the training curves\n",
    "if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        model, optimizer, start_epoch, history = load_checkpoint(\n",
    "            model, optimizer, checkpoint_path\n",
    "        )\n",
    "        print(f\"Resuming training from epoch {start_epoch}\")\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "# plot_training_curves(history)\n",
    "find_sus(model, loader, criterion, label_to_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6661170,
     "sourceId": 10741822,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6669522,
     "sourceId": 10753537,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6718778,
     "sourceId": 10821326,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6729280,
     "sourceId": 10836286,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
