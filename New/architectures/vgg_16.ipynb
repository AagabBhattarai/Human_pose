{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import math\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    \"\"\"Basic attention mechanism for sequence processing\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(input_size, hidden_size)\n",
    "        self.V = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.W.weight)\n",
    "        nn.init.xavier_uniform_(self.V.weight)\n",
    "        nn.init.zeros_(self.W.bias)\n",
    "        nn.init.zeros_(self.V.bias)\n",
    "\n",
    "    def forward(self, lstm_output, mask=None):\n",
    "        att_scores = self.V(torch.tanh(self.W(lstm_output))).squeeze(-1)\n",
    "        if mask is not None:\n",
    "            att_scores = att_scores.masked_fill(mask == 0, -1e9)\n",
    "        att_weights = F.softmax(att_scores, dim=1)\n",
    "        context = (lstm_output * att_weights.unsqueeze(-1)).sum(1)\n",
    "        return context, att_weights\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    \"\"\"Modular video action classifier with various configuration options\"\"\"\n",
    "    def __init__(self, num_classes,\n",
    "                 lstm_hidden_size=512,\n",
    "                 lstm_layers=1,\n",
    "                 dropout=0.5,\n",
    "                 freeze_cnn=True,\n",
    "                 use_attention=False,\n",
    "                 cnn_model='resnet18'):\n",
    "\n",
    "        super().__init__()\n",
    "        self.use_attention = use_attention\n",
    "        self.cnn_model = cnn_model\n",
    "\n",
    "        # CNN Feature Extractor\n",
    "        self.cnn, self.cnn_feature_size = self._build_cnn(cnn_model)\n",
    "        self._set_cnn_freeze(freeze_cnn)\n",
    "\n",
    "        lstm_input_size = self.cnn_feature_size\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_size,\n",
    "            hidden_size=lstm_hidden_size,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self._init_lstm_weights()\n",
    "\n",
    "        if self.use_attention:\n",
    "            self.attention = AttentionLayer(\n",
    "                input_size=lstm_hidden_size,\n",
    "                hidden_size=lstm_hidden_size\n",
    "            )\n",
    "\n",
    "        self.classifier = self._build_classifier(\n",
    "            lstm_hidden_size,\n",
    "            num_classes,\n",
    "            dropout\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _build_cnn(self, model_name):\n",
    "        \"\"\"Initialize CNN feature extractor with proper feature sizes\"\"\"\n",
    "        if model_name == 'resnet18':\n",
    "            cnn = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.children())[:-2]), 512\n",
    "        elif model_name == 'mobilenet_v3':\n",
    "            cnn = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.children())[:-2]), 576\n",
    "        elif model_name == 'vgg16':\n",
    "            cnn = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.features)), 512\n",
    "        elif model_name == 'vgg19':\n",
    "            cnn = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.features)), 512\n",
    "        elif model_name == 'densenet121':\n",
    "            cnn = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.children())[:-1]), 1024\n",
    "        elif model_name == 'densenet201':\n",
    "            cnn = models.densenet201(weights=models.DenseNet201_Weights.DEFAULT)\n",
    "            return nn.Sequential(*list(cnn.children())[:-1]), 1920\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported CNN model: {model_name}\")\n",
    "\n",
    "    def _build_classifier(self, input_size, num_classes, dropout):\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def _init_lstm_weights(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _set_cnn_freeze(self, freeze):\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = not freeze\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        batch_size, seq_len = x.size(0), x.size(1)\n",
    "        x = x.view(batch_size*seq_len, *x.size()[2:])\n",
    "        x = self.cnn(x)\n",
    "        \n",
    "        # Handle different CNN output shapes\n",
    "        if self.cnn_model in ['resnet18', 'mobilenet_v3', 'vgg16', 'vgg19', 'densenet121', 'densenet201']:\n",
    "            x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "            \n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "\n",
    "        packed_x = rnn_utils.pack_padded_sequence(\n",
    "            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_out, _ = self.lstm(packed_x)\n",
    "        lstm_out, _ = rnn_utils.pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        if self.use_attention:\n",
    "            mask = self._create_attention_mask(lstm_out.size(1), lengths)\n",
    "            context, _ = self.attention(lstm_out, mask)\n",
    "        else:\n",
    "            # print(lengths)\n",
    "            indices = torch.clamp(lengths - 1, min=0)\n",
    "            # print(indices)\n",
    "            context = lstm_out[torch.arange(batch_size), indices, :]\n",
    "\n",
    "        return self.classifier(context)\n",
    "\n",
    "    def _create_attention_mask(self, max_len, lengths):\n",
    "        device = lengths.device\n",
    "        return torch.arange(max_len, device=device).expand(len(lengths), max_len) < lengths.unsqueeze(1)\n",
    "\n",
    "    def unfreeze_cnn_layers(self, num_layers=3, start_from_end=True):\n",
    "        all_cnn_layers = []\n",
    "        for name, module in self.cnn.named_modules():\n",
    "            if isinstance(module, (nn.Conv2d, nn.BatchNorm2d)):\n",
    "                all_cnn_layers.append(module)\n",
    "        \n",
    "        conv_layers = [l for l in all_cnn_layers if isinstance(l, nn.Conv2d)]\n",
    "        bn_layers = [l for l in all_cnn_layers if isinstance(l, nn.BatchNorm2d)]\n",
    "        \n",
    "        if start_from_end:\n",
    "            layers_to_unfreeze = conv_layers[-num_layers:]\n",
    "            bn_to_unfreeze = bn_layers[-num_layers:] if bn_layers else []\n",
    "        else:\n",
    "            layers_to_unfreeze = conv_layers[:num_layers]\n",
    "            bn_to_unfreeze = bn_layers[:num_layers] if bn_layers else []\n",
    "        \n",
    "        for layer in layers_to_unfreeze + bn_to_unfreeze:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def count_parameters(self):\n",
    "        total_params = 0\n",
    "        for name, parameter in self.named_parameters():\n",
    "            if parameter.requires_grad:\n",
    "                params = parameter.numel()\n",
    "                print(f\"{name}: {params}\")\n",
    "                total_params += params\n",
    "        print(f\"Total Trainable Params: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.weight_ih_l0: 1048576\n",
      "lstm.weight_hh_l0: 1048576\n",
      "lstm.bias_ih_l0: 2048\n",
      "lstm.bias_hh_l0: 2048\n",
      "classifier.1.weight: 6656\n",
      "classifier.1.bias: 13\n",
      "Total Trainable Params: 2107917\n",
      "\n",
      "\n",
      "Input shape: torch.Size([10, 5, 3, 224, 224])\n",
      "Output shape: torch.Size([10, 13])\n",
      "Loss value: 2.5886\n"
     ]
    }
   ],
   "source": [
    "# With VGG19\n",
    "model_vgg19 = CNNLSTM(\n",
    "    num_classes=13,\n",
    "    cnn_model='vgg19',\n",
    "    lstm_hidden_size=512,\n",
    ")\n",
    "model_vgg19.count_parameters()\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Create dummy input data (batch_size=2, sequence_length=5, channels=3, height=224, width=224)\n",
    "batch_size = 10\n",
    "seq_length = 5\n",
    "dummy_input = torch.randn(batch_size, seq_length, 3, 224, 224)\n",
    "\n",
    "# Create dummy lengths (batch_size=2)\n",
    "dummy_lengths = torch.randint(1, seq_length + 1, (batch_size,))\n",
    "\n",
    "# Create dummy target labels (batch_size=2)\n",
    "dummy_target = torch.randint(0, 13, (batch_size,))\n",
    "\n",
    "# Forward pass\n",
    "output = model_vgg19(dummy_input, lengths=dummy_lengths)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute loss\n",
    "loss = criterion(output, dummy_target)\n",
    "\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Loss value: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.weight_ih_l0: 2097152\n",
      "lstm.weight_hh_l0: 1048576\n",
      "lstm.bias_ih_l0: 2048\n",
      "lstm.bias_hh_l0: 2048\n",
      "classifier.1.weight: 6656\n",
      "classifier.1.bias: 13\n",
      "Total Trainable Params: 3156493\n",
      "\n",
      "\n",
      "tensor([2, 5, 2, 3, 2, 2, 3, 2, 2, 1])\n",
      "Input shape: torch.Size([10, 5, 3, 224, 224])\n",
      "Output shape: torch.Size([10, 13])\n",
      "Loss value: 2.5215\n"
     ]
    }
   ],
   "source": [
    "model_densenet121 = CNNLSTM(\n",
    "    num_classes=13,\n",
    "    cnn_model='densenet121',\n",
    "    lstm_hidden_size=512,\n",
    "    use_attention=False\n",
    ")\n",
    "model_densenet121.count_parameters()\n",
    "print()\n",
    "print()\n",
    "# Create dummy input data (batch_size=2, sequence_length=5, channels=3, height=224, width=224)\n",
    "batch_size = 10\n",
    "seq_length = 5\n",
    "dummy_input = torch.randn(batch_size, seq_length, 3, 224, 224)\n",
    "\n",
    "# Create dummy lengths (batch_size=2)\n",
    "dummy_lengths = torch.randint(1, seq_length + 1, (batch_size,))\n",
    "print(dummy_lengths)\n",
    "\n",
    "# Create dummy target labels (batch_size=2)\n",
    "dummy_target = torch.randint(0, 13, (batch_size,))\n",
    "\n",
    "# Forward pass\n",
    "output = model_densenet121(dummy_input, lengths=dummy_lengths)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute loss\n",
    "loss = criterion(output, dummy_target)\n",
    "\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Loss value: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.weight_ih_l0: 1048576\n",
      "lstm.weight_hh_l0: 1048576\n",
      "lstm.bias_ih_l0: 2048\n",
      "lstm.bias_hh_l0: 2048\n",
      "classifier.1.weight: 6656\n",
      "classifier.1.bias: 13\n",
      "Total Trainable Params: 2107917\n",
      "\n",
      "\n",
      "Input shape: torch.Size([10, 5, 3, 224, 224])\n",
      "Output shape: torch.Size([10, 13])\n",
      "Loss value: 2.5736\n"
     ]
    }
   ],
   "source": [
    "res_model = CNNLSTM(\n",
    "    num_classes=13,\n",
    "    cnn_model='resnet18',\n",
    "    lstm_hidden_size=512,\n",
    "    use_attention=False\n",
    ")\n",
    "res_model.count_parameters()\n",
    "print()\n",
    "print()\n",
    "# Create dummy input data (batch_size=2, sequence_length=5, channels=3, height=224, width=224)\n",
    "batch_size = 10\n",
    "seq_length = 5\n",
    "dummy_input = torch.randn(batch_size, seq_length, 3, 224, 224)\n",
    "\n",
    "# Create dummy lengths (batch_size=2)\n",
    "dummy_lengths = torch.randint(1, seq_length + 1, (batch_size,))\n",
    "\n",
    "# Create dummy target labels (batch_size=2)\n",
    "dummy_target = torch.randint(0, 13, (batch_size,))\n",
    "\n",
    "# Forward pass\n",
    "output = model_densenet121(dummy_input, lengths=dummy_lengths)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute loss\n",
    "loss = criterion(output, dummy_target)\n",
    "\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Loss value: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.weight_ih_l0: 1048576\n",
      "lstm.weight_hh_l0: 1048576\n",
      "lstm.bias_ih_l0: 2048\n",
      "lstm.bias_hh_l0: 2048\n",
      "classifier.1.weight: 6656\n",
      "classifier.1.bias: 13\n",
      "Total Trainable Params: 2107917\n",
      "\n",
      "\n",
      "Input shape: torch.Size([10, 5, 3, 224, 224])\n",
      "Output shape: torch.Size([10, 13])\n",
      "Loss value: 2.6226\n"
     ]
    }
   ],
   "source": [
    "vgg_model = CNNLSTM(\n",
    "    num_classes=13,\n",
    "    cnn_model='vgg16',\n",
    "    lstm_hidden_size=512,\n",
    "    use_attention=False\n",
    ")\n",
    "vgg_model.count_parameters()\n",
    "print()\n",
    "print()\n",
    "# Create dummy input data (batch_size=2, sequence_length=5, channels=3, height=224, width=224)\n",
    "batch_size = 10\n",
    "seq_length = 5\n",
    "dummy_input = torch.randn(batch_size, seq_length, 3, 224, 224)\n",
    "\n",
    "# Create dummy lengths (batch_size=2)\n",
    "dummy_lengths = torch.randint(1, seq_length + 1, (batch_size,))\n",
    "\n",
    "# Create dummy target labels (batch_size=2)\n",
    "dummy_target = torch.randint(0, 13, (batch_size,))\n",
    "\n",
    "# Forward pass\n",
    "output = vgg_model(dummy_input, lengths=dummy_lengths)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute loss\n",
    "loss = criterion(output, dummy_target)\n",
    "\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Loss value: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm.weight_ih_l0: 1179648\n",
      "lstm.weight_hh_l0: 1048576\n",
      "lstm.bias_ih_l0: 2048\n",
      "lstm.bias_hh_l0: 2048\n",
      "classifier.1.weight: 6656\n",
      "classifier.1.bias: 13\n",
      "Total Trainable Params: 2238989\n",
      "\n",
      "\n",
      "tensor([4, 5, 4, 1, 3, 3, 1, 1, 3, 4])\n",
      "tensor([3, 4, 3, 0, 2, 2, 0, 0, 2, 3])\n",
      "Input shape: torch.Size([10, 5, 3, 224, 224])\n",
      "Output shape: torch.Size([10, 13])\n",
      "Loss value: 2.5443\n"
     ]
    }
   ],
   "source": [
    "mobilenet_model = CNNLSTM(\n",
    "    num_classes=13,\n",
    "    cnn_model='mobilenet_v3',\n",
    "    lstm_hidden_size=512,\n",
    "    use_attention=False\n",
    ")\n",
    "mobilenet_model.count_parameters()\n",
    "print()\n",
    "print()\n",
    "# Create dummy input data (batch_size=2, sequence_length=5, channels=3, height=224, width=224)\n",
    "batch_size = 10\n",
    "seq_length = 5\n",
    "dummy_input = torch.randn(batch_size, seq_length, 3, 224, 224)\n",
    "\n",
    "# Create dummy lengths (batch_size=2)\n",
    "dummy_lengths = torch.randint(1, seq_length + 1, (batch_size,))\n",
    "print(dummy_lengths)\n",
    "# Create dummy target labels (batch_size=2)\n",
    "dummy_target = torch.randint(0, 13, (batch_size,))\n",
    "\n",
    "# Forward pass\n",
    "output = mobilenet_model(dummy_input, lengths=dummy_lengths)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Compute loss\n",
    "loss = criterion(output, dummy_target)\n",
    "\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Loss value: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
