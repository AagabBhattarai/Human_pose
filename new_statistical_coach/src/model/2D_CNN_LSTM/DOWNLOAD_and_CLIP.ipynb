{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_j2houStOQx",
        "outputId": "06efeb79-9599-4e00-8e8d-5b3919cc2c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "1DCNNLSTM_Cross_fold\n",
            "2DCNNLSTM-Jan28\n",
            "CROSS_FOLD_2D_CNN_LSTM_2025-02-10_LR0.001_LHS512_LL1_CTResnet\n",
            "CROSS_FOLD_2D_CNN_LSTM_2025-02-13_LR0.001_LHS512_LL1_CTResnet\n",
            "CROSS_FOLD_2D_CNN_LSTM_2025-02-14_LR0.001_LHS512_LL1_CTResnet\n",
            "data\n",
            "gaussian_blur_aug\n",
            "horz_aug\n",
            "mobile_net_nov2\n",
            "new_save\n",
            "NEW_SHORTS\n",
            "nov10_bi_lstm\n",
            "nov10_equal_interval_sample\n",
            "nov11_bi_lstm\n",
            "nov11_Second_bi_lstm\n",
            "nov12_unknown_attention\n",
            "nov16_unknown_attention\n",
            "nov7_equal_interval_sample\n",
            "nov9_equal_interval_sample\n",
            "pre_processed_short\n",
            "resize_aug\n",
            "RESIZED_SHORTS\n",
            "Resnet_nov6\n",
            "save\n",
            "SECOND_mobile_net_nov2\n",
            "Second_Resnet_nov6\n",
            "short\n",
            "SMPLer-X\n",
            "SMPLR-X\n",
            "VIBE\n",
            "Without_augmentation_1DCNNLSTM_Cross_fold\n",
            "2D_CNN_LSTM_folds.pkl\t3DYoga90.csv\t      criterion_fold_1.pkl  pose-index.csv\n",
            "2D_CNN_LSTM_skf.pkl\t3DYoga90.json\t      folds.pkl\t\t    skf.pkl\n",
            "3DYoga90_corrected.csv\tcriterion_fold_0.pkl  mod-yoga-90-data.csv\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "# Define base folder path\n",
        "base_path = '/content/gdrive/MyDrive/RGB_data_stream'\n",
        "data_path = '/content/gdrive/MyDrive/RGB_data_stream/data'\n",
        "!ls /content/gdrive/MyDrive/RGB_data_stream/\n",
        "!ls /content/gdrive/MyDrive/RGB_data_stream/data\n",
        "# base_path = '../'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg\n",
        "!pip install pytubefix"
      ],
      "metadata": {
        "id": "hDh9hnyJx9jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas\n",
        "import numpy\n",
        "import subprocess\n",
        "import pytubefix as pytube\n",
        "from pathlib import Path\n",
        "\n",
        "# # Mount drive and set up directories\n",
        "# drive.mount('/content/gdrive')\n",
        "# base_path = '/content/gdrive/MyDrive/RGB_data_stream'\n",
        "# output_dir = os.path.join(base_path, 'NEW_SHORTS')\n",
        "# log_file = os.path.join(base_path, 'downloaded_log.txt')\n",
        "\n",
        "# # Create output directory if it doesn't exist\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Helper function to find 720p video stream\n",
        "def find_video_stream(url, retries=5):\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            yt = pytube.YouTube(url, use_po_token=True, allow_oauth_cache=True)\n",
        "            yt.check_availability()\n",
        "            streams = yt.streams.filter(resolution='720p', type='video')\n",
        "            if streams:\n",
        "                return streams[0]\n",
        "        except Exception as e:\n",
        "            print(f\"Error accessing video {url}: {str(e)}\")\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "def convert_seconds_to_hms(seconds):\n",
        "    hours = seconds // 3600\n",
        "    minutes = (seconds % 3600) // 60\n",
        "    seconds = seconds % 60\n",
        "    return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
        "\n",
        "def log_download(sequence_id):\n",
        "    with open(log_file, 'a') as f:\n",
        "        f.write(f\"{sequence_id}\\n\")\n",
        "\n",
        "def get_downloaded_sequences():\n",
        "    if os.path.exists(log_file):\n",
        "        with open(log_file, 'r') as f:\n",
        "            return set(int(line.strip()) for line in f if line.strip())\n",
        "    return set()\n",
        "\n",
        "def clip_video(input_file, output_file, start_time, duration):\n",
        "    command = [\n",
        "        'ffmpeg',\n",
        "        '-i', input_file,\n",
        "        '-ss', start_time,\n",
        "        '-t', duration,\n",
        "        '-c:v', 'libx264',\n",
        "        '-c:a', 'aac',\n",
        "        '-y',  # Overwrite output file if it exists\n",
        "        output_file\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        subprocess.run(command, check=True, capture_output=True)\n",
        "        return True\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"FFmpeg error: {e.stderr.decode()}\")\n",
        "        return False\n",
        "\n",
        "def download_and_clip(sequence_id, data):\n",
        "    output_file = os.path.join(output_dir, f\"{sequence_id}.mp4\")\n",
        "\n",
        "    # Skip if already downloaded\n",
        "    if os.path.exists(output_file):\n",
        "        return True\n",
        "\n",
        "    url = data['url']\n",
        "    start_time = convert_seconds_to_hms(data['frame_start'])\n",
        "    duration = convert_seconds_to_hms(data['sequence_duration'])\n",
        "\n",
        "    # Get video stream\n",
        "    stream = find_video_stream(url)\n",
        "    if not stream:\n",
        "        print(f\"Could not find 720p stream for sequence {sequence_id}\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Download full video\n",
        "        print(f\"Downloading sequence {sequence_id}...\")\n",
        "        temp_file = stream.download()\n",
        "\n",
        "        # Clip video\n",
        "        print(f\"Clipping sequence {sequence_id}...\")\n",
        "        if clip_video(temp_file, output_file, start_time, duration):\n",
        "            # Clean up and log success\n",
        "            os.remove(temp_file)\n",
        "            log_download(sequence_id)\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Failed to clip video for sequence {sequence_id}\")\n",
        "            os.remove(temp_file)\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing sequence {sequence_id}: {str(e)}\")\n",
        "        if 'temp_file' in locals() and os.path.exists(temp_file):\n",
        "            os.remove(temp_file)\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    # Read the dataset\n",
        "    data = pandas.read_csv(os.path.join(data_path, 'mod-yoga-90-data.csv')).set_index('sequence_id')\n",
        "\n",
        "    # Define desired poses\n",
        "    desired_poses = ['downward-dog','standing-forward-bend','half-way-lift',\n",
        "             'mountain','chair','cobra','cockerel','extended-triangle',\n",
        "             'extended-side-angle','corpse','staff','wind-relieving','fish'\n",
        "            ]\n",
        "\n",
        "    # Get sequences for desired poses\n",
        "    sequences = data[data['l3_pose'].isin(desired_poses)].index.tolist()\n",
        "\n",
        "    # Get already downloaded sequences\n",
        "    downloaded = get_downloaded_sequences()\n",
        "\n",
        "    # Process remaining sequences\n",
        "    for seq_id in sequences:\n",
        "        if seq_id in downloaded:\n",
        "            print(f\"Sequence {seq_id} already downloaded, skipping...\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing sequence {seq_id}...\")\n",
        "        if download_and_clip(seq_id, data.loc[seq_id]):\n",
        "            print(f\"Successfully processed sequence {seq_id}\")\n",
        "        else:\n",
        "            print(f\"Failed to process sequence {seq_id}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uCk1Q2zuU2T",
        "outputId": "0def5bf4-0875-467e-e0d3-2da9d1ccadf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sequence 1000...\n",
            "Downloading sequence 1000...\n",
            "Clipping sequence 1000...\n",
            "Successfully processed sequence 1000\n",
            "Processing sequence 1002...\n",
            "Downloading sequence 1002...\n",
            "Clipping sequence 1002...\n",
            "Successfully processed sequence 1002\n",
            "Processing sequence 1003...\n",
            "Downloading sequence 1003...\n",
            "Clipping sequence 1003...\n",
            "Successfully processed sequence 1003\n",
            "Processing sequence 1004...\n",
            "Downloading sequence 1004...\n",
            "Clipping sequence 1004...\n",
            "Successfully processed sequence 1004\n",
            "Processing sequence 1005...\n",
            "Downloading sequence 1005...\n",
            "Clipping sequence 1005...\n",
            "Successfully processed sequence 1005\n",
            "Processing sequence 1006...\n",
            "Downloading sequence 1006...\n",
            "Clipping sequence 1006...\n",
            "Successfully processed sequence 1006\n",
            "Processing sequence 1007...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gEXgcFObt2wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visitor = \"CgtqUHhleTZQZkRmYyjojLy9BjIKCgJOUBIEGgAgGA%3D%3D\"\n",
        "po_token = \"MnSrS3KbfBSaLatzpV5bns37pskOd84hrjFt0qMw0MOGNhmhrbGt6l775JDCeXbtT733J6QVnsk1lvSseOVv9Ftoa0qWsSNU58c06acqNhQi0j6XUMxHS0Oe9UrzPzxBbVH9_atU9vu_QMvKlG4xBqw9xQ1T2Q==\""
      ],
      "metadata": {
        "id": "vp6LuzrHtqT_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}