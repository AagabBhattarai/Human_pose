{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "cu0Fn1p_CZC3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "5-EmS0rvCZC4"
      },
      "outputs": [],
      "source": [
        "TEST_SPLIT = 0.1\n",
        "# VAL_SPLIT = 0.2\n",
        "BATCH_SIZE = 16\n",
        "NUM_BLOCKS=7\n",
        "HIDDEN_CHANNELS = 120\n",
        "LEARNING_RATE = 0.001\n",
        "attention = 'soft_attention'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFsLvlE_CZC5",
        "outputId": "d24dac9e-5e28-4fc7-c813-357eb56c1c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "120_h_d_LR_0.01_FEB_4_NEW_STSAE_GCN\n",
            "Adaptive_avg_pooling_BLOCKSIZE_7__RC_attention_january_31_stsaegcn\n",
            "Adaptive_avg_pooling_RC_attention_january_31_stsaegcn\n",
            "CROSS_FOLD_STSAE_GCN_2025-02-08_B7_HC120_LR0.001_soft_attention\n",
            "CROSS_FOLD_STSAE_GCN_2025-02-09_B7_HC120_LR0.001_soft_attention\n",
            "data\n",
            "dec16_Cross_fold\n",
            "Dropout_RC_attention_january_31_stsaegcn\n",
            "FEB_4_NEW_STSAE_GCN\n",
            "FEB_4_no_STSAM_RES_BN_NEW_STSAE_GCN\n",
            "FEB_4_with_STSAM_RES_BN_NEW_STSAE_GCN\n",
            "HIGH_LR_FEB_4_NEW_STSAE_GCN\n",
            "jan30_Cross_fold\n",
            "january_30_CORRECTED_stsaegcn\n",
            "january_31_CORRECTED_stsaegcn\n",
            "LESS_POWER_MTCN_FIXED_stsaegcn\n",
            "Lower_Model_Capacity_RC_attention_january_31_stsaegcn\n",
            "LR_0.001_STSAE_GCN_2025-02-08_B7_HC120_soft_attention\n",
            "LR_0.008_STSAE_GCN_2025-02-08_B7_HC120_soft_attention\n",
            "LR_0.1_STSAE_GCN_2025-02-08_B7_HC120_soft_attention\n",
            "MORE_REDUCED_4_BLOCKS_Model_Capacity_RC_attention_january_31_stsaegcn\n",
            "MTCN_FIXED_stsaegcn\n",
            "NEW_STSAE_GCN_2025-02-08_B7_HC120_soft_attention\n",
            "NO_MTCN_120_h_d_LR_0.01_FEB_4_NEW_STSAE_GCN\n",
            "NO_MTCN_stsaegcn\n",
            "NO_STSAM_stsaegcn\n",
            "nov16_second_run\n",
            "nov16_test_third_run\n",
            "nov16_third_run\n",
            "nov16_unknown_attention\n",
            "nov20_third_run\n",
            "nov22_DA\n",
            "nov22_DA_longer\n",
            "nov24_weighted_loss\n",
            "nov25_Cross_fold\n",
            "official_dataset\n",
            "only_agcn_stsaegcn\n",
            "Progressive_Dropout_RC_attention_january_31_stsaegcn\n",
            "Residual_Connection_january_31_stsaegcn\n",
            "Residual_Connection_plus_attention_fixed_january_31_stsaegcn\n",
            "STSAE_GCN_2025-02-08_B4_HC120_soft_attention\n",
            "STSAE_GCN_2025-02-08_B6_HC120_soft_attention\n",
            "STSAE_GCN_2025-02-08_B7_HC120_soft_attention\n",
            "STSAE_GCN_2025-02-08_B7_HC258_soft_attention\n",
            "STSAE_GCN_2025-02-08_B7_HC66_soft_attention\n",
            "STSAM_120_Hc_LR_0.01_FEB_4_STSAE_GCN\n",
            "STSAM_264_Hc_LR_0.01_FEB_4_STSAE_GCN\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "# Define base folder path\n",
        "base_path = '/content/gdrive/MyDrive/yoga_proj'\n",
        "!ls /content/gdrive/MyDrive/yoga_proj\n",
        "# base_path = '../'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QiOQi7BCZC5",
        "outputId": "d86b1d75-3069-4c82-b205-7be15d0c2dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/yoga_proj/CROSS_FOLD_STSAE_GCN_2025-02-09_B7_HC120_LR0.001_soft_attention\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Gets label\n",
        "csv_path = os.path.join(base_path,'data/3DYoga90_corrected.csv')\n",
        "\n",
        "# SAVE_PATH = os.path.join(base_path, 'STSAE_GCN')\n",
        "today = datetime.today().strftime('%Y-%m-%d')\n",
        "SAVE_PATH = os.path.join(\n",
        "    base_path,\n",
        "    f'CROSS_FOLD_STSAE_GCN_{today}_B{NUM_BLOCKS}_HC{HIDDEN_CHANNELS}_LR{LEARNING_RATE}_{attention}'\n",
        ")\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "print(SAVE_PATH)\n",
        "\n",
        "pose_list = ['downward-dog','standing-forward-bend','half-way-lift',\n",
        "             'mountain','chair','cobra','cockerel','extended-triangle',\n",
        "             'extended-side-angle','corpse','staff','wind-relieving','fish'\n",
        "            ]\n",
        "NUM_CLASSES = len(pose_list)\n",
        "\n",
        "dataset_dir = os.path.join(base_path, 'official_dataset')\n",
        "assert os.path.isdir(dataset_dir), f\"Directory '{dataset_dir}' does not exist.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_mVAnHmCZC6",
        "outputId": "b25fb956-e53f-4509-dcb5-e9857b02d2c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cu124\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "SCqudip1CZC6"
      },
      "outputs": [],
      "source": [
        "meta_info_path = os.path.join(base_path, 'data')\n",
        "pose_index = pd.read_csv(f'{meta_info_path}/pose-index.csv')\n",
        "sequence_index = pd.read_csv(f'{meta_info_path}/3DYoga90_corrected.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpLOGWwACZC7"
      },
      "source": [
        "What does each file tell?\n",
        "\n",
        "1.) pose-index.csv -> Shows Heirarchical organization (THEN NOTHING MORE)\n",
        "\n",
        "2.) 3DYoga90.csv -> Total Main Info(i.e. along with RGB stream){\n",
        "    SequneceID: Parquet_FILE_NAME,\n",
        "    URL,\n",
        "    Frame Start and Frame Stop,\n",
        "    Pose Name, Training Test Split\n",
        "} `Difference between train and test? where to get the validation set from? How to do data augmentation?\n",
        "\n",
        "3.) Parquet Files -> {\n",
        "    Frame Number {\n",
        "        33 Landmarks\n",
        "    },\n",
        "    row-id: FrameNumber-TYPE-Landmark_index,\n",
        "    Coordinates: {x, y, z}\n",
        "}\n",
        "\n",
        "`PLEASE NOTE: The landmark coordinates are all normalized`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y0RRgDxCZC7"
      },
      "source": [
        "# Getting the data ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Kg3fH4QhCZC8"
      },
      "outputs": [],
      "source": [
        "subset_of_poses = pose_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "JD1fgbe3CZC8"
      },
      "outputs": [],
      "source": [
        "# Keep only relevant columns\n",
        "def read_meta_data():\n",
        "    meta_info_path = os.path.join(base_path, 'data')\n",
        "    pose_index = pd.read_csv(f'{meta_info_path}/pose-index.csv')\n",
        "    sequence_index = pd.read_csv(f'{meta_info_path}/3DYoga90_corrected.csv')\n",
        "    parquet_index = sequence_index[['sequence_id', 'l3_pose', 'split']]\n",
        "    return parquet_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "2rYfhKBuu5Ap"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def AddGaussianNoise(data, mean=0., std=0.01):\n",
        "    noise = torch.randn_like(data) * std + mean\n",
        "    return data + noise\n",
        "\n",
        "def RandomRotate(data, max_angle=30):\n",
        "    angle = torch.rand(1) * 2 * max_angle - max_angle  # Range: [-max_angle, max_angle] in degrees\n",
        "    angle_rad = torch.deg2rad(angle)\n",
        "    cos_theta = torch.cos(angle_rad)\n",
        "    sin_theta = torch.sin(angle_rad)\n",
        "\n",
        "    rotation_matrix = torch.tensor([\n",
        "        [cos_theta, 0, sin_theta],\n",
        "        [0, 1, 0],\n",
        "        [-sin_theta, 0, cos_theta]\n",
        "    ]).squeeze()\n",
        "\n",
        "    # print(data.shape)\n",
        "    # print(rotation_matrix.shape)\n",
        "    # data = torch.matmul(rotation_matrix, data)\n",
        "    data = torch.einsum('ij, jkl -> ikl', rotation_matrix, data)\n",
        "    return data\n",
        "\n",
        "def RandomScale(data, scale_range=(0.9, 1.1)):\n",
        "    scale =  scale_range[0] + torch.rand(1) * (scale_range[1] - scale_range[0]) # 0.9 + 0.2 * percentage\n",
        "    return data * scale\n",
        "\n",
        "def RandomTranslate(data, max_translate=0.1):\n",
        "    translate = torch.rand(3) * 2 * max_translate - max_translate  # Range: [-max_translate, max_translate]\n",
        "    return data + translate.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "def TimeReverse(data, p=0.5):\n",
        "    if torch.rand(1) < p:\n",
        "        return torch.flip(data, [1])\n",
        "    else:\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "zaw3MmIFCZC8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class Yoga3DDataset(Dataset):\n",
        "    def __init__(self, parquet_index, root_dir =  dataset_dir,subset_of_poses= subset_of_poses, sub_sampling_length = 20, transform=None, max_frames=None):\n",
        "        self.parquet_index = parquet_index\n",
        "        self.parquet_index = self.parquet_index[self.parquet_index['l3_pose'].isin(subset_of_poses)]\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.max_frames = max_frames\n",
        "        self.sub_sampling_length = sub_sampling_length\n",
        "        self.pose_to_label = {pose: i for i, pose in enumerate(subset_of_poses)}\n",
        "        self.use_augmentation = False\n",
        "\n",
        "        self.cache = dict()\n",
        "        self.idx_to_seq = dict()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.parquet_index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx in self.cache:\n",
        "            data, label = self.cache[idx]\n",
        "        else:\n",
        "            fname, pose_name, _ = self.parquet_index.iloc[idx]\n",
        "            label = self.pose_to_label[pose_name]\n",
        "            path = os.path.join(self.root_dir, f'{fname}.parquet')\n",
        "\n",
        "            df = pd.read_parquet(path)\n",
        "            df = df.drop(columns=['frame', 'row_id', 'type','landmark_index'])\n",
        "\n",
        "            data = self.to_tensor(df)\n",
        "            data = self.sub_sample(data)\n",
        "            data = data.permute(1,0,2)\n",
        "            self.cache[idx] = (data, label)\n",
        "            self.idx_to_seq[idx] = fname\n",
        "\n",
        "        if self.transform and self.use_augmentation:\n",
        "            data = self.transform(data.clone())\n",
        "\n",
        "        return data, label # C, T , V\n",
        "\n",
        "    def sub_sample(self, data):\n",
        "        # data(Number_of_frames, 3, 33)\n",
        "        total_frames = data.shape[0]\n",
        "        indices = torch.linspace(0, total_frames -1 , self.sub_sampling_length, dtype= int)\n",
        "        return data[indices]\n",
        "\n",
        "    def to_tensor(self, df):\n",
        "        # Reshape the data to (num_frames, num_landmarks, 3)  ## WHAT WHAT? this doesn't make sense remove this line you are doing (number of frames, 3 , 33)\n",
        "        num_frames = len(df) // 33  # Assuming 33 landmarks per frame\n",
        "        data = df.values.reshape(num_frames, 33, 3)\n",
        "        return torch.FloatTensor(data).permute(0, 2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "BFttuAX3u5Aq"
      },
      "outputs": [],
      "source": [
        "class Compose:\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, data):\n",
        "        for transform in self.transforms:\n",
        "            data = transform(data)\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "V5QKB0vju5Aq"
      },
      "outputs": [],
      "source": [
        "class RandomApply:\n",
        "    def __init__(self, transform, p=0.5):\n",
        "        self.transform = transform\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, data):\n",
        "        if torch.rand(1) < self.p:\n",
        "            return self.transform(data)\n",
        "        else:\n",
        "            return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, \n",
        "                              stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3,\n",
        "                              padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        \n",
        "        # Shortcut connection\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm1d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        \n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        \n",
        "        out += self.shortcut(residual)\n",
        "        out = self.relu(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "class CNNLSTM(nn.Module):\n",
        "    def __init__(self, input_channels,hidden_size=256, num_classes=NUM_CLASSES, num_nodes=33):\n",
        "        super(CNNLSTM, self).__init__()\n",
        "        \n",
        "        self.batch_norm = nn.BatchNorm1d(input_channels * num_nodes)\n",
        "        # CNN layers\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(input_channels, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        self.blk1 = ResBlock(32, 64, stride=2)\n",
        "        self.blk2 = ResBlock(64, 128, stride=2)\n",
        "        self.blk3 = ResBlock(128, 256, stride=2)\n",
        "        self.blk4 = ResBlock(256, 512, stride=2)\n",
        "\n",
        "        self.V_downsampled = 3\n",
        "        self.lstm = nn.LSTM(512 * self.V_downsampled, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, T, V = x.size()\n",
        "        \n",
        "        # BATCH NORM\n",
        "        x = x.permute(0, 3, 1, 2).contiguous()\n",
        "        x = x.view(N, V * C, T)\n",
        "        x = self.batch_norm(x)\n",
        "        x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()\n",
        "        \n",
        "        # CNN LAYER APPLICATION\n",
        "        x = x.view(N*T, C, V)\n",
        "        x = self.conv1(x)\n",
        "        x = self.blk1(x)\n",
        "        x = self.blk2(x)\n",
        "        x = self.blk3(x)\n",
        "        x = self.blk4(x)\n",
        "        \n",
        "        # Current shape: (N*T, 512, V_downsampled)\n",
        "        _, C_out, V_down = x.size()\n",
        "        x = x.view(N, T, C_out, V_down)\n",
        "        \n",
        "        # no interleaving (x0,y0,z0, x1,y1,z1,..) instead (x0,x1,..x32, y1, y2,...)\n",
        "        x = x.view(N, T, -1)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = x[:, -1, :]\n",
        "        \n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "    def count_parameters(self):\n",
        "        total_params = 0\n",
        "        for name, parameter in self.named_parameters():\n",
        "            if parameter.requires_grad:\n",
        "                params = parameter.numel()\n",
        "                print(f\"{name}: {params}\")\n",
        "                total_params += params\n",
        "        print(f\"Total Trainable Params: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "GFgBfmOSCZC9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "def save_checkpoint(model, optimizer, epoch, history, save_path = SAVE_PATH, best_path=None):\n",
        "    if best_path is not None:\n",
        "        chk_path = os.path.join(save_path, f'best_model.pth')\n",
        "        print(f\"Saving checkpoint to {chk_path}\")\n",
        "    else:\n",
        "        chk_path = os.path.join(save_path, f'checkpath_model.pth')\n",
        "        print(f\"Saving checkpoint to {chk_path}\")\n",
        "\n",
        "    # Combine model, optimizer, and history into one dictionary\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,  # Save the next epoch number for resuming\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'history': history  # Save history along with the model and optimizer\n",
        "    }\n",
        "\n",
        "    # Save everything in a single file using torch.save\n",
        "    torch.save(checkpoint, chk_path)\n",
        "    print(f\"Checkpoint saved at epoch {epoch + 1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "mZprkJQvCZC9"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(model, optimizer, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Load model and training state from a checkpoint\n",
        "    \"\"\"\n",
        "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path, weights_only = False)\n",
        "\n",
        "    # Load model and optimizer states\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    # Get the epoch number to resume from\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "    # Load training history with new metrics\n",
        "    history = checkpoint.get('history', {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_acc': [], 'val_acc': [],\n",
        "        'train_precision': [], 'train_recall': [], 'train_f1': [],\n",
        "        'val_precision': [], 'val_recall': [], 'val_f1': [],\n",
        "        'learning_rates': []\n",
        "    })\n",
        "\n",
        "    return model, optimizer, start_epoch, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "dkDP9PAlCZC9"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
        "    def __init__(self, patience=7, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        # on default = 7 successive val_loss increase stop\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "g8OLd0ZqOHVS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_per_class_metric(precision, recall, f1, epoch=0, pose_list=None, master_save_path=\"SAVE_PATH\"):\n",
        "    \"\"\"\n",
        "    Plots and saves per-class metrics (Precision, Recall, F1-score) for the given epoch.\n",
        "\n",
        "    Args:\n",
        "        precision (list): Per-class precision values.\n",
        "        recall (list): Per-class recall values.\n",
        "        f1 (list): Per-class F1-score values.\n",
        "        epoch (int): Current epoch number.\n",
        "        pose_list (list): List of class names (strings) corresponding to class indices.\n",
        "        master_save_path (str): Directory to save the plot.\n",
        "    \"\"\"\n",
        "    if pose_list is None:\n",
        "        pose_list = [str(i) for i in range(len(precision))]  # Default to numeric labels\n",
        "\n",
        "    save_dir = os.path.join(master_save_path, 'per_class_metric')\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    save_file_path = os.path.join(save_dir, f'per_class_metric_epoch_{epoch}.png')\n",
        "\n",
        "    # Adjust x-axis positions for grouped bars\n",
        "    x = range(len(pose_list))\n",
        "\n",
        "    plt.bar([i - 0.2 for i in x], precision, width=0.2, label='Precision', align='center')\n",
        "    plt.bar(x, recall, width=0.2, label='Recall', align='center')\n",
        "    plt.bar([i + 0.2 for i in x], f1, width=0.2, label='F1-Score', align='center')\n",
        "\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title(f'Per-Class Metrics - Epoch {epoch}')\n",
        "    plt.xticks(x, pose_list, rotation=45, ha='right')  # Use pose_list for x-axis labels\n",
        "    plt.legend()\n",
        "    plt.tight_layout()  # Adjust layout to fit rotated labels\n",
        "    plt.savefig(save_file_path)\n",
        "    plt.show()\n",
        "\n",
        "def per_class_metric(true, pred, epoch, pose_list=pose_list, average=None):\n",
        "    \"\"\"\n",
        "    Computes and logs per-class metrics (Precision, Recall, F1-score).\n",
        "\n",
        "    Args:\n",
        "        true (list): Ground-truth labels.\n",
        "        pred (list): Predicted labels.\n",
        "        epoch (int): Current epoch number.\n",
        "        pose_list (list): List of class names (strings) corresponding to class indices.\n",
        "        average (str or None): Averaging method for sklearn metrics (None for per-class).\n",
        "    \"\"\"\n",
        "    per_class_precision = precision_score(true, pred, average=average, zero_division=0)\n",
        "    per_class_recall = recall_score(true, pred, average=average, zero_division=0)\n",
        "    per_class_f1 = f1_score(true, pred, average=average, zero_division=0)\n",
        "\n",
        "    print(f\"Per-Class Metrics for Epoch {epoch}:\")\n",
        "    for i, (prec, rec, f1) in enumerate(zip(per_class_precision, per_class_recall, per_class_f1)):\n",
        "        class_name = pose_list[i] if pose_list else f\"Class {i}\"\n",
        "        print(f\"{class_name}: Precision={prec:.2f}, Recall={rec:.2f}, F1-Score={f1:.2f}\")\n",
        "\n",
        "    plot_per_class_metric(per_class_precision, per_class_recall, per_class_f1, epoch, pose_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "nNTAFuncCZC9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, dataset,fold, num_epochs=50, patience=18, log_interval=10, checkpoint_path=None, unfreeze_epoch=5, num_layers_unfreeze=3):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # Initialize scheduler\n",
        "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4)\n",
        "\n",
        "    # Initialize early stopping\n",
        "    early_stopping = EarlyStopping(patience=patience, min_delta=1e-4)\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # Initialize history for loss, accuracy, precision, recall, and F1\n",
        "    history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_acc': [], 'val_acc': [],\n",
        "        'train_precision': [], 'train_recall': [], 'train_f1': [],\n",
        "        'val_precision': [], 'val_recall': [], 'val_f1': [],\n",
        "        'learning_rates': []\n",
        "    }\n",
        "\n",
        "    # Check for checkpoint and load if available\n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        model, optimizer, start_epoch, history = load_checkpoint(model, optimizer, checkpoint_path)\n",
        "        print(f\"Resuming training from epoch {start_epoch}\")\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        dataset.use_augmentation = True #############\n",
        "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        history['learning_rates'].append(current_lr)\n",
        "        print(f\"Current Learning Rate: {current_lr}\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
        "        train_true, train_pred = [], []\n",
        "\n",
        "        train_loader_tqdm = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\")\n",
        "        for batch_idx, (inputs, labels) in train_loader_tqdm:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "\n",
        "            # Collect true and predicted labels for precision/recall\n",
        "            train_true.extend(labels.cpu().numpy())\n",
        "            train_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "            # Log batch-level updates\n",
        "            if batch_idx % log_interval == 0:\n",
        "                train_loader_tqdm.set_postfix({\n",
        "                    'loss': train_loss / (BATCH_SIZE * (batch_idx + 1)),\n",
        "                    'accuracy': 100.0 * train_correct / train_total\n",
        "                })\n",
        "\n",
        "        # Calculate training metrics\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = 100.0 * train_correct / train_total\n",
        "        train_precision = precision_score(train_true, train_pred, average='macro')\n",
        "        train_recall = recall_score(train_true, train_pred, average='macro')\n",
        "        train_f1 = f1_score(train_true, train_pred, average='macro')\n",
        "\n",
        "        per_class_metric(train_true, train_pred, epoch)\n",
        "\n",
        "        dataset.use_augmentation = False\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        val_true, val_pred = [], []\n",
        "\n",
        "        val_loader_tqdm = tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validation\")\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, labels) in val_loader_tqdm:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)  # Pass sequence lengths to model forward function\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "                # Collect true and predicted labels for precision/recall\n",
        "                val_true.extend(labels.cpu().numpy())\n",
        "                val_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "                # Log batch-level updates for validation\n",
        "                if batch_idx % log_interval == 0:\n",
        "                    val_loader_tqdm.set_postfix({\n",
        "                        'loss': val_loss / (BATCH_SIZE * (batch_idx + 1)),\n",
        "                        'accuracy': 100.0 * val_correct / val_total\n",
        "                    })\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = 100.0 * val_correct / val_total\n",
        "        val_precision = precision_score(val_true, val_pred, average='macro')\n",
        "        val_recall = recall_score(val_true, val_pred, average='macro')\n",
        "        val_f1 = f1_score(val_true, val_pred, average='macro')\n",
        "        # Per-class metrics for validation\n",
        "        per_class_metric(val_true, val_pred, epoch)\n",
        "        # Update history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['train_precision'].append(train_precision)\n",
        "        history['train_recall'].append(train_recall)\n",
        "        history['train_f1'].append(train_f1)\n",
        "        history['val_precision'].append(val_precision)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['val_f1'].append(val_f1)\n",
        "\n",
        "        # Print metrics at the end of the epoch\n",
        "        print(f'\\nEpoch {epoch + 1}/{num_epochs} Summary:')\n",
        "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Train Precision: {train_precision:.2f} | Train Recall: {train_recall:.2f} | Train F1: {train_f1:.2f}')\n",
        "        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | Val Precision: {val_precision:.2f} | Val Recall: {val_recall:.2f} | Val F1: {val_f1:.2f}')\n",
        "\n",
        "        # Save the best model checkpoint\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_path = os.path.join(SAVE_PATH, f'best_model_fold_{fold}.pth')\n",
        "            if best_model_path is not None:\n",
        "                print(best_model_path)\n",
        "            save_checkpoint(model, optimizer, epoch, history, SAVE_PATH, best_model_path)\n",
        "            print(f\"New best model saved! Validation Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "        # Adjust learning rate based on validation loss\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Check for early stopping\n",
        "        # early_stopping(val_loss)\n",
        "        # if early_stopping.early_stop:\n",
        "        #     print(\"Early stopping triggered\")\n",
        "        #     break\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "8MayBbiF0gtk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion, class_names, spath=SAVE_PATH, fsave='confusion_matrix.png'):\n",
        "    \"\"\"\n",
        "    Evaluate model on test set\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        test_loader: DataLoader for test data\n",
        "        criterion: Loss function\n",
        "        class_names: List of class names\n",
        "        spath: Directory to save the plot\n",
        "        fsave: Filename for confusion matrix plot\n",
        "\n",
        "    Returns:\n",
        "        test_loss: Average test loss\n",
        "        accuracy: Test accuracy\n",
        "        precision: Macro precision score\n",
        "        recall: Macro recall score\n",
        "        f1: Macro F1 score\n",
        "    \"\"\"\n",
        "    csave = os.path.join(spath, fsave)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader_tqdm:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "            test_total += labels.size(0)\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    accuracy = 100 * test_correct / test_total\n",
        "\n",
        "    # Calculate metrics with macro averaging\n",
        "    precision = precision_score(all_labels, all_predictions, average='macro')\n",
        "    recall = recall_score(all_labels, all_predictions, average='macro')\n",
        "    f1 = f1_score(all_labels, all_predictions, average='macro')\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "   # Create figure with adjusted size and subplot positioning\n",
        "    plt.figure(figsize=(12, 10))  # Increased figure size\n",
        "    plt.subplot(111, position=[0.1, 0.2, 0.8, 0.7])  # Adjust main plot position to leave room for text\n",
        "\n",
        "    # Create heatmap\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    # Prepare metrics text\n",
        "    metrics_text = (f'Test Loss: {test_loss:.4f}\\n'\n",
        "                    f'Test Accuracy: {accuracy:.2f}%\\n'\n",
        "                    f'Precision (Macro): {precision:.4f}\\n'\n",
        "                    f'Recall (Macro): {recall:.4f}\\n'\n",
        "                    f'F1 Score (Macro): {f1:.4f}')\n",
        "\n",
        "    # Add metrics text with adjusted position\n",
        "    plt.gcf().text(0.1, 0.02, metrics_text, fontsize=12, ha='left', va='bottom')\n",
        "\n",
        "    # Adjust layout to prevent cutting off\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(bottom=0.2)  # Leave space at bottom for metrics \n",
        "\n",
        "    # Save with tight layout to include all elements\n",
        "    plt.savefig(csave, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "    print(f'Precision (Macro): {precision:.4f}')\n",
        "    print(f'Recall (Macro): {recall:.4f}')\n",
        "    print(f'F1 Score (Macro): {f1:.4f}')\n",
        "\n",
        "    return test_loss, accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "7EWkYX8sCZC-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "def train_val_test_split(dataset, test_split = TEST_SPLIT):\n",
        "    total_size = len(dataset)\n",
        "    test_size = int(test_split * total_size)\n",
        "    train_size = total_size - test_size\n",
        "\n",
        "    train_dataset, test_dataset = random_split(\n",
        "        dataset,\n",
        "        [train_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
        "    )\n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "def create_data_loaders(train_dataset, test_dataset, batch_size = BATCH_SIZE):\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory= True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "-nVQoc_DCZC-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_training_curves(history, fold):\n",
        "    fsave=f'training_curves_fold_{fold}.png'\n",
        "    tsave = os.path.join(SAVE_PATH, fsave)\n",
        "    # plt.style.use('seaborn')\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "    # Loss curves\n",
        "    axs[0, 0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "    axs[0, 0].plot(history['val_loss'], label='Validation Loss', marker='o')\n",
        "    axs[0, 0].set_title('Loss')\n",
        "    axs[0, 0].legend()\n",
        "\n",
        "    # Accuracy curves\n",
        "    axs[0, 1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
        "    axs[0, 1].plot(history['val_acc'], label='Validation Accuracy', marker='o')\n",
        "    axs[0, 1].set_title('Accuracy')\n",
        "    axs[0, 1].legend()\n",
        "\n",
        "    # Learning rate\n",
        "    axs[0, 2].plot(history['learning_rates'], label='Learning Rate', marker='o')\n",
        "    axs[0, 2].set_title('Learning Rate')\n",
        "    axs[0, 2].set_yscale('log')\n",
        "    axs[0, 2].legend()\n",
        "\n",
        "    # Precision\n",
        "    axs[1, 0].plot(history['train_precision'], label='Train Precision', marker='o')\n",
        "    axs[1, 0].plot(history['val_precision'], label='Validation Precision', marker='o')\n",
        "    axs[1, 0].set_title('Precision')\n",
        "    axs[1, 0].legend()\n",
        "\n",
        "    # Recall\n",
        "    axs[1, 1].plot(history['train_recall'], label='Train Recall', marker='o')\n",
        "    axs[1, 1].plot(history['val_recall'], label='Validation Recall', marker='o')\n",
        "    axs[1, 1].set_title('Recall')\n",
        "    axs[1, 1].legend()\n",
        "\n",
        "    # F1 Score\n",
        "    axs[1, 2].plot(history['train_f1'], label='Train F1', marker='o')\n",
        "    axs[1, 2].plot(history['val_f1'], label='Validation F1', marker='o')\n",
        "    axs[1, 2].set_title('F1 Score')\n",
        "    axs[1, 2].legend()\n",
        "\n",
        "    for ax in axs.flat:\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(tsave)\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "7LXXcX28u5Ar"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from collections import Counter\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "def get_class_weights(pose_list, num_classes, strategy='balanced'):\n",
        "    \"\"\"\n",
        "    Calculate class weights with proper class index alignment.\n",
        "\n",
        "    Args:\n",
        "        pose_list: List of labels/poses in the dataset\n",
        "        num_classes: Total number of classes\n",
        "        strategy: Weighting strategy ('balanced', 'inverse', 'effective_samples', 'sqrt_inverse')\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Class weights tensor aligned with class indices\n",
        "    \"\"\"\n",
        "    # Count samples per class\n",
        "    class_counts = Counter(pose_list)\n",
        "    total_samples = len(pose_list)\n",
        "\n",
        "    # Initialize weights array with zeros for all possible classes\n",
        "    weights = np.zeros(num_classes)\n",
        "\n",
        "    if strategy == 'balanced':\n",
        "        # Use sklearn's balanced weighting\n",
        "        unique_classes = sorted(class_counts.keys())\n",
        "        sklearn_weights = compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=np.array(unique_classes),\n",
        "            y=pose_list\n",
        "        )\n",
        "        # Map weights to correct indices\n",
        "        for idx, class_label in enumerate(unique_classes):\n",
        "            weights[class_label] = sklearn_weights[idx]\n",
        "\n",
        "    elif strategy == 'inverse':\n",
        "        # Inverse of sample frequency\n",
        "        for class_label, count in class_counts.items():\n",
        "            weights[class_label] = total_samples / (num_classes * count)\n",
        "\n",
        "    elif strategy == 'effective_samples':\n",
        "        # Effective number of samples weighting\n",
        "        beta = 0.9999\n",
        "        for class_label, count in class_counts.items():\n",
        "            weights[class_label] = (1 - beta) / (1 - beta ** count)\n",
        "\n",
        "    elif strategy == 'sqrt_inverse':\n",
        "        # Square root of inverse frequency\n",
        "        for class_label, count in class_counts.items():\n",
        "            weights[class_label] = np.sqrt(total_samples / (num_classes * count))\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown weighting strategy: {strategy}\")\n",
        "\n",
        "    # Convert to tensor and normalize\n",
        "    weights = torch.FloatTensor(weights)\n",
        "    weights = weights / weights.sum() * len(weights)\n",
        "\n",
        "    return weights\n",
        "\n",
        "def create_weighted_criterion(pose_list, num_classes, strategy='balanced'):\n",
        "    \"\"\"\n",
        "    Create a weighted CrossEntropyLoss criterion.\n",
        "\n",
        "    Args:\n",
        "        pose_list: List of labels/poses in the dataset\n",
        "        num_classes: Total number of classes\n",
        "        strategy: Weighting strategy for calculating class weights\n",
        "\n",
        "    Returns:\n",
        "        nn.CrossEntropyLoss: Weighted loss criterion\n",
        "    \"\"\"\n",
        "    weights = get_class_weights(pose_list, num_classes, strategy)\n",
        "    print(\"Class weights aligned with indices:\", weights)\n",
        "    if torch.cuda.is_available():\n",
        "        weights = weights.cuda()\n",
        "    return nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "def analyze_class_distribution(pose_list):\n",
        "    \"\"\"\n",
        "    Analyze and print class distribution information.\n",
        "\n",
        "    Args:\n",
        "        pose_list: List of labels/poses in the dataset\n",
        "    \"\"\"\n",
        "    class_counts = Counter(pose_list)\n",
        "    total_samples = len(pose_list)\n",
        "\n",
        "    print(\"\\nClass Distribution Analysis:\")\n",
        "    print(\"-\" * 50)\n",
        "    for class_idx, count in sorted(class_counts.items()):\n",
        "        percentage = (count / total_samples) * 100\n",
        "        print(f\"Class {class_idx}: {count} samples ({percentage:.2f}%)\")\n",
        "\n",
        "    # Calculate imbalance metrics\n",
        "    max_count = max(class_counts.values())\n",
        "    min_count = min(class_counts.values())\n",
        "    imbalance_ratio = max_count / min_count\n",
        "\n",
        "    print(\"\\nImbalance Statistics:\")\n",
        "    print(f\"Imbalance Ratio (max/min): {imbalance_ratio:.2f}\")\n",
        "    print(f\"Maximum class size: {max_count}\")\n",
        "    print(f\"Minimum class size: {min_count}\")\n",
        "    print(f\"Average class size: {total_samples/len(class_counts):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "fqt2Ho_GOHVT"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "def create_data_loaders(train_idx, val_idx, dataset, batch_size=BATCH_SIZE):\n",
        "    # Create subsets for this fold\n",
        "    train_subset = Subset(dataset, train_idx)\n",
        "    val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "bi1E3bF0OHVT"
      },
      "outputs": [],
      "source": [
        "def compute_average_history(histories):\n",
        "    \"\"\"\n",
        "    Compute the average history across multiple folds.\n",
        "\n",
        "    Args:\n",
        "        histories (list of dict): List of history dictionaries from all folds. Each dictionary contains\n",
        "                                  metrics like 'train_loss', 'val_loss', 'train_accuracy', etc., as lists.\n",
        "\n",
        "    Returns:\n",
        "        dict: Averaged history containing the same keys as the input histories.\n",
        "    \"\"\"\n",
        "    avg_history = {}\n",
        "    num_folds = len(histories)\n",
        "\n",
        "    for key in histories[0]:  # Iterate over metric names\n",
        "        # Initialize a list for each metric\n",
        "        avg_history[key] = [0.0] * len(histories[0][key])  # Assume all folds have same length histories\n",
        "\n",
        "        # Sum across all folds\n",
        "        for fold_history in histories:\n",
        "            for i, value in enumerate(fold_history[key]):\n",
        "                avg_history[key][i] += value\n",
        "\n",
        "        # Divide by the number of folds to compute the average\n",
        "        avg_history[key] = [val / num_folds for val in avg_history[key]]\n",
        "\n",
        "    return avg_history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "RcWrvy4ZNiYj"
      },
      "outputs": [],
      "source": [
        "def compute_average_history(histories):\n",
        "    \"\"\"\n",
        "    Compute the average history across multiple folds.\n",
        "\n",
        "    Args:\n",
        "        histories (list of dict): List of history dictionaries from all folds. Each dictionary contains\n",
        "                                  metrics like 'train_loss', 'val_loss', 'train_accuracy', etc., as lists.\n",
        "\n",
        "    Returns:\n",
        "        dict: Averaged history containing the same keys as the input histories.\n",
        "    \"\"\"\n",
        "    avg_history = {}\n",
        "    num_folds = len(histories)\n",
        "\n",
        "    for key in histories[0]:  # Iterate over metric names\n",
        "        # Initialize a list for each metric\n",
        "        avg_history[key] = [0.0] * len(histories[0][key])  # Assume all folds have same length histories\n",
        "\n",
        "        # Sum across all folds\n",
        "        for fold_history in histories:\n",
        "            for i, value in enumerate(fold_history[key]):\n",
        "                avg_history[key][i] += value\n",
        "\n",
        "        # Divide by the number of folds to compute the average\n",
        "        avg_history[key] = [val / num_folds for val in avg_history[key]]\n",
        "\n",
        "    return avg_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "gX9YM1zJNj3A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def save_folds(meta_info_path, skf, folds):\n",
        "    folds_path = os.path.join(meta_info_path, \"folds.pkl\")\n",
        "    skf_path = os.path.join(meta_info_path, \"skf.pkl\")\n",
        "\n",
        "    with open(folds_path, \"wb\") as f:\n",
        "        pickle.dump(folds, f)\n",
        "\n",
        "    with open(skf_path, \"wb\") as f:\n",
        "        pickle.dump(skf, f)\n",
        "\n",
        "def load_folds(meta_info_path):\n",
        "    folds_path = os.path.join(meta_info_path, \"folds.pkl\")\n",
        "    skf_path = os.path.join(meta_info_path, \"skf.pkl\")\n",
        "\n",
        "    if os.path.exists(folds_path) and os.path.exists(skf_path):\n",
        "        with open(folds_path, \"rb\") as f:\n",
        "            folds = pickle.load(f)\n",
        "        with open(skf_path, \"rb\") as f:\n",
        "            skf = pickle.load(f)\n",
        "        return skf, folds\n",
        "    return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Vn5XpTqG6_6J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "def get_weighted_loss_criterion(train_dataset, train_indices=None, meta_info_path=None, fold=None):\n",
        "    \"\"\"\n",
        "    Get or compute weighted loss criterion, with caching support.\n",
        "\n",
        "    Args:\n",
        "        train_dataset: The training dataset\n",
        "        train_indices: Optional indices for cross-validation fold\n",
        "        meta_info_path: Path to save/load cached criteria\n",
        "        fold: Current fold number (required if using caching)\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.CrossEntropyLoss with computed weights\n",
        "    \"\"\"\n",
        "    if meta_info_path and fold is not None:\n",
        "        criterion_cache_path = os.path.join(meta_info_path, f'criterion_fold_{fold}.pkl')\n",
        "\n",
        "        # Try to load cached criterion\n",
        "        if os.path.exists(criterion_cache_path):\n",
        "            try:\n",
        "                with open(criterion_cache_path, 'rb') as f:\n",
        "                    cached_data = pickle.load(f)\n",
        "\n",
        "                # Verify the cached criterion matches current data\n",
        "                if verify_criterion_cache(cached_data, train_indices):\n",
        "                    print(f\"Loading cached criterion for fold {fold}\")\n",
        "                    return cached_data['criterion']\n",
        "                else:\n",
        "                    print(f\"Cached criterion for fold {fold} is invalid, recomputing...\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading cached criterion: {e}, recomputing...\")\n",
        "\n",
        "    # Compute criterion if no cache exists or verification failed\n",
        "    if train_indices is not None:\n",
        "        labels = [train_dataset[i][1] for i in train_indices]\n",
        "    else:\n",
        "        labels = [train_dataset[i][1] for i in range(len(train_dataset))]\n",
        "\n",
        "    analyze_class_distribution(labels)\n",
        "    criterion = create_weighted_criterion(\n",
        "        labels,\n",
        "        num_classes=NUM_CLASSES,\n",
        "        strategy='effective_samples'\n",
        "    )\n",
        "\n",
        "    # Cache the computed criterion if path is provided\n",
        "    if meta_info_path and fold is not None:\n",
        "        os.makedirs(meta_info_path, exist_ok=True)\n",
        "        cache_data = {\n",
        "            'criterion': criterion,\n",
        "            'train_indices': train_indices,\n",
        "            'fold': fold\n",
        "        }\n",
        "        with open(criterion_cache_path, 'wb') as f:\n",
        "            pickle.dump(cache_data, f)\n",
        "        print(f\"Cached criterion for fold {fold}\")\n",
        "\n",
        "    return criterion\n",
        "\n",
        "def verify_criterion_cache(cached_data, current_train_indices):\n",
        "    \"\"\"\n",
        "    Verify that cached criterion matches current training indices.\n",
        "\n",
        "    Args:\n",
        "        cached_data: Dictionary containing cached criterion and metadata\n",
        "        current_train_indices: Current training indices to verify against\n",
        "\n",
        "    Returns:\n",
        "        bool: True if cache is valid, False otherwise\n",
        "    \"\"\"\n",
        "    cached_indices = cached_data['train_indices']\n",
        "    if cached_indices is None and current_train_indices is None:\n",
        "        return True\n",
        "    if cached_indices is None or current_train_indices is None:\n",
        "        return False\n",
        "    return len(cached_indices) == len(current_train_indices) and all(\n",
        "        a == b for a, b in zip(sorted(cached_indices), sorted(current_train_indices))\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "_G8_YTgfNq3R"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def main(in_channels=3, hidden_channels=HIDDEN_CHANNELS, num_classes=NUM_CLASSES, num_frames=20, LR=LEARNING_RATE, Epochs=50):\n",
        "    transforms = Compose([\n",
        "        RandomApply(AddGaussianNoise, p=0.5),\n",
        "        RandomApply(RandomRotate, p=0.5),\n",
        "        RandomApply(RandomScale, p=0.5),\n",
        "        RandomApply(RandomTranslate, p=0.5),\n",
        "    ])\n",
        "\n",
        "    dataset, train_dataset, test_dataset = prepare_dataset()\n",
        "\n",
        "    # Load precomputed folds if available\n",
        "    skf, folds = load_folds(meta_info_path)\n",
        "\n",
        "    if folds is None:\n",
        "        k_folds = 5\n",
        "        skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "        folds = list(skf.split(np.arange(len(train_dataset)), get_all_the_labels(train_dataset)))\n",
        "        save_folds(meta_info_path, skf, folds)\n",
        "\n",
        "    best_model = None\n",
        "    best_val_loss = float('inf')\n",
        "    best_fold = 0\n",
        "    all_metrics = []\n",
        "\n",
        "    print('Starting cross-validation...')\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(folds):\n",
        "        print(f\"Fold {fold + 1}/{len(folds)}\")\n",
        "        train_loader, val_loader = create_data_loaders(train_idx, val_idx, train_dataset)\n",
        "\n",
        "        criterion = get_weighted_loss_criterion(\n",
        "            train_dataset,\n",
        "            train_idx,\n",
        "            meta_info_path=meta_info_path,\n",
        "            fold=fold\n",
        "        )\n",
        "        model = CNNLSTM(in_channels, hidden_channels, num_classes)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "        model, history = train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            criterion,\n",
        "            optimizer,\n",
        "            dataset,\n",
        "            fold=fold,\n",
        "            num_epochs=Epochs,\n",
        "            patience=10,\n",
        "            log_interval=1,\n",
        "            checkpoint_path=None\n",
        "        )\n",
        "        plot_training_curves(history, fold)\n",
        "        all_metrics.append(history)\n",
        "\n",
        "        if history['val_loss'][-1] < best_val_loss:\n",
        "            best_val_loss = history['val_loss'][-1]\n",
        "            best_model = model\n",
        "            best_fold = fold\n",
        "\n",
        "    avg_history = compute_average_history(all_metrics)\n",
        "    plot_training_curves(avg_history, 'average')\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    evaluate_model(best_model, test_loader, criterion, pose_list)\n",
        "\n",
        "    model_save_path = os.path.join(SAVE_PATH, f'my_model_{best_fold}.pth')\n",
        "    torch.save(best_model.state_dict(), model_save_path)\n",
        "\n",
        "\n",
        "# def get_weighted_loss_criterion(train_dataset, train_indices=None):\n",
        "#     \"\"\"\n",
        "#     Calculate class weights based on the training data only.\n",
        "\n",
        "#     Args:\n",
        "#         train_dataset: The training dataset\n",
        "#         train_indices: Optional indices for cross-validation fold\n",
        "\n",
        "#     Returns:\n",
        "#         torch.nn.CrossEntropyLoss with computed weights\n",
        "#     \"\"\"\n",
        "#     # If we're doing cross-validation, use only the fold's training data\n",
        "#     if train_indices is not None:\n",
        "#         labels = [train_dataset[i][1] for i in train_indices]\n",
        "#     else:\n",
        "#         labels = [train_dataset[i][1] for i in range(len(train_dataset))]\n",
        "\n",
        "#     analyze_class_distribution(labels)\n",
        "\n",
        "#     # Create weighted loss criterion\n",
        "#     criterion = create_weighted_criterion(\n",
        "#         labels,\n",
        "#         num_classes=NUM_CLASSES,\n",
        "#         strategy='effective_samples'\n",
        "#     )\n",
        "\n",
        "#     return criterion\n",
        "def prepare_dataset():\n",
        "    dataset = Yoga3DDataset(read_meta_data()) #removed transforms for now\n",
        "    train_dataset, test_dataset = train_val_test_split(dataset)\n",
        "    # train_loader, test_loader = create_data_loaders(train_dataset, test_dataset)\n",
        "    return dataset,train_dataset,test_dataset\n",
        "\n",
        "def get_all_the_labels(dataset):\n",
        "    return [label for _, label in dataset]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "KaE3iYzvCZC-"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# def main(in_channels = 3, hidden_channels= HIDDEN_CHANNELS, num_classes= NUM_CLASSES, num_frames= 20, LR = LEARNING_RATE, Epochs =50):\n",
        "#     transforms = Compose([\n",
        "#         RandomApply(AddGaussianNoise, p=0.5),\n",
        "#         RandomApply(RandomRotate, p=0.5),\n",
        "#         RandomApply(RandomScale, p=0.5),\n",
        "#         RandomApply(RandomTranslate, p=0.5),\n",
        "#         # TimeReverse(p=0.5)\n",
        "#         # Normalize,\n",
        "#     ])\n",
        "\n",
        "#     dataset, train_dataset, test_dataset = prepare_dataset(transforms)\n",
        "\n",
        "#     # checkpoint_path = os.path.join(SAVE_PATH, 'best_model.pth')\n",
        "#     k_folds = 5\n",
        "#     skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "#     folds = list(skf.split(np.arange(len(train_dataset)), get_all_the_labels(train_dataset)))\n",
        "\n",
        "#     best_model = None\n",
        "#     best_val_loss = float('inf')\n",
        "#     best_fold = 0\n",
        "#     all_metrics = []\n",
        "#     loss_weights = None\n",
        "#     print('starting')\n",
        "#     for fold, (train_idx, val_idx) in enumerate(folds):\n",
        "#         print(f\"Fold {fold + 1}/{k_folds}\")\n",
        "#         train_loader, val_loader = create_data_loaders(train_idx, val_idx, train_dataset)\n",
        "\n",
        "#         criterion = get_weighted_loss_criterion(dataset) # Cross Entropy Loss\n",
        "#         model = STSAE_GCN(in_channels, hidden_channels, num_classes, num_frames)\n",
        "#         optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "#         model, history = train_model(\n",
        "#             model,\n",
        "#             train_loader,\n",
        "#             val_loader,\n",
        "#             criterion,\n",
        "#             optimizer,\n",
        "#             dataset,\n",
        "#             fold= fold,\n",
        "#             num_epochs= Epochs,\n",
        "#             patience=20,\n",
        "#             log_interval=1,\n",
        "#             checkpoint_path=None\n",
        "#         )\n",
        "#         plot_training_curves(history, fold)\n",
        "#         all_metrics.append(history)\n",
        "\n",
        "#         print(history['val_loss'][-1])\n",
        "#         print(type(history['val_loss'][-1]))\n",
        "#         if history['val_loss'][-1] < best_val_loss:\n",
        "#             best_val_loss = history['val_loss'][-1]\n",
        "#             best_model = model\n",
        "#             best_fold = fold\n",
        "\n",
        "#     avg_history = compute_average_history(all_metrics)\n",
        "#     plot_training_curves(avg_history, 'average')  # Plot the average history\n",
        "\n",
        "#     test_loader = DataLoader(test_dataset, batch_size= BATCH_SIZE, shuffle= False)\n",
        "#     evaluate_model(best_model, test_loader, criterion, pose_list)\n",
        "\n",
        "#     model_save_path = os.path.join(SAVE_PATH, f'my_model_{best_fold}.pth')\n",
        "#     torch.save(best_model.state_dict(), model_save_path)\n",
        "\n",
        "# def get_weighted_loss_criterion(dataset):\n",
        "#     all_labels = [dataset[i][1] for i in range(len(dataset))]\n",
        "#     analyze_class_distribution(all_labels)\n",
        "\n",
        "#     # Create weighted loss criterion\n",
        "#     criterion = create_weighted_criterion(\n",
        "#         all_labels,\n",
        "#         num_classes= NUM_CLASSES,\n",
        "#         strategy='effective_samples'  # Try different strategies\n",
        "#     )\n",
        "\n",
        "#     return criterion\n",
        "\n",
        "# def prepare_dataset(transforms):\n",
        "#     dataset = Yoga3DDataset(read_meta_data(), transform=transforms)\n",
        "#     train_dataset, test_dataset = train_val_test_split(dataset)\n",
        "#     # train_loader, test_loader = create_data_loaders(train_dataset, test_dataset)\n",
        "#     return dataset,train_dataset,test_dataset\n",
        "\n",
        "# def get_all_the_labels(dataset):\n",
        "#     return [label for _, label in dataset]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GpaMPADECZC-",
        "outputId": "0d74603d-9820-43cc-8163-1d78971c4887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting cross-validation...\n",
            "Fold 1/5\n",
            "\n",
            "Class Distribution Analysis:\n",
            "--------------------------------------------------\n",
            "Class 0: 184 samples (14.06%)\n",
            "Class 1: 162 samples (12.38%)\n",
            "Class 2: 149 samples (11.38%)\n",
            "Class 3: 115 samples (8.79%)\n",
            "Class 4: 94 samples (7.18%)\n",
            "Class 5: 92 samples (7.03%)\n",
            "Class 6: 89 samples (6.80%)\n",
            "Class 7: 79 samples (6.04%)\n",
            "Class 8: 73 samples (5.58%)\n",
            "Class 9: 70 samples (5.35%)\n",
            "Class 10: 65 samples (4.97%)\n",
            "Class 11: 69 samples (5.27%)\n",
            "Class 12: 68 samples (5.19%)\n",
            "\n",
            "Imbalance Statistics:\n",
            "Imbalance Ratio (max/min): 2.83\n",
            "Maximum class size: 184\n",
            "Minimum class size: 65\n",
            "Average class size: 100.69\n",
            "Class weights aligned with indices: tensor([0.4896, 0.5555, 0.6036, 0.7807, 0.9541, 0.9747, 1.0074, 1.1344, 1.2273,\n",
            "        1.2797, 1.3778, 1.2981, 1.3172])\n",
            "Cached criterion for fold 0\n",
            "Using device: cuda\n",
            "\n",
            "Epoch 1/50\n",
            "Current Learning Rate: 0.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 82/82 [00:06<00:00, 12.73it/s, loss=1.45, accuracy=60.9]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per-Class Metrics for Epoch 0:\n",
            "downward-dog: Precision=0.66, Recall=0.69, F1-Score=0.68\n",
            "standing-forward-bend: Precision=0.72, Recall=0.48, F1-Score=0.58\n",
            "half-way-lift: Precision=0.71, Recall=0.84, F1-Score=0.77\n",
            "mountain: Precision=0.63, Recall=0.66, F1-Score=0.64\n",
            "chair: Precision=0.48, Recall=0.50, F1-Score=0.49\n",
            "cobra: Precision=0.68, Recall=0.68, F1-Score=0.68\n",
            "cockerel: Precision=0.70, Recall=0.65, F1-Score=0.67\n",
            "extended-triangle: Precision=0.56, Recall=0.52, F1-Score=0.54\n",
            "extended-side-angle: Precision=0.45, Recall=0.49, F1-Score=0.47\n",
            "corpse: Precision=0.28, Recall=0.34, F1-Score=0.31\n",
            "staff: Precision=0.59, Recall=0.74, F1-Score=0.65\n",
            "wind-relieving: Precision=0.81, Recall=0.68, F1-Score=0.74\n",
            "fish: Precision=0.45, Recall=0.40, F1-Score=0.42\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation:  38%|███▊      | 8/21 [01:13<03:56, 18.23s/it, loss=0.911, accuracy=60.9]"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNhSc5nau5Ar"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "\n",
        "def find_sus(model, test_loader, criterion, class_names, spath=SAVE_PATH, fsave='confusion_matrix_all.png'):\n",
        "    \"\"\"\n",
        "    Evaluate model on test set\n",
        "\n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        test_loader: DataLoader for test data\n",
        "        criterion: Loss function\n",
        "        class_names: List of class names\n",
        "        save_path: Directory to save the plot\n",
        "        fsave: Filename for confusion matrix plot\n",
        "    \"\"\"\n",
        "    csave = os.path.join(spath, fsave)\n",
        "    sussave = os.path.join(spath, 'sus.csv')\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    misclassified_data = []\n",
        "\n",
        "    # Create progress bar\n",
        "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(test_loader_tqdm):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            # Get predictions\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            # Calculate accuracy\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "            test_total += labels.size(0)\n",
        "\n",
        "            # Store predictions and labels for confusion matrix\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Check if the sample is misclassified\n",
        "            misclassified_indices = (predicted != labels).nonzero(as_tuple=True)[0]\n",
        "            for misclassified_idx in misclassified_indices:\n",
        "                global_idx = batch_idx * inputs.size(0) + misclassified_idx.item()\n",
        "                sequence_id = test_loader.dataset.idx_to_seq[global_idx]\n",
        "                correct_label = class_names[labels[misclassified_idx].item()]\n",
        "                prediction = class_names[predicted[misclassified_idx].item()]\n",
        "                misclassified_data.append([sequence_id, correct_label, prediction])\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    accuracy = 100 * test_correct / test_total\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=pose_list, yticklabels=pose_list)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(csave)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # Save misclassified data to CSV\n",
        "    with open(sussave, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(['sequence_id', 'correct_label', 'prediction'])\n",
        "        writer.writerows(misclassified_data)\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}')\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60euC5Fmu5As"
      },
      "outputs": [],
      "source": [
        "dataset = Yoga3DDataset(read_meta_data())\n",
        "label_to_pose = {v:k for k,v in dataset.pose_to_label.items()}\n",
        "\n",
        "# model = STSAE_GCN(3, HIDDEN_CHANNELS, NUM_CLASSES, 20, NUM_BLOCKS)\n",
        "in_channels = 3\n",
        "hidden_channels = HIDDEN_CHANNELS\n",
        "num_classes = NUM_CLASSES\n",
        "model = CNNLSTM(in_channels, hidden_channels, num_classes)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "all_labels = [dataset[i][1] for i in range(len(dataset))]\n",
        "criterion = create_weighted_criterion(\n",
        "        all_labels,\n",
        "        num_classes= NUM_CLASSES,\n",
        "        strategy='inverse'  # Try different strategies\n",
        "    )\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "checkpoint_path = os.path.join(SAVE_PATH, 'best_model.pth')\n",
        "# Plot the training curves\n",
        "if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        model, optimizer, start_epoch, history = load_checkpoint(\n",
        "            model, optimizer, checkpoint_path\n",
        "        )\n",
        "        print(f\"Resuming training from epoch {start_epoch}\")\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "# plot_training_curves(history)\n",
        "find_sus(model, loader, criterion, label_to_pose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dkqFDp2y5HK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
